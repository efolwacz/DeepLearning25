{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/efolwacz/DeepLearning25/blob/main/week_1/CIFAR10-ShallowLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7t4Y8D_BxLK"
      },
      "source": [
        "# Lab 1: CIFAR10 Challenge\n",
        "\n",
        "**CIFAR10** (http://www.cs.toronto.edu/~kriz/cifar.html) is one of the most famous ML data sets.\n",
        "\n",
        "## Data\n",
        "* 32x32 color images\n",
        "* in 10 classes\n",
        "* 50k training images\n",
        "* 10k test images\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8-2lrE9BxLR"
      },
      "source": [
        "<img src=\"https://production-media.paperswithcode.com/datasets/CIFAR-10-0000000431-b71f61c0_U5n3Glr.jpg\" width=700>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "owj3QsH2BxLS"
      },
      "outputs": [],
      "source": [
        "#get data\n",
        "from keras.datasets import cifar10\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFjmpalPBxLW",
        "outputId": "669fba24-bc25-462f-cf27-2ed943da38bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "#traindata: 50k 32X32 rgb images\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtB2ZlTkBxLW",
        "outputId": "f4449773-85ef-4af4-cb94-db4f644a275f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6],\n",
              "       [9],\n",
              "       [9],\n",
              "       ...,\n",
              "       [9],\n",
              "       [1],\n",
              "       [1]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "#labels\n",
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M67ENz0DCJi0"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task: build the best classifier (with feature extration) using the methods you know from ML1+2\n",
        "* work in small teams (2-4)\n",
        "* use NumPy pre-processing, feature extraction and hyer-parameter tuning in Scikit-Learn\n",
        "* no Neural Networks!\n",
        "* best test F1-Score winns!"
      ],
      "metadata": {
        "id": "9rEXJUhVCmvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from skimage.feature import hog\n",
        "from skimage.io import imread\n",
        "from skimage.transform import rescale"
      ],
      "metadata": {
        "id": "_fKpoDXQEmyb"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bins = 8\n",
        "\n",
        "# feature-descriptor-1: Hu Moments\n",
        "def fd_hu_moments(image):\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    feature = cv2.HuMoments(cv2.moments(image)).flatten()\n",
        "    return feature\n",
        "\n",
        "\n",
        "def fd_histogram(image, mask=None):\n",
        "    # convert the image to HSV color-space\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    # compute the color histogram\n",
        "    hist  = cv2.calcHist([image], [0, 1, 2], None, [bins, bins, bins], [0, 256, 0, 256, 0, 256])\n",
        "    # normalize the histogram\n",
        "    cv2.normalize(hist, hist)\n",
        "    # return the histogram\n",
        "    return hist.flatten()\n",
        "\n",
        "def edges(image):\n",
        "  # Convert to grayscale\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  # Detect edges using Canny method\n",
        "  e = cv2.Canny(gray, 150, 300)\n",
        "  return e.flatten()\n",
        ""
      ],
      "metadata": {
        "id": "mDGEzM6YGAP4"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge = edges(X_train[0])\n",
        "edge\n"
      ],
      "metadata": {
        "id": "STKKfSE-idO4",
        "outputId": "e08129b6-1856-4082-c94c-9a557cd5bf70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   0,   0],\n",
              "       [  0,   0,   0, ...,   0,   0,   0],\n",
              "       [  0,   0,   0, ...,   0,   0,   0],\n",
              "       ...,\n",
              "       [255,   0,   0, ...,   0, 255,   0],\n",
              "       [  0,   0,   0, ...,   0, 255, 255],\n",
              "       [  0,   0,   0, ...,   0, 255, 255]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-16b64f65-c5f5-4166-b2b5-3d2a1ef99c78\" class=\"ndarray_repr\"><pre>ndarray (32, 32) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAAAqUlEQVR4nN1SQRIDIQhLOvz/y+lhBaKLfUA9OAIhBAT4h0M3dNgnQCCgM8viWiy6VFNd97iSq3Fh5ZuDDSDMyUFhdD7o+ARG8WT93TR98g77+bE0LvESAO0jfAhUPQppRkooeaxsCmA0B6udQrRUrcJpPrOUzLPNutW1o2WdA/DG/ZeSQRPcPFFv6rVNIhTW9LBpk/ADEL/Dd4Ic1bZRLw3iKiECGuIA8AUk9nHf1UYzmgAAAABJRU5ErkJggg==\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[  0,   0,   0, ...,   0,   0,   0],\n",
              "       [  0,   0,   0, ...,   0,   0,   0],\n",
              "       [  0,   0,   0, ...,   0,   0,   0],\n",
              "       ...,\n",
              "       [255,   0,   0, ...,   0, 255,   0],\n",
              "       [  0,   0,   0, ...,   0, 255, 255],\n",
              "       [  0,   0,   0, ...,   0, 255, 255]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-16b64f65-c5f5-4166-b2b5-3d2a1ef99c78 button').onclick = (e) => {\n",
              "        document.querySelector('#id-16b64f65-c5f5-4166-b2b5-3d2a1ef99c78').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-16b64f65-c5f5-4166-b2b5-3d2a1ef99c78 button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Feature-Liste f√ºr alle Bilder\n",
        "features = []\n",
        "\n",
        "def transform(data):\n",
        "  features = []\n",
        "\n",
        "  for img in data:  # img hat die Form (32, 32, 3)\n",
        "    # features.append(fd_hu_moments(img))\n",
        "\n",
        "\n",
        "      ####################################\n",
        "    # Global Feature extraction\n",
        "    ####################################\n",
        "    fv_hu_moments = fd_hu_moments(img)\n",
        "    fv_histogram  = fd_histogram(img)\n",
        "    e = edges(img)\n",
        "\n",
        "\n",
        "    # np.array([skimage.color.rgb2gray(img)])\n",
        "\n",
        "    ###################################\n",
        "    # Concatenate global features\n",
        "    ###################################\n",
        "    global_feature = np.hstack([fv_histogram, fv_hu_moments, e])\n",
        "    features.append(global_feature)\n",
        "\n",
        "\n",
        "  return features\n",
        "  # X_features = np.array(features)  # Shape: (50000, n_features)\n"
      ],
      "metadata": {
        "id": "6FXU5hLhDfUP"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# features"
      ],
      "metadata": {
        "id": "VkguC2vuFLjt"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier()\n",
        "\n",
        "clf.fit(transform(X_train), y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "nC1xgw-dFNi4",
        "outputId": "9b3b949f-512f-4860-d91e-cd890613ce11"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 2 has 2 dimension(s)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-d60e7af32ba8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-92-d4639ae6b31b>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Concatenate global features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m###################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mglobal_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfv_histogram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfv_hu_moments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/_core/shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;31m# As a special case, dimension 0 of 1-dimensional arrays is \"horizontal\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcasting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcasting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 2 has 2 dimension(s)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(transform(X_test))\n",
        "\n",
        "acc = accuracy_score(y_pred, y_test)\n",
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_rHCVAEWJmf",
        "outputId": "171b4141-f7e9-4402-d056-d06c567a6c22"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4257"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "CIFAR10-ShallowLearning.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}