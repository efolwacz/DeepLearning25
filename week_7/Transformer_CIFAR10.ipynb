{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN_CIFAR10.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment: Vision Transformers on CIFAR10"
      ],
      "metadata": {
        "id": "9rZPsOU0phDS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i0AIosM0AaY2"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the dataset\n",
        "dataset = dset.CIFAR10(root=\"./data\", download=True,\n",
        "                           transform=transforms.Compose([\n",
        "                               transforms.Resize(224),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                           ]))\n",
        "nc=3\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=128,\n",
        "                                         shuffle=True, num_workers=2)\n"
      ],
      "metadata": {
        "id": "is2FpH_lAtJJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the availability of cuda devices\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "yF-tedlhAx-s"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tasks:\n",
        "* try to get the best test Accuracy on Cifar10 using a transformer model\n",
        "* pre-trained models allowed - see [here](https://docs.pytorch.org/vision/main/models/vision_transformer.html) for list of models in TorchVision\n",
        "* **hint**: just like with the CNN in Week 5 - wee need to change the classification layer to fit our 10 class CIFAR-10 problem before we can fine-tune it...\n",
        "* **hint**: Transformers need a lot of compute + memory - use the A100 GPU\n",
        "\n"
      ],
      "metadata": {
        "id": "KxRD7Myvpogs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import vit_b_16, ViT_B_16_Weights"
      ],
      "metadata": {
        "id": "w6abeuIeAXBh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Vision Transformer Model\n",
        "weights = ViT_B_16_Weights.DEFAULT\n",
        "model = vit_b_16(weights=weights)\n",
        "model.heads.head = nn.Linear(model.heads.head.in_features, 10)\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss Function and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "m_Dbc3R6vENq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, criterion, optimizer, device, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        correct, total = 0, 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {running_loss / len(train_loader)}, Accuracy: {100 * correct / total:.2f}%')"
      ],
      "metadata": {
        "id": "F1pLcDk4HGao"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Accuracy on test data: {100 * correct / total:.2f}%')\n"
      ],
      "metadata": {
        "id": "vr9EYM-pHkna"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train and Evaluate the Model\n",
        "train_model(model, dataloader, criterion, optimizer, device, epochs=5)\n",
        "evaluate_model(model, dataloader, device)"
      ],
      "metadata": {
        "id": "yxTPjo38Hnaa",
        "outputId": "94aa5cee-8783-4dd3-fcc8-5dbdc67aee9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1], Loss: 2.2075450789288182, Accuracy: 17.24%\n",
            "Accuracy on test data: 16.52%\n"
          ]
        }
      ]
    }
  ]
}