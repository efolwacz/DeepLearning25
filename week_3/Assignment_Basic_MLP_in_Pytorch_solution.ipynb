{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8Cwq-uPYvpa"
      },
      "source": [
        "# Build basic 2-Layer MLP to solve the xor-Problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K4FDsqgaYvps"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_blobs #for data generatio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2x1wijYZYvpu"
      },
      "outputs": [],
      "source": [
        "X, y = make_blobs(n_samples=200, n_features=2, cluster_std=.1\n",
        "                  ,centers= [(1,1), (1,0), (0,0),(0,1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "aoAh4a4KYvpv"
      },
      "outputs": [],
      "source": [
        "y[y==2]=0\n",
        "y[y==3]=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "RMPaCrKBYvpw",
        "outputId": "6bf7beb1-013c-4112-db45-12452f75acf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7bc080233010>"
            ]
          },
          "metadata": {},
          "execution_count": 180
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.scatter(X[:,0],X[:,1],c=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q9Y4g0NYvpy"
      },
      "source": [
        "## Steps:\n",
        "* build train and test sets\n",
        "* write MLP class in Pytorch with two layers with adjustable number of perceptrons\n",
        "* use nn.linear and nn.Sigmoid() units\n",
        "* train your model\n",
        "* test your model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "class MLP(torch.nn.Module): #all nets inherit from nn.Module\n",
        "    def __init__(self): #define layer types\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(2,4,bias=False) #1st layer input dim = 2, output =4 - | input needs to have size of data\n",
        "        self.fc2 = torch.nn.Linear(4,1,bias=True) #2nd layer input 4 out put 2 | output needs to be one for binary problem\n",
        "        self.non_linear = torch.nn.Sigmoid() #non-linear activation\n",
        "\n",
        "    def forward(self, x): #build network\n",
        "        output = self.fc1(x) #w*X\n",
        "        output = self.non_linear(output) # activation\n",
        "        output = self.fc2(output) #w*X\n",
        "        output = self.non_linear(output) # activation\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "piXsTVTrZssQ"
      },
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split #for test set generation\n",
        "#split in train and test\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "#np->torch\n",
        "x_train = torch.FloatTensor(x_train)\n",
        "x_test = torch.FloatTensor(x_test)\n",
        "y_train = torch.FloatTensor(y_train)\n",
        "y_test = torch.FloatTensor(y_test)\n"
      ],
      "metadata": {
        "id": "5YfSkNwwWZY1"
      },
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape,y_train.shape)"
      ],
      "metadata": {
        "id": "QG5MeNZQXLuv",
        "outputId": "5a780e71-e0e9-431c-c40e-79abd582b479",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([134, 2]) torch.Size([134])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get instance of perceptron model\n",
        "model = MLP()\n",
        "\n",
        "#define loss function\n",
        "criterion = torch.nn.BCELoss()\n",
        "\n",
        "#define optimizer -> SGD with learning rate lr\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)"
      ],
      "metadata": {
        "id": "pDx8cyyzWhEB"
      },
      "execution_count": 280,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show model\n",
        "print(model)"
      ],
      "metadata": {
        "id": "bx3Btm46Ymq6",
        "outputId": "79edb641-fa09-4bc3-f122-295382cbf467",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (fc1): Linear(in_features=2, out_features=4, bias=False)\n",
            "  (fc2): Linear(in_features=4, out_features=1, bias=True)\n",
            "  (non_linear): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train() #set to train mode\n",
        "iterations = 5000\n",
        "for iter in range(iterations):\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    y_pred = model(x_train)\n",
        "    # Compute Loss\n",
        "    loss = criterion(y_pred.squeeze(), y_train)\n",
        "\n",
        "    print('Iter {}: train loss: {}'.format(iter, loss.item()))\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    #make gradient update\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "sYbJhiT3Wvgf",
        "outputId": "9295f2d7-8362-4c30-daf3-fbf950ac4373",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 0: train loss: 0.7262821793556213\n",
            "Iter 1: train loss: 0.7234851717948914\n",
            "Iter 2: train loss: 0.7209308743476868\n",
            "Iter 3: train loss: 0.718599259853363\n",
            "Iter 4: train loss: 0.7164716124534607\n",
            "Iter 5: train loss: 0.7145308256149292\n",
            "Iter 6: train loss: 0.7127610445022583\n",
            "Iter 7: train loss: 0.7111476063728333\n",
            "Iter 8: train loss: 0.7096769213676453\n",
            "Iter 9: train loss: 0.7083368897438049\n",
            "Iter 10: train loss: 0.7071160078048706\n",
            "Iter 11: train loss: 0.7060039639472961\n",
            "Iter 12: train loss: 0.7049910426139832\n",
            "Iter 13: train loss: 0.7040687203407288\n",
            "Iter 14: train loss: 0.7032288908958435\n",
            "Iter 15: train loss: 0.7024642825126648\n",
            "Iter 16: train loss: 0.7017682194709778\n",
            "Iter 17: train loss: 0.701134443283081\n",
            "Iter 18: train loss: 0.7005575895309448\n",
            "Iter 19: train loss: 0.7000325918197632\n",
            "Iter 20: train loss: 0.6995546221733093\n",
            "Iter 21: train loss: 0.6991196274757385\n",
            "Iter 22: train loss: 0.6987236738204956\n",
            "Iter 23: train loss: 0.698363184928894\n",
            "Iter 24: train loss: 0.6980350017547607\n",
            "Iter 25: train loss: 0.6977363228797913\n",
            "Iter 26: train loss: 0.6974644064903259\n",
            "Iter 27: train loss: 0.6972166895866394\n",
            "Iter 28: train loss: 0.6969913244247437\n",
            "Iter 29: train loss: 0.6967859268188477\n",
            "Iter 30: train loss: 0.6965988278388977\n",
            "Iter 31: train loss: 0.6964285373687744\n",
            "Iter 32: train loss: 0.6962733268737793\n",
            "Iter 33: train loss: 0.6961319446563721\n",
            "Iter 34: train loss: 0.6960030198097229\n",
            "Iter 35: train loss: 0.6958854794502258\n",
            "Iter 36: train loss: 0.6957782506942749\n",
            "Iter 37: train loss: 0.6956804990768433\n",
            "Iter 38: train loss: 0.6955912113189697\n",
            "Iter 39: train loss: 0.6955098509788513\n",
            "Iter 40: train loss: 0.6954354643821716\n",
            "Iter 41: train loss: 0.6953676342964172\n",
            "Iter 42: train loss: 0.6953054666519165\n",
            "Iter 43: train loss: 0.6952487826347351\n",
            "Iter 44: train loss: 0.695196807384491\n",
            "Iter 45: train loss: 0.695149302482605\n",
            "Iter 46: train loss: 0.695105791091919\n",
            "Iter 47: train loss: 0.6950658559799194\n",
            "Iter 48: train loss: 0.6950291991233826\n",
            "Iter 49: train loss: 0.694995641708374\n",
            "Iter 50: train loss: 0.6949647665023804\n",
            "Iter 51: train loss: 0.6949364542961121\n",
            "Iter 52: train loss: 0.6949101686477661\n",
            "Iter 53: train loss: 0.6948861479759216\n",
            "Iter 54: train loss: 0.6948639750480652\n",
            "Iter 55: train loss: 0.6948434114456177\n",
            "Iter 56: train loss: 0.6948245167732239\n",
            "Iter 57: train loss: 0.6948068737983704\n",
            "Iter 58: train loss: 0.6947906017303467\n",
            "Iter 59: train loss: 0.6947754621505737\n",
            "Iter 60: train loss: 0.6947613954544067\n",
            "Iter 61: train loss: 0.6947481632232666\n",
            "Iter 62: train loss: 0.6947359442710876\n",
            "Iter 63: train loss: 0.6947245001792908\n",
            "Iter 64: train loss: 0.6947138905525208\n",
            "Iter 65: train loss: 0.6947038769721985\n",
            "Iter 66: train loss: 0.6946942806243896\n",
            "Iter 67: train loss: 0.6946853399276733\n",
            "Iter 68: train loss: 0.6946768760681152\n",
            "Iter 69: train loss: 0.6946689486503601\n",
            "Iter 70: train loss: 0.6946613788604736\n",
            "Iter 71: train loss: 0.694654107093811\n",
            "Iter 72: train loss: 0.6946472525596619\n",
            "Iter 73: train loss: 0.6946406960487366\n",
            "Iter 74: train loss: 0.6946344971656799\n",
            "Iter 75: train loss: 0.6946284770965576\n",
            "Iter 76: train loss: 0.6946226358413696\n",
            "Iter 77: train loss: 0.6946170926094055\n",
            "Iter 78: train loss: 0.6946117281913757\n",
            "Iter 79: train loss: 0.6946064829826355\n",
            "Iter 80: train loss: 0.6946014761924744\n",
            "Iter 81: train loss: 0.6945966482162476\n",
            "Iter 82: train loss: 0.6945918202400208\n",
            "Iter 83: train loss: 0.6945871710777283\n",
            "Iter 84: train loss: 0.6945826411247253\n",
            "Iter 85: train loss: 0.694578230381012\n",
            "Iter 86: train loss: 0.6945739388465881\n",
            "Iter 87: train loss: 0.6945697069168091\n",
            "Iter 88: train loss: 0.6945655345916748\n",
            "Iter 89: train loss: 0.6945614814758301\n",
            "Iter 90: train loss: 0.6945574283599854\n",
            "Iter 91: train loss: 0.6945534944534302\n",
            "Iter 92: train loss: 0.6945496797561646\n",
            "Iter 93: train loss: 0.6945457458496094\n",
            "Iter 94: train loss: 0.6945419907569885\n",
            "Iter 95: train loss: 0.6945381760597229\n",
            "Iter 96: train loss: 0.694534420967102\n",
            "Iter 97: train loss: 0.6945308446884155\n",
            "Iter 98: train loss: 0.6945272088050842\n",
            "Iter 99: train loss: 0.6945235133171082\n",
            "Iter 100: train loss: 0.6945199370384216\n",
            "Iter 101: train loss: 0.6945163607597351\n",
            "Iter 102: train loss: 0.6945128440856934\n",
            "Iter 103: train loss: 0.6945093274116516\n",
            "Iter 104: train loss: 0.6945058107376099\n",
            "Iter 105: train loss: 0.6945023536682129\n",
            "Iter 106: train loss: 0.6944988965988159\n",
            "Iter 107: train loss: 0.6944953799247742\n",
            "Iter 108: train loss: 0.6944921016693115\n",
            "Iter 109: train loss: 0.6944885849952698\n",
            "Iter 110: train loss: 0.6944853067398071\n",
            "Iter 111: train loss: 0.6944818496704102\n",
            "Iter 112: train loss: 0.6944785118103027\n",
            "Iter 113: train loss: 0.6944751739501953\n",
            "Iter 114: train loss: 0.6944718360900879\n",
            "Iter 115: train loss: 0.6944684982299805\n",
            "Iter 116: train loss: 0.694465160369873\n",
            "Iter 117: train loss: 0.6944619417190552\n",
            "Iter 118: train loss: 0.6944586634635925\n",
            "Iter 119: train loss: 0.6944553256034851\n",
            "Iter 120: train loss: 0.6944521069526672\n",
            "Iter 121: train loss: 0.6944487690925598\n",
            "Iter 122: train loss: 0.6944455504417419\n",
            "Iter 123: train loss: 0.6944422721862793\n",
            "Iter 124: train loss: 0.6944390535354614\n",
            "Iter 125: train loss: 0.6944357752799988\n",
            "Iter 126: train loss: 0.6944325566291809\n",
            "Iter 127: train loss: 0.6944293975830078\n",
            "Iter 128: train loss: 0.6944261193275452\n",
            "Iter 129: train loss: 0.6944229602813721\n",
            "Iter 130: train loss: 0.6944197416305542\n",
            "Iter 131: train loss: 0.6944165825843811\n",
            "Iter 132: train loss: 0.6944133639335632\n",
            "Iter 133: train loss: 0.6944102048873901\n",
            "Iter 134: train loss: 0.694407045841217\n",
            "Iter 135: train loss: 0.6944038271903992\n",
            "Iter 136: train loss: 0.6944006085395813\n",
            "Iter 137: train loss: 0.6943975687026978\n",
            "Iter 138: train loss: 0.6943944096565247\n",
            "Iter 139: train loss: 0.6943912506103516\n",
            "Iter 140: train loss: 0.6943880319595337\n",
            "Iter 141: train loss: 0.6943849921226501\n",
            "Iter 142: train loss: 0.694381833076477\n",
            "Iter 143: train loss: 0.6943787336349487\n",
            "Iter 144: train loss: 0.6943755745887756\n",
            "Iter 145: train loss: 0.6943724751472473\n",
            "Iter 146: train loss: 0.6943694353103638\n",
            "Iter 147: train loss: 0.6943663358688354\n",
            "Iter 148: train loss: 0.6943632364273071\n",
            "Iter 149: train loss: 0.6943601965904236\n",
            "Iter 150: train loss: 0.6943569779396057\n",
            "Iter 151: train loss: 0.6943539381027222\n",
            "Iter 152: train loss: 0.6943507790565491\n",
            "Iter 153: train loss: 0.6943477988243103\n",
            "Iter 154: train loss: 0.6943447589874268\n",
            "Iter 155: train loss: 0.6943417191505432\n",
            "Iter 156: train loss: 0.6943386197090149\n",
            "Iter 157: train loss: 0.6943355202674866\n",
            "Iter 158: train loss: 0.6943325996398926\n",
            "Iter 159: train loss: 0.694329559803009\n",
            "Iter 160: train loss: 0.6943264603614807\n",
            "Iter 161: train loss: 0.6943234801292419\n",
            "Iter 162: train loss: 0.6943204402923584\n",
            "Iter 163: train loss: 0.6943175196647644\n",
            "Iter 164: train loss: 0.6943144798278809\n",
            "Iter 165: train loss: 0.6943114399909973\n",
            "Iter 166: train loss: 0.6943084597587585\n",
            "Iter 167: train loss: 0.694305419921875\n",
            "Iter 168: train loss: 0.6943023800849915\n",
            "Iter 169: train loss: 0.6942995190620422\n",
            "Iter 170: train loss: 0.6942964792251587\n",
            "Iter 171: train loss: 0.6942934989929199\n",
            "Iter 172: train loss: 0.6942905187606812\n",
            "Iter 173: train loss: 0.6942875385284424\n",
            "Iter 174: train loss: 0.6942845582962036\n",
            "Iter 175: train loss: 0.6942816376686096\n",
            "Iter 176: train loss: 0.6942786574363708\n",
            "Iter 177: train loss: 0.6942756772041321\n",
            "Iter 178: train loss: 0.6942728161811829\n",
            "Iter 179: train loss: 0.6942698359489441\n",
            "Iter 180: train loss: 0.6942669153213501\n",
            "Iter 181: train loss: 0.6942639946937561\n",
            "Iter 182: train loss: 0.6942610144615173\n",
            "Iter 183: train loss: 0.6942581534385681\n",
            "Iter 184: train loss: 0.6942551732063293\n",
            "Iter 185: train loss: 0.6942522525787354\n",
            "Iter 186: train loss: 0.6942493915557861\n",
            "Iter 187: train loss: 0.6942464709281921\n",
            "Iter 188: train loss: 0.6942436099052429\n",
            "Iter 189: train loss: 0.6942407488822937\n",
            "Iter 190: train loss: 0.6942378282546997\n",
            "Iter 191: train loss: 0.6942349672317505\n",
            "Iter 192: train loss: 0.6942321062088013\n",
            "Iter 193: train loss: 0.694229245185852\n",
            "Iter 194: train loss: 0.6942263245582581\n",
            "Iter 195: train loss: 0.6942234635353088\n",
            "Iter 196: train loss: 0.6942206621170044\n",
            "Iter 197: train loss: 0.6942178010940552\n",
            "Iter 198: train loss: 0.6942148804664612\n",
            "Iter 199: train loss: 0.694212019443512\n",
            "Iter 200: train loss: 0.6942092180252075\n",
            "Iter 201: train loss: 0.6942063570022583\n",
            "Iter 202: train loss: 0.6942034959793091\n",
            "Iter 203: train loss: 0.6942006349563599\n",
            "Iter 204: train loss: 0.694197952747345\n",
            "Iter 205: train loss: 0.6941950917243958\n",
            "Iter 206: train loss: 0.6941922307014465\n",
            "Iter 207: train loss: 0.6941894292831421\n",
            "Iter 208: train loss: 0.6941865682601929\n",
            "Iter 209: train loss: 0.694183886051178\n",
            "Iter 210: train loss: 0.6941810846328735\n",
            "Iter 211: train loss: 0.6941781640052795\n",
            "Iter 212: train loss: 0.6941754221916199\n",
            "Iter 213: train loss: 0.6941726207733154\n",
            "Iter 214: train loss: 0.6941699385643005\n",
            "Iter 215: train loss: 0.6941670775413513\n",
            "Iter 216: train loss: 0.6941642761230469\n",
            "Iter 217: train loss: 0.6941615343093872\n",
            "Iter 218: train loss: 0.6941587328910828\n",
            "Iter 219: train loss: 0.6941559910774231\n",
            "Iter 220: train loss: 0.6941533088684082\n",
            "Iter 221: train loss: 0.6941505074501038\n",
            "Iter 222: train loss: 0.6941478252410889\n",
            "Iter 223: train loss: 0.6941450238227844\n",
            "Iter 224: train loss: 0.69414222240448\n",
            "Iter 225: train loss: 0.6941395401954651\n",
            "Iter 226: train loss: 0.6941368579864502\n",
            "Iter 227: train loss: 0.6941340565681458\n",
            "Iter 228: train loss: 0.6941313743591309\n",
            "Iter 229: train loss: 0.6941286325454712\n",
            "Iter 230: train loss: 0.6941258311271667\n",
            "Iter 231: train loss: 0.6941231489181519\n",
            "Iter 232: train loss: 0.6941204071044922\n",
            "Iter 233: train loss: 0.6941177845001221\n",
            "Iter 234: train loss: 0.6941151022911072\n",
            "Iter 235: train loss: 0.6941123008728027\n",
            "Iter 236: train loss: 0.6941096186637878\n",
            "Iter 237: train loss: 0.694106936454773\n",
            "Iter 238: train loss: 0.6941043138504028\n",
            "Iter 239: train loss: 0.6941016316413879\n",
            "Iter 240: train loss: 0.6940988898277283\n",
            "Iter 241: train loss: 0.6940962672233582\n",
            "Iter 242: train loss: 0.6940935254096985\n",
            "Iter 243: train loss: 0.6940909624099731\n",
            "Iter 244: train loss: 0.6940882802009583\n",
            "Iter 245: train loss: 0.6940855979919434\n",
            "Iter 246: train loss: 0.6940829157829285\n",
            "Iter 247: train loss: 0.6940802335739136\n",
            "Iter 248: train loss: 0.6940776705741882\n",
            "Iter 249: train loss: 0.6940749287605286\n",
            "Iter 250: train loss: 0.6940723657608032\n",
            "Iter 251: train loss: 0.6940697431564331\n",
            "Iter 252: train loss: 0.6940670609474182\n",
            "Iter 253: train loss: 0.6940644383430481\n",
            "Iter 254: train loss: 0.694061815738678\n",
            "Iter 255: train loss: 0.6940592527389526\n",
            "Iter 256: train loss: 0.6940565705299377\n",
            "Iter 257: train loss: 0.6940540075302124\n",
            "Iter 258: train loss: 0.6940513849258423\n",
            "Iter 259: train loss: 0.6940487623214722\n",
            "Iter 260: train loss: 0.694046139717102\n",
            "Iter 261: train loss: 0.6940435767173767\n",
            "Iter 262: train loss: 0.6940409541130066\n",
            "Iter 263: train loss: 0.6940383911132812\n",
            "Iter 264: train loss: 0.6940357685089111\n",
            "Iter 265: train loss: 0.6940332055091858\n",
            "Iter 266: train loss: 0.6940306425094604\n",
            "Iter 267: train loss: 0.6940280199050903\n",
            "Iter 268: train loss: 0.694025456905365\n",
            "Iter 269: train loss: 0.6940228343009949\n",
            "Iter 270: train loss: 0.6940203309059143\n",
            "Iter 271: train loss: 0.6940177083015442\n",
            "Iter 272: train loss: 0.6940152645111084\n",
            "Iter 273: train loss: 0.6940126419067383\n",
            "Iter 274: train loss: 0.6940100193023682\n",
            "Iter 275: train loss: 0.6940075159072876\n",
            "Iter 276: train loss: 0.6940049529075623\n",
            "Iter 277: train loss: 0.6940024495124817\n",
            "Iter 278: train loss: 0.6939998865127563\n",
            "Iter 279: train loss: 0.6939973831176758\n",
            "Iter 280: train loss: 0.6939947605133057\n",
            "Iter 281: train loss: 0.6939922571182251\n",
            "Iter 282: train loss: 0.6939897537231445\n",
            "Iter 283: train loss: 0.693987250328064\n",
            "Iter 284: train loss: 0.6939846873283386\n",
            "Iter 285: train loss: 0.6939821839332581\n",
            "Iter 286: train loss: 0.6939796805381775\n",
            "Iter 287: train loss: 0.6939771771430969\n",
            "Iter 288: train loss: 0.6939746737480164\n",
            "Iter 289: train loss: 0.6939721703529358\n",
            "Iter 290: train loss: 0.6939696073532104\n",
            "Iter 291: train loss: 0.6939671635627747\n",
            "Iter 292: train loss: 0.6939647197723389\n",
            "Iter 293: train loss: 0.6939622163772583\n",
            "Iter 294: train loss: 0.6939597129821777\n",
            "Iter 295: train loss: 0.6939572095870972\n",
            "Iter 296: train loss: 0.6939547657966614\n",
            "Iter 297: train loss: 0.6939522624015808\n",
            "Iter 298: train loss: 0.693949818611145\n",
            "Iter 299: train loss: 0.6939473748207092\n",
            "Iter 300: train loss: 0.6939448714256287\n",
            "Iter 301: train loss: 0.6939424276351929\n",
            "Iter 302: train loss: 0.6939398646354675\n",
            "Iter 303: train loss: 0.6939374208450317\n",
            "Iter 304: train loss: 0.693934977054596\n",
            "Iter 305: train loss: 0.6939325332641602\n",
            "Iter 306: train loss: 0.6939300894737244\n",
            "Iter 307: train loss: 0.6939276456832886\n",
            "Iter 308: train loss: 0.6939252018928528\n",
            "Iter 309: train loss: 0.6939228177070618\n",
            "Iter 310: train loss: 0.693920373916626\n",
            "Iter 311: train loss: 0.6939178705215454\n",
            "Iter 312: train loss: 0.6939155459403992\n",
            "Iter 313: train loss: 0.6939131021499634\n",
            "Iter 314: train loss: 0.6939105987548828\n",
            "Iter 315: train loss: 0.6939082145690918\n",
            "Iter 316: train loss: 0.693905770778656\n",
            "Iter 317: train loss: 0.693903386592865\n",
            "Iter 318: train loss: 0.693901002407074\n",
            "Iter 319: train loss: 0.6938984990119934\n",
            "Iter 320: train loss: 0.6938962340354919\n",
            "Iter 321: train loss: 0.6938937902450562\n",
            "Iter 322: train loss: 0.6938912868499756\n",
            "Iter 323: train loss: 0.6938889622688293\n",
            "Iter 324: train loss: 0.6938865780830383\n",
            "Iter 325: train loss: 0.6938841342926025\n",
            "Iter 326: train loss: 0.6938818097114563\n",
            "Iter 327: train loss: 0.6938794255256653\n",
            "Iter 328: train loss: 0.6938770413398743\n",
            "Iter 329: train loss: 0.6938746571540833\n",
            "Iter 330: train loss: 0.6938722729682922\n",
            "Iter 331: train loss: 0.6938698887825012\n",
            "Iter 332: train loss: 0.6938674449920654\n",
            "Iter 333: train loss: 0.693865180015564\n",
            "Iter 334: train loss: 0.6938628554344177\n",
            "Iter 335: train loss: 0.6938604712486267\n",
            "Iter 336: train loss: 0.6938580870628357\n",
            "Iter 337: train loss: 0.6938557624816895\n",
            "Iter 338: train loss: 0.6938533782958984\n",
            "Iter 339: train loss: 0.6938510537147522\n",
            "Iter 340: train loss: 0.6938486695289612\n",
            "Iter 341: train loss: 0.6938463449478149\n",
            "Iter 342: train loss: 0.6938439607620239\n",
            "Iter 343: train loss: 0.6938416361808777\n",
            "Iter 344: train loss: 0.6938393712043762\n",
            "Iter 345: train loss: 0.6938369870185852\n",
            "Iter 346: train loss: 0.693834662437439\n",
            "Iter 347: train loss: 0.693832278251648\n",
            "Iter 348: train loss: 0.6938300132751465\n",
            "Iter 349: train loss: 0.6938276886940002\n",
            "Iter 350: train loss: 0.693825364112854\n",
            "Iter 351: train loss: 0.693822979927063\n",
            "Iter 352: train loss: 0.6938206553459167\n",
            "Iter 353: train loss: 0.6938183903694153\n",
            "Iter 354: train loss: 0.6938161253929138\n",
            "Iter 355: train loss: 0.6938138604164124\n",
            "Iter 356: train loss: 0.6938115358352661\n",
            "Iter 357: train loss: 0.6938091516494751\n",
            "Iter 358: train loss: 0.6938068866729736\n",
            "Iter 359: train loss: 0.6938046216964722\n",
            "Iter 360: train loss: 0.6938023567199707\n",
            "Iter 361: train loss: 0.6938000321388245\n",
            "Iter 362: train loss: 0.693797767162323\n",
            "Iter 363: train loss: 0.6937955021858215\n",
            "Iter 364: train loss: 0.6937931776046753\n",
            "Iter 365: train loss: 0.693790853023529\n",
            "Iter 366: train loss: 0.6937885284423828\n",
            "Iter 367: train loss: 0.6937862634658813\n",
            "Iter 368: train loss: 0.6937840580940247\n",
            "Iter 369: train loss: 0.6937817931175232\n",
            "Iter 370: train loss: 0.6937795877456665\n",
            "Iter 371: train loss: 0.6937772631645203\n",
            "Iter 372: train loss: 0.6937750577926636\n",
            "Iter 373: train loss: 0.6937727928161621\n",
            "Iter 374: train loss: 0.6937705278396606\n",
            "Iter 375: train loss: 0.6937682628631592\n",
            "Iter 376: train loss: 0.6937659978866577\n",
            "Iter 377: train loss: 0.6937637329101562\n",
            "Iter 378: train loss: 0.6937614679336548\n",
            "Iter 379: train loss: 0.6937592625617981\n",
            "Iter 380: train loss: 0.6937569975852966\n",
            "Iter 381: train loss: 0.6937547326087952\n",
            "Iter 382: train loss: 0.6937525868415833\n",
            "Iter 383: train loss: 0.6937503814697266\n",
            "Iter 384: train loss: 0.6937480568885803\n",
            "Iter 385: train loss: 0.6937458515167236\n",
            "Iter 386: train loss: 0.6937436461448669\n",
            "Iter 387: train loss: 0.6937414407730103\n",
            "Iter 388: train loss: 0.6937391757965088\n",
            "Iter 389: train loss: 0.6937369704246521\n",
            "Iter 390: train loss: 0.6937348246574402\n",
            "Iter 391: train loss: 0.6937325596809387\n",
            "Iter 392: train loss: 0.6937302947044373\n",
            "Iter 393: train loss: 0.6937280893325806\n",
            "Iter 394: train loss: 0.6937258839607239\n",
            "Iter 395: train loss: 0.6937236785888672\n",
            "Iter 396: train loss: 0.6937215328216553\n",
            "Iter 397: train loss: 0.6937193274497986\n",
            "Iter 398: train loss: 0.6937171816825867\n",
            "Iter 399: train loss: 0.69371497631073\n",
            "Iter 400: train loss: 0.6937127113342285\n",
            "Iter 401: train loss: 0.6937105059623718\n",
            "Iter 402: train loss: 0.6937083005905151\n",
            "Iter 403: train loss: 0.6937061548233032\n",
            "Iter 404: train loss: 0.6937040090560913\n",
            "Iter 405: train loss: 0.6937018036842346\n",
            "Iter 406: train loss: 0.6936996579170227\n",
            "Iter 407: train loss: 0.693697452545166\n",
            "Iter 408: train loss: 0.6936952471733093\n",
            "Iter 409: train loss: 0.6936931610107422\n",
            "Iter 410: train loss: 0.6936908960342407\n",
            "Iter 411: train loss: 0.6936887502670288\n",
            "Iter 412: train loss: 0.6936866044998169\n",
            "Iter 413: train loss: 0.6936843991279602\n",
            "Iter 414: train loss: 0.6936823129653931\n",
            "Iter 415: train loss: 0.6936801671981812\n",
            "Iter 416: train loss: 0.6936779618263245\n",
            "Iter 417: train loss: 0.6936758160591125\n",
            "Iter 418: train loss: 0.6936736702919006\n",
            "Iter 419: train loss: 0.6936715245246887\n",
            "Iter 420: train loss: 0.693669319152832\n",
            "Iter 421: train loss: 0.6936672925949097\n",
            "Iter 422: train loss: 0.6936651468276978\n",
            "Iter 423: train loss: 0.6936629414558411\n",
            "Iter 424: train loss: 0.6936607956886292\n",
            "Iter 425: train loss: 0.693658709526062\n",
            "Iter 426: train loss: 0.6936565041542053\n",
            "Iter 427: train loss: 0.693654477596283\n",
            "Iter 428: train loss: 0.693652331829071\n",
            "Iter 429: train loss: 0.6936502456665039\n",
            "Iter 430: train loss: 0.6936480402946472\n",
            "Iter 431: train loss: 0.6936460137367249\n",
            "Iter 432: train loss: 0.6936438083648682\n",
            "Iter 433: train loss: 0.6936416625976562\n",
            "Iter 434: train loss: 0.6936396360397339\n",
            "Iter 435: train loss: 0.6936374306678772\n",
            "Iter 436: train loss: 0.6936354041099548\n",
            "Iter 437: train loss: 0.6936333179473877\n",
            "Iter 438: train loss: 0.693631112575531\n",
            "Iter 439: train loss: 0.6936290264129639\n",
            "Iter 440: train loss: 0.6936269998550415\n",
            "Iter 441: train loss: 0.6936247944831848\n",
            "Iter 442: train loss: 0.6936227083206177\n",
            "Iter 443: train loss: 0.6936206817626953\n",
            "Iter 444: train loss: 0.6936184763908386\n",
            "Iter 445: train loss: 0.6936164498329163\n",
            "Iter 446: train loss: 0.6936143636703491\n",
            "Iter 447: train loss: 0.6936122179031372\n",
            "Iter 448: train loss: 0.6936101913452148\n",
            "Iter 449: train loss: 0.6936080455780029\n",
            "Iter 450: train loss: 0.6936060786247253\n",
            "Iter 451: train loss: 0.6936039328575134\n",
            "Iter 452: train loss: 0.6936018466949463\n",
            "Iter 453: train loss: 0.6935998201370239\n",
            "Iter 454: train loss: 0.6935977339744568\n",
            "Iter 455: train loss: 0.6935955882072449\n",
            "Iter 456: train loss: 0.6935935616493225\n",
            "Iter 457: train loss: 0.6935914158821106\n",
            "Iter 458: train loss: 0.693589448928833\n",
            "Iter 459: train loss: 0.6935873627662659\n",
            "Iter 460: train loss: 0.6935852766036987\n",
            "Iter 461: train loss: 0.6935832500457764\n",
            "Iter 462: train loss: 0.693581223487854\n",
            "Iter 463: train loss: 0.6935790777206421\n",
            "Iter 464: train loss: 0.6935771107673645\n",
            "Iter 465: train loss: 0.6935750246047974\n",
            "Iter 466: train loss: 0.693572998046875\n",
            "Iter 467: train loss: 0.6935709714889526\n",
            "Iter 468: train loss: 0.6935688257217407\n",
            "Iter 469: train loss: 0.6935668587684631\n",
            "Iter 470: train loss: 0.693564772605896\n",
            "Iter 471: train loss: 0.6935627460479736\n",
            "Iter 472: train loss: 0.6935607194900513\n",
            "Iter 473: train loss: 0.6935586333274841\n",
            "Iter 474: train loss: 0.6935566067695618\n",
            "Iter 475: train loss: 0.6935545802116394\n",
            "Iter 476: train loss: 0.6935526132583618\n",
            "Iter 477: train loss: 0.6935505270957947\n",
            "Iter 478: train loss: 0.6935485601425171\n",
            "Iter 479: train loss: 0.69354647397995\n",
            "Iter 480: train loss: 0.6935443878173828\n",
            "Iter 481: train loss: 0.6935424208641052\n",
            "Iter 482: train loss: 0.6935404539108276\n",
            "Iter 483: train loss: 0.6935383677482605\n",
            "Iter 484: train loss: 0.6935364007949829\n",
            "Iter 485: train loss: 0.6935343146324158\n",
            "Iter 486: train loss: 0.6935323476791382\n",
            "Iter 487: train loss: 0.6935303211212158\n",
            "Iter 488: train loss: 0.6935282945632935\n",
            "Iter 489: train loss: 0.6935263276100159\n",
            "Iter 490: train loss: 0.6935242414474487\n",
            "Iter 491: train loss: 0.6935222744941711\n",
            "Iter 492: train loss: 0.6935203075408936\n",
            "Iter 493: train loss: 0.6935182809829712\n",
            "Iter 494: train loss: 0.6935163140296936\n",
            "Iter 495: train loss: 0.6935142874717712\n",
            "Iter 496: train loss: 0.6935123205184937\n",
            "Iter 497: train loss: 0.6935102939605713\n",
            "Iter 498: train loss: 0.6935083270072937\n",
            "Iter 499: train loss: 0.6935063004493713\n",
            "Iter 500: train loss: 0.6935043334960938\n",
            "Iter 501: train loss: 0.6935023665428162\n",
            "Iter 502: train loss: 0.6935003399848938\n",
            "Iter 503: train loss: 0.693498432636261\n",
            "Iter 504: train loss: 0.6934963464736938\n",
            "Iter 505: train loss: 0.693494439125061\n",
            "Iter 506: train loss: 0.6934923529624939\n",
            "Iter 507: train loss: 0.6934905052185059\n",
            "Iter 508: train loss: 0.6934884190559387\n",
            "Iter 509: train loss: 0.6934865117073059\n",
            "Iter 510: train loss: 0.6934846043586731\n",
            "Iter 511: train loss: 0.6934825778007507\n",
            "Iter 512: train loss: 0.6934805512428284\n",
            "Iter 513: train loss: 0.6934786438941956\n",
            "Iter 514: train loss: 0.693476676940918\n",
            "Iter 515: train loss: 0.6934747099876404\n",
            "Iter 516: train loss: 0.693472683429718\n",
            "Iter 517: train loss: 0.6934707164764404\n",
            "Iter 518: train loss: 0.6934688687324524\n",
            "Iter 519: train loss: 0.69346684217453\n",
            "Iter 520: train loss: 0.6934648752212524\n",
            "Iter 521: train loss: 0.6934630274772644\n",
            "Iter 522: train loss: 0.693461000919342\n",
            "Iter 523: train loss: 0.6934590935707092\n",
            "Iter 524: train loss: 0.6934571266174316\n",
            "Iter 525: train loss: 0.6934551000595093\n",
            "Iter 526: train loss: 0.6934531927108765\n",
            "Iter 527: train loss: 0.6934513449668884\n",
            "Iter 528: train loss: 0.6934492588043213\n",
            "Iter 529: train loss: 0.6934473514556885\n",
            "Iter 530: train loss: 0.6934453845024109\n",
            "Iter 531: train loss: 0.6934435367584229\n",
            "Iter 532: train loss: 0.6934415102005005\n",
            "Iter 533: train loss: 0.6934396624565125\n",
            "Iter 534: train loss: 0.6934376955032349\n",
            "Iter 535: train loss: 0.6934356689453125\n",
            "Iter 536: train loss: 0.6934337615966797\n",
            "Iter 537: train loss: 0.6934319734573364\n",
            "Iter 538: train loss: 0.6934299468994141\n",
            "Iter 539: train loss: 0.6934279799461365\n",
            "Iter 540: train loss: 0.6934261322021484\n",
            "Iter 541: train loss: 0.6934241652488708\n",
            "Iter 542: train loss: 0.6934223175048828\n",
            "Iter 543: train loss: 0.69342041015625\n",
            "Iter 544: train loss: 0.6934184432029724\n",
            "Iter 545: train loss: 0.6934165358543396\n",
            "Iter 546: train loss: 0.6934146285057068\n",
            "Iter 547: train loss: 0.6934126615524292\n",
            "Iter 548: train loss: 0.6934107542037964\n",
            "Iter 549: train loss: 0.6934089064598083\n",
            "Iter 550: train loss: 0.6934069395065308\n",
            "Iter 551: train loss: 0.693405032157898\n",
            "Iter 552: train loss: 0.6934031844139099\n",
            "Iter 553: train loss: 0.6934012174606323\n",
            "Iter 554: train loss: 0.6933993697166443\n",
            "Iter 555: train loss: 0.6933974027633667\n",
            "Iter 556: train loss: 0.6933956146240234\n",
            "Iter 557: train loss: 0.6933935880661011\n",
            "Iter 558: train loss: 0.693391740322113\n",
            "Iter 559: train loss: 0.6933897733688354\n",
            "Iter 560: train loss: 0.6933879852294922\n",
            "Iter 561: train loss: 0.6933860182762146\n",
            "Iter 562: train loss: 0.6933841705322266\n",
            "Iter 563: train loss: 0.6933822631835938\n",
            "Iter 564: train loss: 0.6933803558349609\n",
            "Iter 565: train loss: 0.6933784484863281\n",
            "Iter 566: train loss: 0.6933765411376953\n",
            "Iter 567: train loss: 0.693374752998352\n",
            "Iter 568: train loss: 0.6933727860450745\n",
            "Iter 569: train loss: 0.6933709383010864\n",
            "Iter 570: train loss: 0.6933690905570984\n",
            "Iter 571: train loss: 0.6933672428131104\n",
            "Iter 572: train loss: 0.6933652758598328\n",
            "Iter 573: train loss: 0.6933634281158447\n",
            "Iter 574: train loss: 0.6933615207672119\n",
            "Iter 575: train loss: 0.6933597326278687\n",
            "Iter 576: train loss: 0.6933577656745911\n",
            "Iter 577: train loss: 0.693355917930603\n",
            "Iter 578: train loss: 0.6933540105819702\n",
            "Iter 579: train loss: 0.693352222442627\n",
            "Iter 580: train loss: 0.6933503150939941\n",
            "Iter 581: train loss: 0.6933485269546509\n",
            "Iter 582: train loss: 0.6933466196060181\n",
            "Iter 583: train loss: 0.69334477186203\n",
            "Iter 584: train loss: 0.6933428645133972\n",
            "Iter 585: train loss: 0.6933410167694092\n",
            "Iter 586: train loss: 0.6933391690254211\n",
            "Iter 587: train loss: 0.6933372616767883\n",
            "Iter 588: train loss: 0.6933354139328003\n",
            "Iter 589: train loss: 0.6933335661888123\n",
            "Iter 590: train loss: 0.6933317184448242\n",
            "Iter 591: train loss: 0.6933298707008362\n",
            "Iter 592: train loss: 0.6933280229568481\n",
            "Iter 593: train loss: 0.6933261752128601\n",
            "Iter 594: train loss: 0.6933243870735168\n",
            "Iter 595: train loss: 0.6933225393295288\n",
            "Iter 596: train loss: 0.6933205723762512\n",
            "Iter 597: train loss: 0.693318784236908\n",
            "Iter 598: train loss: 0.6933168768882751\n",
            "Iter 599: train loss: 0.6933150887489319\n",
            "Iter 600: train loss: 0.6933132410049438\n",
            "Iter 601: train loss: 0.6933114528656006\n",
            "Iter 602: train loss: 0.693309485912323\n",
            "Iter 603: train loss: 0.6933076977729797\n",
            "Iter 604: train loss: 0.6933059096336365\n",
            "Iter 605: train loss: 0.6933040618896484\n",
            "Iter 606: train loss: 0.6933022141456604\n",
            "Iter 607: train loss: 0.6933003067970276\n",
            "Iter 608: train loss: 0.6932985782623291\n",
            "Iter 609: train loss: 0.6932967305183411\n",
            "Iter 610: train loss: 0.693294882774353\n",
            "Iter 611: train loss: 0.6932930946350098\n",
            "Iter 612: train loss: 0.6932913064956665\n",
            "Iter 613: train loss: 0.6932894587516785\n",
            "Iter 614: train loss: 0.6932875514030457\n",
            "Iter 615: train loss: 0.6932858228683472\n",
            "Iter 616: train loss: 0.6932839155197144\n",
            "Iter 617: train loss: 0.6932820677757263\n",
            "Iter 618: train loss: 0.6932802200317383\n",
            "Iter 619: train loss: 0.6932784914970398\n",
            "Iter 620: train loss: 0.6932766437530518\n",
            "Iter 621: train loss: 0.6932748556137085\n",
            "Iter 622: train loss: 0.6932730078697205\n",
            "Iter 623: train loss: 0.6932712197303772\n",
            "Iter 624: train loss: 0.6932694315910339\n",
            "Iter 625: train loss: 0.6932675838470459\n",
            "Iter 626: train loss: 0.6932658553123474\n",
            "Iter 627: train loss: 0.6932639479637146\n",
            "Iter 628: train loss: 0.6932621002197266\n",
            "Iter 629: train loss: 0.6932603716850281\n",
            "Iter 630: train loss: 0.69325852394104\n",
            "Iter 631: train loss: 0.6932567954063416\n",
            "Iter 632: train loss: 0.6932548880577087\n",
            "Iter 633: train loss: 0.6932531595230103\n",
            "Iter 634: train loss: 0.693251371383667\n",
            "Iter 635: train loss: 0.693249523639679\n",
            "Iter 636: train loss: 0.6932477355003357\n",
            "Iter 637: train loss: 0.6932458877563477\n",
            "Iter 638: train loss: 0.6932441592216492\n",
            "Iter 639: train loss: 0.6932423114776611\n",
            "Iter 640: train loss: 0.6932405233383179\n",
            "Iter 641: train loss: 0.6932387351989746\n",
            "Iter 642: train loss: 0.6932368874549866\n",
            "Iter 643: train loss: 0.6932351589202881\n",
            "Iter 644: train loss: 0.6932333111763\n",
            "Iter 645: train loss: 0.6932315826416016\n",
            "Iter 646: train loss: 0.6932297945022583\n",
            "Iter 647: train loss: 0.693228006362915\n",
            "Iter 648: train loss: 0.6932262778282166\n",
            "Iter 649: train loss: 0.6932244300842285\n",
            "Iter 650: train loss: 0.6932226419448853\n",
            "Iter 651: train loss: 0.6932209134101868\n",
            "Iter 652: train loss: 0.6932190656661987\n",
            "Iter 653: train loss: 0.6932172775268555\n",
            "Iter 654: train loss: 0.6932154893875122\n",
            "Iter 655: train loss: 0.6932137608528137\n",
            "Iter 656: train loss: 0.6932119131088257\n",
            "Iter 657: train loss: 0.6932101249694824\n",
            "Iter 658: train loss: 0.6932083368301392\n",
            "Iter 659: train loss: 0.6932066082954407\n",
            "Iter 660: train loss: 0.6932048797607422\n",
            "Iter 661: train loss: 0.6932030916213989\n",
            "Iter 662: train loss: 0.6932013630867004\n",
            "Iter 663: train loss: 0.6931995749473572\n",
            "Iter 664: train loss: 0.6931977868080139\n",
            "Iter 665: train loss: 0.6931959986686707\n",
            "Iter 666: train loss: 0.6931942105293274\n",
            "Iter 667: train loss: 0.6931924223899841\n",
            "Iter 668: train loss: 0.6931906342506409\n",
            "Iter 669: train loss: 0.6931889057159424\n",
            "Iter 670: train loss: 0.6931871771812439\n",
            "Iter 671: train loss: 0.6931853890419006\n",
            "Iter 672: train loss: 0.6931836009025574\n",
            "Iter 673: train loss: 0.6931818723678589\n",
            "Iter 674: train loss: 0.6931800842285156\n",
            "Iter 675: train loss: 0.6931784152984619\n",
            "Iter 676: train loss: 0.6931766271591187\n",
            "Iter 677: train loss: 0.6931748986244202\n",
            "Iter 678: train loss: 0.6931731104850769\n",
            "Iter 679: train loss: 0.6931713223457336\n",
            "Iter 680: train loss: 0.6931695342063904\n",
            "Iter 681: train loss: 0.6931678056716919\n",
            "Iter 682: train loss: 0.6931660175323486\n",
            "Iter 683: train loss: 0.6931642889976501\n",
            "Iter 684: train loss: 0.6931626200675964\n",
            "Iter 685: train loss: 0.6931607723236084\n",
            "Iter 686: train loss: 0.6931590437889099\n",
            "Iter 687: train loss: 0.6931572556495667\n",
            "Iter 688: train loss: 0.6931555271148682\n",
            "Iter 689: train loss: 0.6931537985801697\n",
            "Iter 690: train loss: 0.6931520700454712\n",
            "Iter 691: train loss: 0.6931502223014832\n",
            "Iter 692: train loss: 0.6931484937667847\n",
            "Iter 693: train loss: 0.6931467652320862\n",
            "Iter 694: train loss: 0.6931450963020325\n",
            "Iter 695: train loss: 0.693143367767334\n",
            "Iter 696: train loss: 0.693141520023346\n",
            "Iter 697: train loss: 0.6931398510932922\n",
            "Iter 698: train loss: 0.6931381225585938\n",
            "Iter 699: train loss: 0.6931363344192505\n",
            "Iter 700: train loss: 0.693134605884552\n",
            "Iter 701: train loss: 0.6931329369544983\n",
            "Iter 702: train loss: 0.693131148815155\n",
            "Iter 703: train loss: 0.6931294798851013\n",
            "Iter 704: train loss: 0.6931276917457581\n",
            "Iter 705: train loss: 0.6931259632110596\n",
            "Iter 706: train loss: 0.6931241750717163\n",
            "Iter 707: train loss: 0.6931225061416626\n",
            "Iter 708: train loss: 0.6931207776069641\n",
            "Iter 709: train loss: 0.6931190490722656\n",
            "Iter 710: train loss: 0.6931173205375671\n",
            "Iter 711: train loss: 0.6931155920028687\n",
            "Iter 712: train loss: 0.6931138634681702\n",
            "Iter 713: train loss: 0.6931120753288269\n",
            "Iter 714: train loss: 0.693110466003418\n",
            "Iter 715: train loss: 0.6931086182594299\n",
            "Iter 716: train loss: 0.6931069493293762\n",
            "Iter 717: train loss: 0.6931052803993225\n",
            "Iter 718: train loss: 0.6931034326553345\n",
            "Iter 719: train loss: 0.6931018233299255\n",
            "Iter 720: train loss: 0.6931000351905823\n",
            "Iter 721: train loss: 0.6930983662605286\n",
            "Iter 722: train loss: 0.6930966377258301\n",
            "Iter 723: train loss: 0.6930949091911316\n",
            "Iter 724: train loss: 0.6930930614471436\n",
            "Iter 725: train loss: 0.6930915117263794\n",
            "Iter 726: train loss: 0.6930897235870361\n",
            "Iter 727: train loss: 0.6930879950523376\n",
            "Iter 728: train loss: 0.6930863261222839\n",
            "Iter 729: train loss: 0.6930845975875854\n",
            "Iter 730: train loss: 0.6930828094482422\n",
            "Iter 731: train loss: 0.6930812001228333\n",
            "Iter 732: train loss: 0.6930795311927795\n",
            "Iter 733: train loss: 0.6930777430534363\n",
            "Iter 734: train loss: 0.6930760741233826\n",
            "Iter 735: train loss: 0.6930742859840393\n",
            "Iter 736: train loss: 0.6930726170539856\n",
            "Iter 737: train loss: 0.6930709481239319\n",
            "Iter 738: train loss: 0.6930691599845886\n",
            "Iter 739: train loss: 0.6930675506591797\n",
            "Iter 740: train loss: 0.6930657625198364\n",
            "Iter 741: train loss: 0.6930640935897827\n",
            "Iter 742: train loss: 0.6930623054504395\n",
            "Iter 743: train loss: 0.6930606961250305\n",
            "Iter 744: train loss: 0.693058967590332\n",
            "Iter 745: train loss: 0.6930572986602783\n",
            "Iter 746: train loss: 0.6930556297302246\n",
            "Iter 747: train loss: 0.6930537819862366\n",
            "Iter 748: train loss: 0.6930522918701172\n",
            "Iter 749: train loss: 0.6930504441261292\n",
            "Iter 750: train loss: 0.6930487751960754\n",
            "Iter 751: train loss: 0.6930471062660217\n",
            "Iter 752: train loss: 0.6930453777313232\n",
            "Iter 753: train loss: 0.6930437088012695\n",
            "Iter 754: train loss: 0.693041980266571\n",
            "Iter 755: train loss: 0.6930403113365173\n",
            "Iter 756: train loss: 0.6930385828018188\n",
            "Iter 757: train loss: 0.6930369138717651\n",
            "Iter 758: train loss: 0.6930351257324219\n",
            "Iter 759: train loss: 0.6930335164070129\n",
            "Iter 760: train loss: 0.6930318474769592\n",
            "Iter 761: train loss: 0.6930301785469055\n",
            "Iter 762: train loss: 0.6930283904075623\n",
            "Iter 763: train loss: 0.6930267810821533\n",
            "Iter 764: train loss: 0.6930250525474548\n",
            "Iter 765: train loss: 0.6930233240127563\n",
            "Iter 766: train loss: 0.6930217146873474\n",
            "Iter 767: train loss: 0.6930199265480042\n",
            "Iter 768: train loss: 0.6930183172225952\n",
            "Iter 769: train loss: 0.6930166482925415\n",
            "Iter 770: train loss: 0.693014919757843\n",
            "Iter 771: train loss: 0.6930131912231445\n",
            "Iter 772: train loss: 0.6930115818977356\n",
            "Iter 773: train loss: 0.6930099129676819\n",
            "Iter 774: train loss: 0.6930081844329834\n",
            "Iter 775: train loss: 0.6930065155029297\n",
            "Iter 776: train loss: 0.6930047869682312\n",
            "Iter 777: train loss: 0.6930031776428223\n",
            "Iter 778: train loss: 0.6930014491081238\n",
            "Iter 779: train loss: 0.6929997801780701\n",
            "Iter 780: train loss: 0.6929980516433716\n",
            "Iter 781: train loss: 0.6929964423179626\n",
            "Iter 782: train loss: 0.6929947733879089\n",
            "Iter 783: train loss: 0.6929930448532104\n",
            "Iter 784: train loss: 0.6929913759231567\n",
            "Iter 785: train loss: 0.692989706993103\n",
            "Iter 786: train loss: 0.6929880380630493\n",
            "Iter 787: train loss: 0.6929863095283508\n",
            "Iter 788: train loss: 0.6929846405982971\n",
            "Iter 789: train loss: 0.6929830312728882\n",
            "Iter 790: train loss: 0.6929813623428345\n",
            "Iter 791: train loss: 0.6929796934127808\n",
            "Iter 792: train loss: 0.692978024482727\n",
            "Iter 793: train loss: 0.6929764151573181\n",
            "Iter 794: train loss: 0.6929747462272644\n",
            "Iter 795: train loss: 0.6929730176925659\n",
            "Iter 796: train loss: 0.6929712891578674\n",
            "Iter 797: train loss: 0.6929696798324585\n",
            "Iter 798: train loss: 0.6929680109024048\n",
            "Iter 799: train loss: 0.6929662823677063\n",
            "Iter 800: train loss: 0.6929646134376526\n",
            "Iter 801: train loss: 0.6929630041122437\n",
            "Iter 802: train loss: 0.6929613947868347\n",
            "Iter 803: train loss: 0.6929596662521362\n",
            "Iter 804: train loss: 0.6929579973220825\n",
            "Iter 805: train loss: 0.692956268787384\n",
            "Iter 806: train loss: 0.6929545998573303\n",
            "Iter 807: train loss: 0.6929529905319214\n",
            "Iter 808: train loss: 0.6929513812065125\n",
            "Iter 809: train loss: 0.692949652671814\n",
            "Iter 810: train loss: 0.692948043346405\n",
            "Iter 811: train loss: 0.6929463744163513\n",
            "Iter 812: train loss: 0.6929447054862976\n",
            "Iter 813: train loss: 0.6929429769515991\n",
            "Iter 814: train loss: 0.692941427230835\n",
            "Iter 815: train loss: 0.6929396986961365\n",
            "Iter 816: train loss: 0.6929380297660828\n",
            "Iter 817: train loss: 0.692936360836029\n",
            "Iter 818: train loss: 0.6929347515106201\n",
            "Iter 819: train loss: 0.6929330825805664\n",
            "Iter 820: train loss: 0.6929314136505127\n",
            "Iter 821: train loss: 0.6929296851158142\n",
            "Iter 822: train loss: 0.6929280757904053\n",
            "Iter 823: train loss: 0.6929264068603516\n",
            "Iter 824: train loss: 0.6929247379302979\n",
            "Iter 825: train loss: 0.6929230690002441\n",
            "Iter 826: train loss: 0.6929214000701904\n",
            "Iter 827: train loss: 0.6929198503494263\n",
            "Iter 828: train loss: 0.6929181814193726\n",
            "Iter 829: train loss: 0.6929164528846741\n",
            "Iter 830: train loss: 0.6929148435592651\n",
            "Iter 831: train loss: 0.6929132342338562\n",
            "Iter 832: train loss: 0.6929115056991577\n",
            "Iter 833: train loss: 0.6929098963737488\n",
            "Iter 834: train loss: 0.6929082274436951\n",
            "Iter 835: train loss: 0.6929064989089966\n",
            "Iter 836: train loss: 0.6929048895835876\n",
            "Iter 837: train loss: 0.6929033398628235\n",
            "Iter 838: train loss: 0.692901611328125\n",
            "Iter 839: train loss: 0.6929000020027161\n",
            "Iter 840: train loss: 0.6928983330726624\n",
            "Iter 841: train loss: 0.6928967237472534\n",
            "Iter 842: train loss: 0.6928951144218445\n",
            "Iter 843: train loss: 0.6928933262825012\n",
            "Iter 844: train loss: 0.6928918361663818\n",
            "Iter 845: train loss: 0.6928900480270386\n",
            "Iter 846: train loss: 0.6928884387016296\n",
            "Iter 847: train loss: 0.6928868889808655\n",
            "Iter 848: train loss: 0.692885160446167\n",
            "Iter 849: train loss: 0.6928834915161133\n",
            "Iter 850: train loss: 0.6928818821907043\n",
            "Iter 851: train loss: 0.6928802728652954\n",
            "Iter 852: train loss: 0.6928786039352417\n",
            "Iter 853: train loss: 0.6928768754005432\n",
            "Iter 854: train loss: 0.692875325679779\n",
            "Iter 855: train loss: 0.6928736567497253\n",
            "Iter 856: train loss: 0.6928719878196716\n",
            "Iter 857: train loss: 0.6928704380989075\n",
            "Iter 858: train loss: 0.6928688287734985\n",
            "Iter 859: train loss: 0.6928671002388\n",
            "Iter 860: train loss: 0.6928654909133911\n",
            "Iter 861: train loss: 0.692863941192627\n",
            "Iter 862: train loss: 0.6928621530532837\n",
            "Iter 863: train loss: 0.6928605437278748\n",
            "Iter 864: train loss: 0.692858874797821\n",
            "Iter 865: train loss: 0.6928572058677673\n",
            "Iter 866: train loss: 0.6928556561470032\n",
            "Iter 867: train loss: 0.6928539872169495\n",
            "Iter 868: train loss: 0.6928523778915405\n",
            "Iter 869: train loss: 0.6928507089614868\n",
            "Iter 870: train loss: 0.6928490996360779\n",
            "Iter 871: train loss: 0.692847490310669\n",
            "Iter 872: train loss: 0.6928458213806152\n",
            "Iter 873: train loss: 0.6928440928459167\n",
            "Iter 874: train loss: 0.6928424835205078\n",
            "Iter 875: train loss: 0.6928409337997437\n",
            "Iter 876: train loss: 0.6928393840789795\n",
            "Iter 877: train loss: 0.6928375959396362\n",
            "Iter 878: train loss: 0.6928360462188721\n",
            "Iter 879: train loss: 0.6928343772888184\n",
            "Iter 880: train loss: 0.6928327679634094\n",
            "Iter 881: train loss: 0.6928310990333557\n",
            "Iter 882: train loss: 0.6928294897079468\n",
            "Iter 883: train loss: 0.6928278207778931\n",
            "Iter 884: train loss: 0.6928262114524841\n",
            "Iter 885: train loss: 0.69282466173172\n",
            "Iter 886: train loss: 0.6928229331970215\n",
            "Iter 887: train loss: 0.6928213238716125\n",
            "Iter 888: train loss: 0.6928196549415588\n",
            "Iter 889: train loss: 0.6928181052207947\n",
            "Iter 890: train loss: 0.692816436290741\n",
            "Iter 891: train loss: 0.692814826965332\n",
            "Iter 892: train loss: 0.6928132176399231\n",
            "Iter 893: train loss: 0.6928115487098694\n",
            "Iter 894: train loss: 0.6928099393844604\n",
            "Iter 895: train loss: 0.6928083300590515\n",
            "Iter 896: train loss: 0.6928066611289978\n",
            "Iter 897: train loss: 0.6928050518035889\n",
            "Iter 898: train loss: 0.6928034424781799\n",
            "Iter 899: train loss: 0.692801833152771\n",
            "Iter 900: train loss: 0.6928002238273621\n",
            "Iter 901: train loss: 0.6927985548973083\n",
            "Iter 902: train loss: 0.6927969455718994\n",
            "Iter 903: train loss: 0.6927953958511353\n",
            "Iter 904: train loss: 0.6927936673164368\n",
            "Iter 905: train loss: 0.6927920579910278\n",
            "Iter 906: train loss: 0.6927904486656189\n",
            "Iter 907: train loss: 0.6927888989448547\n",
            "Iter 908: train loss: 0.6927871704101562\n",
            "Iter 909: train loss: 0.6927855610847473\n",
            "Iter 910: train loss: 0.6927840113639832\n",
            "Iter 911: train loss: 0.6927824020385742\n",
            "Iter 912: train loss: 0.692780613899231\n",
            "Iter 913: train loss: 0.6927790641784668\n",
            "Iter 914: train loss: 0.6927775144577026\n",
            "Iter 915: train loss: 0.6927757263183594\n",
            "Iter 916: train loss: 0.6927741765975952\n",
            "Iter 917: train loss: 0.6927725672721863\n",
            "Iter 918: train loss: 0.6927709579467773\n",
            "Iter 919: train loss: 0.6927692890167236\n",
            "Iter 920: train loss: 0.6927676200866699\n",
            "Iter 921: train loss: 0.6927660703659058\n",
            "Iter 922: train loss: 0.692764401435852\n",
            "Iter 923: train loss: 0.6927628517150879\n",
            "Iter 924: train loss: 0.6927611827850342\n",
            "Iter 925: train loss: 0.6927595734596252\n",
            "Iter 926: train loss: 0.6927579641342163\n",
            "Iter 927: train loss: 0.6927563548088074\n",
            "Iter 928: train loss: 0.6927547454833984\n",
            "Iter 929: train loss: 0.6927531361579895\n",
            "Iter 930: train loss: 0.6927514672279358\n",
            "Iter 931: train loss: 0.6927498579025269\n",
            "Iter 932: train loss: 0.6927481889724731\n",
            "Iter 933: train loss: 0.6927465796470642\n",
            "Iter 934: train loss: 0.6927450299263\n",
            "Iter 935: train loss: 0.6927433609962463\n",
            "Iter 936: train loss: 0.6927418112754822\n",
            "Iter 937: train loss: 0.6927401423454285\n",
            "Iter 938: train loss: 0.6927384734153748\n",
            "Iter 939: train loss: 0.6927369236946106\n",
            "Iter 940: train loss: 0.6927353143692017\n",
            "Iter 941: train loss: 0.692733645439148\n",
            "Iter 942: train loss: 0.6927319765090942\n",
            "Iter 943: train loss: 0.6927304863929749\n",
            "Iter 944: train loss: 0.6927288174629211\n",
            "Iter 945: train loss: 0.6927272081375122\n",
            "Iter 946: train loss: 0.6927255988121033\n",
            "Iter 947: train loss: 0.6927239894866943\n",
            "Iter 948: train loss: 0.6927223801612854\n",
            "Iter 949: train loss: 0.6927207112312317\n",
            "Iter 950: train loss: 0.6927191615104675\n",
            "Iter 951: train loss: 0.6927175521850586\n",
            "Iter 952: train loss: 0.6927158832550049\n",
            "Iter 953: train loss: 0.692714273929596\n",
            "Iter 954: train loss: 0.6927127242088318\n",
            "Iter 955: train loss: 0.6927111148834229\n",
            "Iter 956: train loss: 0.6927093863487244\n",
            "Iter 957: train loss: 0.6927078366279602\n",
            "Iter 958: train loss: 0.692706286907196\n",
            "Iter 959: train loss: 0.6927046179771423\n",
            "Iter 960: train loss: 0.6927029490470886\n",
            "Iter 961: train loss: 0.6927013397216797\n",
            "Iter 962: train loss: 0.6926998496055603\n",
            "Iter 963: train loss: 0.6926981806755066\n",
            "Iter 964: train loss: 0.6926965117454529\n",
            "Iter 965: train loss: 0.6926949620246887\n",
            "Iter 966: train loss: 0.6926933526992798\n",
            "Iter 967: train loss: 0.6926917433738708\n",
            "Iter 968: train loss: 0.6926900148391724\n",
            "Iter 969: train loss: 0.6926884651184082\n",
            "Iter 970: train loss: 0.692686915397644\n",
            "Iter 971: train loss: 0.6926852464675903\n",
            "Iter 972: train loss: 0.6926835775375366\n",
            "Iter 973: train loss: 0.6926820278167725\n",
            "Iter 974: train loss: 0.6926804184913635\n",
            "Iter 975: train loss: 0.6926788091659546\n",
            "Iter 976: train loss: 0.6926771998405457\n",
            "Iter 977: train loss: 0.6926755905151367\n",
            "Iter 978: train loss: 0.6926739811897278\n",
            "Iter 979: train loss: 0.6926723122596741\n",
            "Iter 980: train loss: 0.6926707625389099\n",
            "Iter 981: train loss: 0.6926690936088562\n",
            "Iter 982: train loss: 0.692667543888092\n",
            "Iter 983: train loss: 0.6926658749580383\n",
            "Iter 984: train loss: 0.6926643252372742\n",
            "Iter 985: train loss: 0.6926627159118652\n",
            "Iter 986: train loss: 0.6926610469818115\n",
            "Iter 987: train loss: 0.6926593780517578\n",
            "Iter 988: train loss: 0.6926578283309937\n",
            "Iter 989: train loss: 0.6926562190055847\n",
            "Iter 990: train loss: 0.6926546692848206\n",
            "Iter 991: train loss: 0.6926530003547668\n",
            "Iter 992: train loss: 0.6926513314247131\n",
            "Iter 993: train loss: 0.6926497220993042\n",
            "Iter 994: train loss: 0.69264817237854\n",
            "Iter 995: train loss: 0.6926465630531311\n",
            "Iter 996: train loss: 0.6926448941230774\n",
            "Iter 997: train loss: 0.6926433444023132\n",
            "Iter 998: train loss: 0.6926417350769043\n",
            "Iter 999: train loss: 0.6926401853561401\n",
            "Iter 1000: train loss: 0.6926385164260864\n",
            "Iter 1001: train loss: 0.6926369667053223\n",
            "Iter 1002: train loss: 0.6926353573799133\n",
            "Iter 1003: train loss: 0.6926337480545044\n",
            "Iter 1004: train loss: 0.6926320791244507\n",
            "Iter 1005: train loss: 0.6926304697990417\n",
            "Iter 1006: train loss: 0.6926288604736328\n",
            "Iter 1007: train loss: 0.6926273107528687\n",
            "Iter 1008: train loss: 0.6926256418228149\n",
            "Iter 1009: train loss: 0.692624032497406\n",
            "Iter 1010: train loss: 0.6926224231719971\n",
            "Iter 1011: train loss: 0.6926208138465881\n",
            "Iter 1012: train loss: 0.6926191449165344\n",
            "Iter 1013: train loss: 0.6926175951957703\n",
            "Iter 1014: train loss: 0.6926159262657166\n",
            "Iter 1015: train loss: 0.6926143169403076\n",
            "Iter 1016: train loss: 0.6926127672195435\n",
            "Iter 1017: train loss: 0.6926110982894897\n",
            "Iter 1018: train loss: 0.6926095485687256\n",
            "Iter 1019: train loss: 0.6926079392433167\n",
            "Iter 1020: train loss: 0.6926063299179077\n",
            "Iter 1021: train loss: 0.6926047205924988\n",
            "Iter 1022: train loss: 0.6926031708717346\n",
            "Iter 1023: train loss: 0.6926015019416809\n",
            "Iter 1024: train loss: 0.6925998330116272\n",
            "Iter 1025: train loss: 0.6925983428955078\n",
            "Iter 1026: train loss: 0.6925967335700989\n",
            "Iter 1027: train loss: 0.6925950646400452\n",
            "Iter 1028: train loss: 0.6925934553146362\n",
            "Iter 1029: train loss: 0.6925918459892273\n",
            "Iter 1030: train loss: 0.6925901770591736\n",
            "Iter 1031: train loss: 0.6925885677337646\n",
            "Iter 1032: train loss: 0.6925869584083557\n",
            "Iter 1033: train loss: 0.6925853490829468\n",
            "Iter 1034: train loss: 0.6925837397575378\n",
            "Iter 1035: train loss: 0.6925821900367737\n",
            "Iter 1036: train loss: 0.69258052110672\n",
            "Iter 1037: train loss: 0.6925789713859558\n",
            "Iter 1038: train loss: 0.6925773024559021\n",
            "Iter 1039: train loss: 0.6925756335258484\n",
            "Iter 1040: train loss: 0.692574143409729\n",
            "Iter 1041: train loss: 0.6925725340843201\n",
            "Iter 1042: train loss: 0.6925708651542664\n",
            "Iter 1043: train loss: 0.6925693154335022\n",
            "Iter 1044: train loss: 0.692567765712738\n",
            "Iter 1045: train loss: 0.6925660371780396\n",
            "Iter 1046: train loss: 0.6925644278526306\n",
            "Iter 1047: train loss: 0.6925628185272217\n",
            "Iter 1048: train loss: 0.6925612092018127\n",
            "Iter 1049: train loss: 0.6925596594810486\n",
            "Iter 1050: train loss: 0.6925579309463501\n",
            "Iter 1051: train loss: 0.6925563812255859\n",
            "Iter 1052: train loss: 0.692554771900177\n",
            "Iter 1053: train loss: 0.6925531029701233\n",
            "Iter 1054: train loss: 0.6925514936447144\n",
            "Iter 1055: train loss: 0.6925499439239502\n",
            "Iter 1056: train loss: 0.6925483345985413\n",
            "Iter 1057: train loss: 0.6925467848777771\n",
            "Iter 1058: train loss: 0.6925450563430786\n",
            "Iter 1059: train loss: 0.6925435066223145\n",
            "Iter 1060: train loss: 0.6925418972969055\n",
            "Iter 1061: train loss: 0.6925402879714966\n",
            "Iter 1062: train loss: 0.6925386786460876\n",
            "Iter 1063: train loss: 0.6925371289253235\n",
            "Iter 1064: train loss: 0.6925354599952698\n",
            "Iter 1065: train loss: 0.6925337910652161\n",
            "Iter 1066: train loss: 0.6925322413444519\n",
            "Iter 1067: train loss: 0.692530632019043\n",
            "Iter 1068: train loss: 0.692529022693634\n",
            "Iter 1069: train loss: 0.6925273537635803\n",
            "Iter 1070: train loss: 0.6925258040428162\n",
            "Iter 1071: train loss: 0.6925241351127625\n",
            "Iter 1072: train loss: 0.6925225257873535\n",
            "Iter 1073: train loss: 0.6925208568572998\n",
            "Iter 1074: train loss: 0.6925193667411804\n",
            "Iter 1075: train loss: 0.6925176382064819\n",
            "Iter 1076: train loss: 0.6925160884857178\n",
            "Iter 1077: train loss: 0.6925144791603088\n",
            "Iter 1078: train loss: 0.6925128698348999\n",
            "Iter 1079: train loss: 0.692511260509491\n",
            "Iter 1080: train loss: 0.6925095915794373\n",
            "Iter 1081: train loss: 0.6925080418586731\n",
            "Iter 1082: train loss: 0.6925064921379089\n",
            "Iter 1083: train loss: 0.6925048232078552\n",
            "Iter 1084: train loss: 0.6925032138824463\n",
            "Iter 1085: train loss: 0.6925016045570374\n",
            "Iter 1086: train loss: 0.6924999952316284\n",
            "Iter 1087: train loss: 0.6924983263015747\n",
            "Iter 1088: train loss: 0.6924967169761658\n",
            "Iter 1089: train loss: 0.6924951076507568\n",
            "Iter 1090: train loss: 0.6924934983253479\n",
            "Iter 1091: train loss: 0.692491888999939\n",
            "Iter 1092: train loss: 0.69249027967453\n",
            "Iter 1093: train loss: 0.6924886703491211\n",
            "Iter 1094: train loss: 0.6924870014190674\n",
            "Iter 1095: train loss: 0.6924853920936584\n",
            "Iter 1096: train loss: 0.6924837827682495\n",
            "Iter 1097: train loss: 0.6924821734428406\n",
            "Iter 1098: train loss: 0.6924805045127869\n",
            "Iter 1099: train loss: 0.6924788951873779\n",
            "Iter 1100: train loss: 0.6924773454666138\n",
            "Iter 1101: train loss: 0.6924756765365601\n",
            "Iter 1102: train loss: 0.6924741268157959\n",
            "Iter 1103: train loss: 0.6924724578857422\n",
            "Iter 1104: train loss: 0.692470908164978\n",
            "Iter 1105: train loss: 0.6924692392349243\n",
            "Iter 1106: train loss: 0.6924675703048706\n",
            "Iter 1107: train loss: 0.6924660205841064\n",
            "Iter 1108: train loss: 0.6924643516540527\n",
            "Iter 1109: train loss: 0.692462682723999\n",
            "Iter 1110: train loss: 0.6924611926078796\n",
            "Iter 1111: train loss: 0.6924595832824707\n",
            "Iter 1112: train loss: 0.692457914352417\n",
            "Iter 1113: train loss: 0.6924563646316528\n",
            "Iter 1114: train loss: 0.6924546360969543\n",
            "Iter 1115: train loss: 0.6924530863761902\n",
            "Iter 1116: train loss: 0.6924514770507812\n",
            "Iter 1117: train loss: 0.6924498081207275\n",
            "Iter 1118: train loss: 0.6924481987953186\n",
            "Iter 1119: train loss: 0.6924465894699097\n",
            "Iter 1120: train loss: 0.6924449801445007\n",
            "Iter 1121: train loss: 0.6924432516098022\n",
            "Iter 1122: train loss: 0.6924417018890381\n",
            "Iter 1123: train loss: 0.6924400925636292\n",
            "Iter 1124: train loss: 0.6924384832382202\n",
            "Iter 1125: train loss: 0.6924368143081665\n",
            "Iter 1126: train loss: 0.6924352049827576\n",
            "Iter 1127: train loss: 0.6924335956573486\n",
            "Iter 1128: train loss: 0.6924319267272949\n",
            "Iter 1129: train loss: 0.692430317401886\n",
            "Iter 1130: train loss: 0.692428708076477\n",
            "Iter 1131: train loss: 0.6924270987510681\n",
            "Iter 1132: train loss: 0.6924254894256592\n",
            "Iter 1133: train loss: 0.692423939704895\n",
            "Iter 1134: train loss: 0.6924222707748413\n",
            "Iter 1135: train loss: 0.6924206018447876\n",
            "Iter 1136: train loss: 0.6924190521240234\n",
            "Iter 1137: train loss: 0.692417323589325\n",
            "Iter 1138: train loss: 0.6924157738685608\n",
            "Iter 1139: train loss: 0.6924140453338623\n",
            "Iter 1140: train loss: 0.6924124956130981\n",
            "Iter 1141: train loss: 0.6924108266830444\n",
            "Iter 1142: train loss: 0.6924092173576355\n",
            "Iter 1143: train loss: 0.6924076080322266\n",
            "Iter 1144: train loss: 0.6924059987068176\n",
            "Iter 1145: train loss: 0.6924043297767639\n",
            "Iter 1146: train loss: 0.692402720451355\n",
            "Iter 1147: train loss: 0.6924011707305908\n",
            "Iter 1148: train loss: 0.6923994421958923\n",
            "Iter 1149: train loss: 0.6923978328704834\n",
            "Iter 1150: train loss: 0.6923962235450745\n",
            "Iter 1151: train loss: 0.6923946738243103\n",
            "Iter 1152: train loss: 0.6923929452896118\n",
            "Iter 1153: train loss: 0.6923913359642029\n",
            "Iter 1154: train loss: 0.692389726638794\n",
            "Iter 1155: train loss: 0.6923880577087402\n",
            "Iter 1156: train loss: 0.6923863887786865\n",
            "Iter 1157: train loss: 0.6923847794532776\n",
            "Iter 1158: train loss: 0.6923831701278687\n",
            "Iter 1159: train loss: 0.6923814415931702\n",
            "Iter 1160: train loss: 0.692379891872406\n",
            "Iter 1161: train loss: 0.6923782825469971\n",
            "Iter 1162: train loss: 0.6923766732215881\n",
            "Iter 1163: train loss: 0.6923750042915344\n",
            "Iter 1164: train loss: 0.6923733949661255\n",
            "Iter 1165: train loss: 0.6923717260360718\n",
            "Iter 1166: train loss: 0.6923701167106628\n",
            "Iter 1167: train loss: 0.6923683881759644\n",
            "Iter 1168: train loss: 0.692366898059845\n",
            "Iter 1169: train loss: 0.6923652291297913\n",
            "Iter 1170: train loss: 0.6923635005950928\n",
            "Iter 1171: train loss: 0.6923618912696838\n",
            "Iter 1172: train loss: 0.6923602819442749\n",
            "Iter 1173: train loss: 0.692358672618866\n",
            "Iter 1174: train loss: 0.692357063293457\n",
            "Iter 1175: train loss: 0.6923554539680481\n",
            "Iter 1176: train loss: 0.6923537850379944\n",
            "Iter 1177: train loss: 0.6923521161079407\n",
            "Iter 1178: train loss: 0.692350447177887\n",
            "Iter 1179: train loss: 0.6923487782478333\n",
            "Iter 1180: train loss: 0.6923472285270691\n",
            "Iter 1181: train loss: 0.6923455595970154\n",
            "Iter 1182: train loss: 0.6923439502716064\n",
            "Iter 1183: train loss: 0.6923422813415527\n",
            "Iter 1184: train loss: 0.692340612411499\n",
            "Iter 1185: train loss: 0.6923390030860901\n",
            "Iter 1186: train loss: 0.6923373937606812\n",
            "Iter 1187: train loss: 0.6923357248306274\n",
            "Iter 1188: train loss: 0.6923340559005737\n",
            "Iter 1189: train loss: 0.69233238697052\n",
            "Iter 1190: train loss: 0.6923308372497559\n",
            "Iter 1191: train loss: 0.6923291683197021\n",
            "Iter 1192: train loss: 0.6923274993896484\n",
            "Iter 1193: train loss: 0.6923258900642395\n",
            "Iter 1194: train loss: 0.6923242807388306\n",
            "Iter 1195: train loss: 0.6923225522041321\n",
            "Iter 1196: train loss: 0.6923210024833679\n",
            "Iter 1197: train loss: 0.6923193335533142\n",
            "Iter 1198: train loss: 0.6923176050186157\n",
            "Iter 1199: train loss: 0.6923160552978516\n",
            "Iter 1200: train loss: 0.6923143267631531\n",
            "Iter 1201: train loss: 0.6923126578330994\n",
            "Iter 1202: train loss: 0.6923109889030457\n",
            "Iter 1203: train loss: 0.6923093795776367\n",
            "Iter 1204: train loss: 0.6923077702522278\n",
            "Iter 1205: train loss: 0.6923061013221741\n",
            "Iter 1206: train loss: 0.6923044919967651\n",
            "Iter 1207: train loss: 0.6923028826713562\n",
            "Iter 1208: train loss: 0.6923010945320129\n",
            "Iter 1209: train loss: 0.6922995448112488\n",
            "Iter 1210: train loss: 0.6922978758811951\n",
            "Iter 1211: train loss: 0.6922962069511414\n",
            "Iter 1212: train loss: 0.6922944784164429\n",
            "Iter 1213: train loss: 0.6922928690910339\n",
            "Iter 1214: train loss: 0.692291259765625\n",
            "Iter 1215: train loss: 0.6922895908355713\n",
            "Iter 1216: train loss: 0.6922879815101624\n",
            "Iter 1217: train loss: 0.6922863125801086\n",
            "Iter 1218: train loss: 0.6922846436500549\n",
            "Iter 1219: train loss: 0.692283034324646\n",
            "Iter 1220: train loss: 0.6922814249992371\n",
            "Iter 1221: train loss: 0.6922796964645386\n",
            "Iter 1222: train loss: 0.6922780275344849\n",
            "Iter 1223: train loss: 0.6922764182090759\n",
            "Iter 1224: train loss: 0.6922746896743774\n",
            "Iter 1225: train loss: 0.6922730207443237\n",
            "Iter 1226: train loss: 0.69227135181427\n",
            "Iter 1227: train loss: 0.6922696828842163\n",
            "Iter 1228: train loss: 0.6922680735588074\n",
            "Iter 1229: train loss: 0.6922664642333984\n",
            "Iter 1230: train loss: 0.6922648549079895\n",
            "Iter 1231: train loss: 0.692263126373291\n",
            "Iter 1232: train loss: 0.6922613978385925\n",
            "Iter 1233: train loss: 0.6922598481178284\n",
            "Iter 1234: train loss: 0.6922581195831299\n",
            "Iter 1235: train loss: 0.6922563910484314\n",
            "Iter 1236: train loss: 0.6922548413276672\n",
            "Iter 1237: train loss: 0.6922531723976135\n",
            "Iter 1238: train loss: 0.6922515034675598\n",
            "Iter 1239: train loss: 0.6922498345375061\n",
            "Iter 1240: train loss: 0.6922481656074524\n",
            "Iter 1241: train loss: 0.6922464370727539\n",
            "Iter 1242: train loss: 0.692244827747345\n",
            "Iter 1243: train loss: 0.6922431588172913\n",
            "Iter 1244: train loss: 0.6922415494918823\n",
            "Iter 1245: train loss: 0.6922398209571838\n",
            "Iter 1246: train loss: 0.6922381520271301\n",
            "Iter 1247: train loss: 0.6922365427017212\n",
            "Iter 1248: train loss: 0.6922348141670227\n",
            "Iter 1249: train loss: 0.6922332048416138\n",
            "Iter 1250: train loss: 0.6922314763069153\n",
            "Iter 1251: train loss: 0.6922297477722168\n",
            "Iter 1252: train loss: 0.6922281980514526\n",
            "Iter 1253: train loss: 0.6922265291213989\n",
            "Iter 1254: train loss: 0.6922248005867004\n",
            "Iter 1255: train loss: 0.6922231912612915\n",
            "Iter 1256: train loss: 0.692221462726593\n",
            "Iter 1257: train loss: 0.6922197341918945\n",
            "Iter 1258: train loss: 0.6922181248664856\n",
            "Iter 1259: train loss: 0.6922165155410767\n",
            "Iter 1260: train loss: 0.6922147274017334\n",
            "Iter 1261: train loss: 0.6922131180763245\n",
            "Iter 1262: train loss: 0.6922114491462708\n",
            "Iter 1263: train loss: 0.6922096610069275\n",
            "Iter 1264: train loss: 0.6922080516815186\n",
            "Iter 1265: train loss: 0.6922063827514648\n",
            "Iter 1266: train loss: 0.6922047138214111\n",
            "Iter 1267: train loss: 0.6922029852867126\n",
            "Iter 1268: train loss: 0.6922013759613037\n",
            "Iter 1269: train loss: 0.69219970703125\n",
            "Iter 1270: train loss: 0.6921979784965515\n",
            "Iter 1271: train loss: 0.6921963095664978\n",
            "Iter 1272: train loss: 0.6921945810317993\n",
            "Iter 1273: train loss: 0.6921929717063904\n",
            "Iter 1274: train loss: 0.6921913027763367\n",
            "Iter 1275: train loss: 0.6921895742416382\n",
            "Iter 1276: train loss: 0.6921879649162292\n",
            "Iter 1277: train loss: 0.6921862363815308\n",
            "Iter 1278: train loss: 0.692184567451477\n",
            "Iter 1279: train loss: 0.6921828389167786\n",
            "Iter 1280: train loss: 0.6921812295913696\n",
            "Iter 1281: train loss: 0.6921794414520264\n",
            "Iter 1282: train loss: 0.6921778321266174\n",
            "Iter 1283: train loss: 0.692176103591919\n",
            "Iter 1284: train loss: 0.6921744346618652\n",
            "Iter 1285: train loss: 0.6921727061271667\n",
            "Iter 1286: train loss: 0.692171037197113\n",
            "Iter 1287: train loss: 0.6921693086624146\n",
            "Iter 1288: train loss: 0.6921676993370056\n",
            "Iter 1289: train loss: 0.6921660304069519\n",
            "Iter 1290: train loss: 0.6921643018722534\n",
            "Iter 1291: train loss: 0.6921625733375549\n",
            "Iter 1292: train loss: 0.6921609044075012\n",
            "Iter 1293: train loss: 0.6921591758728027\n",
            "Iter 1294: train loss: 0.692157506942749\n",
            "Iter 1295: train loss: 0.6921558380126953\n",
            "Iter 1296: train loss: 0.6921541690826416\n",
            "Iter 1297: train loss: 0.6921524405479431\n",
            "Iter 1298: train loss: 0.6921507120132446\n",
            "Iter 1299: train loss: 0.6921489834785461\n",
            "Iter 1300: train loss: 0.6921472549438477\n",
            "Iter 1301: train loss: 0.692145586013794\n",
            "Iter 1302: train loss: 0.6921439170837402\n",
            "Iter 1303: train loss: 0.6921423077583313\n",
            "Iter 1304: train loss: 0.692140519618988\n",
            "Iter 1305: train loss: 0.6921387910842896\n",
            "Iter 1306: train loss: 0.6921371221542358\n",
            "Iter 1307: train loss: 0.6921353936195374\n",
            "Iter 1308: train loss: 0.6921336650848389\n",
            "Iter 1309: train loss: 0.6921320557594299\n",
            "Iter 1310: train loss: 0.6921303868293762\n",
            "Iter 1311: train loss: 0.692128598690033\n",
            "Iter 1312: train loss: 0.6921269297599792\n",
            "Iter 1313: train loss: 0.6921252012252808\n",
            "Iter 1314: train loss: 0.6921234130859375\n",
            "Iter 1315: train loss: 0.692121684551239\n",
            "Iter 1316: train loss: 0.6921201348304749\n",
            "Iter 1317: train loss: 0.6921183466911316\n",
            "Iter 1318: train loss: 0.6921165585517883\n",
            "Iter 1319: train loss: 0.6921149492263794\n",
            "Iter 1320: train loss: 0.6921132206916809\n",
            "Iter 1321: train loss: 0.6921114325523376\n",
            "Iter 1322: train loss: 0.6921098232269287\n",
            "Iter 1323: train loss: 0.6921080350875854\n",
            "Iter 1324: train loss: 0.692106306552887\n",
            "Iter 1325: train loss: 0.692104697227478\n",
            "Iter 1326: train loss: 0.6921029090881348\n",
            "Iter 1327: train loss: 0.6921011805534363\n",
            "Iter 1328: train loss: 0.6920995712280273\n",
            "Iter 1329: train loss: 0.6920977830886841\n",
            "Iter 1330: train loss: 0.6920960545539856\n",
            "Iter 1331: train loss: 0.6920943856239319\n",
            "Iter 1332: train loss: 0.6920925974845886\n",
            "Iter 1333: train loss: 0.6920909285545349\n",
            "Iter 1334: train loss: 0.6920891404151917\n",
            "Iter 1335: train loss: 0.6920875310897827\n",
            "Iter 1336: train loss: 0.6920856833457947\n",
            "Iter 1337: train loss: 0.692084014415741\n",
            "Iter 1338: train loss: 0.6920822858810425\n",
            "Iter 1339: train loss: 0.692080557346344\n",
            "Iter 1340: train loss: 0.6920787692070007\n",
            "Iter 1341: train loss: 0.692077100276947\n",
            "Iter 1342: train loss: 0.6920753717422485\n",
            "Iter 1343: train loss: 0.69207364320755\n",
            "Iter 1344: train loss: 0.6920719742774963\n",
            "Iter 1345: train loss: 0.6920701861381531\n",
            "Iter 1346: train loss: 0.6920684576034546\n",
            "Iter 1347: train loss: 0.6920667290687561\n",
            "Iter 1348: train loss: 0.6920650005340576\n",
            "Iter 1349: train loss: 0.6920632719993591\n",
            "Iter 1350: train loss: 0.6920616030693054\n",
            "Iter 1351: train loss: 0.6920598745346069\n",
            "Iter 1352: train loss: 0.6920580267906189\n",
            "Iter 1353: train loss: 0.6920562982559204\n",
            "Iter 1354: train loss: 0.6920545101165771\n",
            "Iter 1355: train loss: 0.6920528411865234\n",
            "Iter 1356: train loss: 0.6920510530471802\n",
            "Iter 1357: train loss: 0.6920492649078369\n",
            "Iter 1358: train loss: 0.692047655582428\n",
            "Iter 1359: train loss: 0.6920458674430847\n",
            "Iter 1360: train loss: 0.6920440793037415\n",
            "Iter 1361: train loss: 0.6920424699783325\n",
            "Iter 1362: train loss: 0.6920406222343445\n",
            "Iter 1363: train loss: 0.6920388340950012\n",
            "Iter 1364: train loss: 0.6920372247695923\n",
            "Iter 1365: train loss: 0.692035436630249\n",
            "Iter 1366: train loss: 0.6920336484909058\n",
            "Iter 1367: train loss: 0.6920319199562073\n",
            "Iter 1368: train loss: 0.6920301914215088\n",
            "Iter 1369: train loss: 0.6920284032821655\n",
            "Iter 1370: train loss: 0.6920266151428223\n",
            "Iter 1371: train loss: 0.6920249462127686\n",
            "Iter 1372: train loss: 0.6920230984687805\n",
            "Iter 1373: train loss: 0.6920214295387268\n",
            "Iter 1374: train loss: 0.6920197010040283\n",
            "Iter 1375: train loss: 0.6920179128646851\n",
            "Iter 1376: train loss: 0.6920161247253418\n",
            "Iter 1377: train loss: 0.6920144557952881\n",
            "Iter 1378: train loss: 0.6920127272605896\n",
            "Iter 1379: train loss: 0.6920108795166016\n",
            "Iter 1380: train loss: 0.6920092105865479\n",
            "Iter 1381: train loss: 0.6920074224472046\n",
            "Iter 1382: train loss: 0.6920056343078613\n",
            "Iter 1383: train loss: 0.6920038461685181\n",
            "Iter 1384: train loss: 0.6920020580291748\n",
            "Iter 1385: train loss: 0.6920003294944763\n",
            "Iter 1386: train loss: 0.6919985413551331\n",
            "Iter 1387: train loss: 0.6919968128204346\n",
            "Iter 1388: train loss: 0.6919950842857361\n",
            "Iter 1389: train loss: 0.691993236541748\n",
            "Iter 1390: train loss: 0.6919916272163391\n",
            "Iter 1391: train loss: 0.6919897198677063\n",
            "Iter 1392: train loss: 0.6919879913330078\n",
            "Iter 1393: train loss: 0.6919863224029541\n",
            "Iter 1394: train loss: 0.6919844150543213\n",
            "Iter 1395: train loss: 0.6919826865196228\n",
            "Iter 1396: train loss: 0.6919808387756348\n",
            "Iter 1397: train loss: 0.6919791102409363\n",
            "Iter 1398: train loss: 0.6919773817062378\n",
            "Iter 1399: train loss: 0.6919755339622498\n",
            "Iter 1400: train loss: 0.6919738054275513\n",
            "Iter 1401: train loss: 0.6919719576835632\n",
            "Iter 1402: train loss: 0.69197016954422\n",
            "Iter 1403: train loss: 0.6919684410095215\n",
            "Iter 1404: train loss: 0.6919666528701782\n",
            "Iter 1405: train loss: 0.6919649243354797\n",
            "Iter 1406: train loss: 0.6919630765914917\n",
            "Iter 1407: train loss: 0.6919612884521484\n",
            "Iter 1408: train loss: 0.69195955991745\n",
            "Iter 1409: train loss: 0.6919576525688171\n",
            "Iter 1410: train loss: 0.6919560432434082\n",
            "Iter 1411: train loss: 0.6919541954994202\n",
            "Iter 1412: train loss: 0.6919524073600769\n",
            "Iter 1413: train loss: 0.6919506788253784\n",
            "Iter 1414: train loss: 0.6919488310813904\n",
            "Iter 1415: train loss: 0.6919470429420471\n",
            "Iter 1416: train loss: 0.6919451951980591\n",
            "Iter 1417: train loss: 0.6919434666633606\n",
            "Iter 1418: train loss: 0.6919416785240173\n",
            "Iter 1419: train loss: 0.6919397711753845\n",
            "Iter 1420: train loss: 0.6919381022453308\n",
            "Iter 1421: train loss: 0.6919362545013428\n",
            "Iter 1422: train loss: 0.6919344663619995\n",
            "Iter 1423: train loss: 0.6919326782226562\n",
            "Iter 1424: train loss: 0.6919308304786682\n",
            "Iter 1425: train loss: 0.691929042339325\n",
            "Iter 1426: train loss: 0.6919271945953369\n",
            "Iter 1427: train loss: 0.6919255256652832\n",
            "Iter 1428: train loss: 0.6919236183166504\n",
            "Iter 1429: train loss: 0.6919218897819519\n",
            "Iter 1430: train loss: 0.6919201016426086\n",
            "Iter 1431: train loss: 0.6919182538986206\n",
            "Iter 1432: train loss: 0.6919164061546326\n",
            "Iter 1433: train loss: 0.6919146180152893\n",
            "Iter 1434: train loss: 0.691912829875946\n",
            "Iter 1435: train loss: 0.6919109225273132\n",
            "Iter 1436: train loss: 0.6919091939926147\n",
            "Iter 1437: train loss: 0.6919073462486267\n",
            "Iter 1438: train loss: 0.6919055581092834\n",
            "Iter 1439: train loss: 0.6919037699699402\n",
            "Iter 1440: train loss: 0.6919019222259521\n",
            "Iter 1441: train loss: 0.6919001340866089\n",
            "Iter 1442: train loss: 0.6918982863426208\n",
            "Iter 1443: train loss: 0.6918964385986328\n",
            "Iter 1444: train loss: 0.6918947100639343\n",
            "Iter 1445: train loss: 0.6918928027153015\n",
            "Iter 1446: train loss: 0.691891074180603\n",
            "Iter 1447: train loss: 0.691889226436615\n",
            "Iter 1448: train loss: 0.6918874382972717\n",
            "Iter 1449: train loss: 0.6918855905532837\n",
            "Iter 1450: train loss: 0.6918837428092957\n",
            "Iter 1451: train loss: 0.6918818950653076\n",
            "Iter 1452: train loss: 0.6918801069259644\n",
            "Iter 1453: train loss: 0.6918782591819763\n",
            "Iter 1454: train loss: 0.6918764114379883\n",
            "Iter 1455: train loss: 0.6918745040893555\n",
            "Iter 1456: train loss: 0.6918727159500122\n",
            "Iter 1457: train loss: 0.691870927810669\n",
            "Iter 1458: train loss: 0.6918690204620361\n",
            "Iter 1459: train loss: 0.6918672323226929\n",
            "Iter 1460: train loss: 0.6918654441833496\n",
            "Iter 1461: train loss: 0.6918635368347168\n",
            "Iter 1462: train loss: 0.6918616890907288\n",
            "Iter 1463: train loss: 0.6918598413467407\n",
            "Iter 1464: train loss: 0.6918581128120422\n",
            "Iter 1465: train loss: 0.6918562054634094\n",
            "Iter 1466: train loss: 0.6918543577194214\n",
            "Iter 1467: train loss: 0.6918525099754333\n",
            "Iter 1468: train loss: 0.6918507218360901\n",
            "Iter 1469: train loss: 0.6918488144874573\n",
            "Iter 1470: train loss: 0.6918469071388245\n",
            "Iter 1471: train loss: 0.6918451189994812\n",
            "Iter 1472: train loss: 0.6918432116508484\n",
            "Iter 1473: train loss: 0.6918414831161499\n",
            "Iter 1474: train loss: 0.6918395757675171\n",
            "Iter 1475: train loss: 0.6918377876281738\n",
            "Iter 1476: train loss: 0.6918357610702515\n",
            "Iter 1477: train loss: 0.691834032535553\n",
            "Iter 1478: train loss: 0.6918321251869202\n",
            "Iter 1479: train loss: 0.6918302774429321\n",
            "Iter 1480: train loss: 0.6918283700942993\n",
            "Iter 1481: train loss: 0.6918265223503113\n",
            "Iter 1482: train loss: 0.6918246746063232\n",
            "Iter 1483: train loss: 0.6918227672576904\n",
            "Iter 1484: train loss: 0.6918209791183472\n",
            "Iter 1485: train loss: 0.6918191313743591\n",
            "Iter 1486: train loss: 0.6918172240257263\n",
            "Iter 1487: train loss: 0.6918153762817383\n",
            "Iter 1488: train loss: 0.691813588142395\n",
            "Iter 1489: train loss: 0.6918116807937622\n",
            "Iter 1490: train loss: 0.6918097734451294\n",
            "Iter 1491: train loss: 0.6918079257011414\n",
            "Iter 1492: train loss: 0.6918060183525085\n",
            "Iter 1493: train loss: 0.6918041110038757\n",
            "Iter 1494: train loss: 0.6918023228645325\n",
            "Iter 1495: train loss: 0.6918004155158997\n",
            "Iter 1496: train loss: 0.6917985081672668\n",
            "Iter 1497: train loss: 0.691796600818634\n",
            "Iter 1498: train loss: 0.6917946934700012\n",
            "Iter 1499: train loss: 0.6917928457260132\n",
            "Iter 1500: train loss: 0.6917909383773804\n",
            "Iter 1501: train loss: 0.6917890906333923\n",
            "Iter 1502: train loss: 0.6917871236801147\n",
            "Iter 1503: train loss: 0.6917853355407715\n",
            "Iter 1504: train loss: 0.6917833685874939\n",
            "Iter 1505: train loss: 0.6917815804481506\n",
            "Iter 1506: train loss: 0.691779613494873\n",
            "Iter 1507: train loss: 0.6917778253555298\n",
            "Iter 1508: train loss: 0.6917757987976074\n",
            "Iter 1509: train loss: 0.6917740106582642\n",
            "Iter 1510: train loss: 0.6917719841003418\n",
            "Iter 1511: train loss: 0.6917701959609985\n",
            "Iter 1512: train loss: 0.6917682886123657\n",
            "Iter 1513: train loss: 0.6917663812637329\n",
            "Iter 1514: train loss: 0.6917644739151001\n",
            "Iter 1515: train loss: 0.6917626261711121\n",
            "Iter 1516: train loss: 0.6917606592178345\n",
            "Iter 1517: train loss: 0.6917588114738464\n",
            "Iter 1518: train loss: 0.6917568445205688\n",
            "Iter 1519: train loss: 0.691754937171936\n",
            "Iter 1520: train loss: 0.691753089427948\n",
            "Iter 1521: train loss: 0.6917511224746704\n",
            "Iter 1522: train loss: 0.6917492151260376\n",
            "Iter 1523: train loss: 0.6917473673820496\n",
            "Iter 1524: train loss: 0.691745400428772\n",
            "Iter 1525: train loss: 0.6917434334754944\n",
            "Iter 1526: train loss: 0.6917415261268616\n",
            "Iter 1527: train loss: 0.6917396187782288\n",
            "Iter 1528: train loss: 0.691737711429596\n",
            "Iter 1529: train loss: 0.6917358040809631\n",
            "Iter 1530: train loss: 0.6917338371276855\n",
            "Iter 1531: train loss: 0.6917319297790527\n",
            "Iter 1532: train loss: 0.6917299628257751\n",
            "Iter 1533: train loss: 0.6917280554771423\n",
            "Iter 1534: train loss: 0.6917261481285095\n",
            "Iter 1535: train loss: 0.6917242407798767\n",
            "Iter 1536: train loss: 0.6917223334312439\n",
            "Iter 1537: train loss: 0.6917203664779663\n",
            "Iter 1538: train loss: 0.6917183995246887\n",
            "Iter 1539: train loss: 0.6917165517807007\n",
            "Iter 1540: train loss: 0.6917145848274231\n",
            "Iter 1541: train loss: 0.6917126774787903\n",
            "Iter 1542: train loss: 0.6917107105255127\n",
            "Iter 1543: train loss: 0.6917087435722351\n",
            "Iter 1544: train loss: 0.6917068958282471\n",
            "Iter 1545: train loss: 0.6917048692703247\n",
            "Iter 1546: train loss: 0.6917029619216919\n",
            "Iter 1547: train loss: 0.6917009949684143\n",
            "Iter 1548: train loss: 0.6916990280151367\n",
            "Iter 1549: train loss: 0.6916970610618591\n",
            "Iter 1550: train loss: 0.6916950941085815\n",
            "Iter 1551: train loss: 0.6916930675506592\n",
            "Iter 1552: train loss: 0.6916912794113159\n",
            "Iter 1553: train loss: 0.6916891932487488\n",
            "Iter 1554: train loss: 0.691687285900116\n",
            "Iter 1555: train loss: 0.6916853189468384\n",
            "Iter 1556: train loss: 0.6916833519935608\n",
            "Iter 1557: train loss: 0.6916813850402832\n",
            "Iter 1558: train loss: 0.6916794180870056\n",
            "Iter 1559: train loss: 0.6916775107383728\n",
            "Iter 1560: train loss: 0.6916754841804504\n",
            "Iter 1561: train loss: 0.6916735768318176\n",
            "Iter 1562: train loss: 0.69167160987854\n",
            "Iter 1563: train loss: 0.6916696429252625\n",
            "Iter 1564: train loss: 0.6916675567626953\n",
            "Iter 1565: train loss: 0.6916656494140625\n",
            "Iter 1566: train loss: 0.6916637420654297\n",
            "Iter 1567: train loss: 0.6916617751121521\n",
            "Iter 1568: train loss: 0.6916598081588745\n",
            "Iter 1569: train loss: 0.6916577816009521\n",
            "Iter 1570: train loss: 0.6916558742523193\n",
            "Iter 1571: train loss: 0.6916537880897522\n",
            "Iter 1572: train loss: 0.6916517615318298\n",
            "Iter 1573: train loss: 0.6916497945785522\n",
            "Iter 1574: train loss: 0.6916478276252747\n",
            "Iter 1575: train loss: 0.6916458606719971\n",
            "Iter 1576: train loss: 0.6916438937187195\n",
            "Iter 1577: train loss: 0.6916419267654419\n",
            "Iter 1578: train loss: 0.6916399002075195\n",
            "Iter 1579: train loss: 0.6916378736495972\n",
            "Iter 1580: train loss: 0.6916358470916748\n",
            "Iter 1581: train loss: 0.691633939743042\n",
            "Iter 1582: train loss: 0.6916319727897644\n",
            "Iter 1583: train loss: 0.6916298866271973\n",
            "Iter 1584: train loss: 0.6916279196739197\n",
            "Iter 1585: train loss: 0.6916258335113525\n",
            "Iter 1586: train loss: 0.691623866558075\n",
            "Iter 1587: train loss: 0.6916218400001526\n",
            "Iter 1588: train loss: 0.691619873046875\n",
            "Iter 1589: train loss: 0.6916179060935974\n",
            "Iter 1590: train loss: 0.691615879535675\n",
            "Iter 1591: train loss: 0.6916138529777527\n",
            "Iter 1592: train loss: 0.6916118264198303\n",
            "Iter 1593: train loss: 0.6916097402572632\n",
            "Iter 1594: train loss: 0.6916077733039856\n",
            "Iter 1595: train loss: 0.6916057467460632\n",
            "Iter 1596: train loss: 0.6916037201881409\n",
            "Iter 1597: train loss: 0.6916016936302185\n",
            "Iter 1598: train loss: 0.6915997266769409\n",
            "Iter 1599: train loss: 0.6915976405143738\n",
            "Iter 1600: train loss: 0.6915956735610962\n",
            "Iter 1601: train loss: 0.691593587398529\n",
            "Iter 1602: train loss: 0.6915915608406067\n",
            "Iter 1603: train loss: 0.6915895342826843\n",
            "Iter 1604: train loss: 0.6915874481201172\n",
            "Iter 1605: train loss: 0.6915854811668396\n",
            "Iter 1606: train loss: 0.6915834546089172\n",
            "Iter 1607: train loss: 0.6915813684463501\n",
            "Iter 1608: train loss: 0.6915794610977173\n",
            "Iter 1609: train loss: 0.6915772557258606\n",
            "Iter 1610: train loss: 0.6915752291679382\n",
            "Iter 1611: train loss: 0.6915732026100159\n",
            "Iter 1612: train loss: 0.6915711164474487\n",
            "Iter 1613: train loss: 0.6915691494941711\n",
            "Iter 1614: train loss: 0.691567063331604\n",
            "Iter 1615: train loss: 0.6915649771690369\n",
            "Iter 1616: train loss: 0.691563069820404\n",
            "Iter 1617: train loss: 0.6915608644485474\n",
            "Iter 1618: train loss: 0.691558837890625\n",
            "Iter 1619: train loss: 0.6915568113327026\n",
            "Iter 1620: train loss: 0.6915547251701355\n",
            "Iter 1621: train loss: 0.6915526390075684\n",
            "Iter 1622: train loss: 0.6915505528450012\n",
            "Iter 1623: train loss: 0.6915485262870789\n",
            "Iter 1624: train loss: 0.6915464401245117\n",
            "Iter 1625: train loss: 0.6915444135665894\n",
            "Iter 1626: train loss: 0.6915423274040222\n",
            "Iter 1627: train loss: 0.6915403008460999\n",
            "Iter 1628: train loss: 0.6915380954742432\n",
            "Iter 1629: train loss: 0.6915360689163208\n",
            "Iter 1630: train loss: 0.6915339827537537\n",
            "Iter 1631: train loss: 0.6915320158004761\n",
            "Iter 1632: train loss: 0.6915298700332642\n",
            "Iter 1633: train loss: 0.6915276646614075\n",
            "Iter 1634: train loss: 0.6915255784988403\n",
            "Iter 1635: train loss: 0.691523551940918\n",
            "Iter 1636: train loss: 0.691521406173706\n",
            "Iter 1637: train loss: 0.6915193200111389\n",
            "Iter 1638: train loss: 0.6915172934532166\n",
            "Iter 1639: train loss: 0.6915152072906494\n",
            "Iter 1640: train loss: 0.6915131211280823\n",
            "Iter 1641: train loss: 0.6915109753608704\n",
            "Iter 1642: train loss: 0.6915088891983032\n",
            "Iter 1643: train loss: 0.6915068030357361\n",
            "Iter 1644: train loss: 0.691504716873169\n",
            "Iter 1645: train loss: 0.6915026307106018\n",
            "Iter 1646: train loss: 0.6915004253387451\n",
            "Iter 1647: train loss: 0.6914983987808228\n",
            "Iter 1648: train loss: 0.6914962530136108\n",
            "Iter 1649: train loss: 0.6914941668510437\n",
            "Iter 1650: train loss: 0.691491961479187\n",
            "Iter 1651: train loss: 0.6914898753166199\n",
            "Iter 1652: train loss: 0.6914877891540527\n",
            "Iter 1653: train loss: 0.6914857029914856\n",
            "Iter 1654: train loss: 0.6914835572242737\n",
            "Iter 1655: train loss: 0.6914814114570618\n",
            "Iter 1656: train loss: 0.6914793252944946\n",
            "Iter 1657: train loss: 0.6914771199226379\n",
            "Iter 1658: train loss: 0.6914750337600708\n",
            "Iter 1659: train loss: 0.6914728879928589\n",
            "Iter 1660: train loss: 0.6914708018302917\n",
            "Iter 1661: train loss: 0.6914685964584351\n",
            "Iter 1662: train loss: 0.6914665102958679\n",
            "Iter 1663: train loss: 0.6914643049240112\n",
            "Iter 1664: train loss: 0.6914622187614441\n",
            "Iter 1665: train loss: 0.6914600133895874\n",
            "Iter 1666: train loss: 0.6914578676223755\n",
            "Iter 1667: train loss: 0.6914558410644531\n",
            "Iter 1668: train loss: 0.6914535164833069\n",
            "Iter 1669: train loss: 0.6914514303207397\n",
            "Iter 1670: train loss: 0.6914492845535278\n",
            "Iter 1671: train loss: 0.6914471983909607\n",
            "Iter 1672: train loss: 0.691444993019104\n",
            "Iter 1673: train loss: 0.6914427876472473\n",
            "Iter 1674: train loss: 0.6914407014846802\n",
            "Iter 1675: train loss: 0.6914384365081787\n",
            "Iter 1676: train loss: 0.6914362907409668\n",
            "Iter 1677: train loss: 0.6914341449737549\n",
            "Iter 1678: train loss: 0.6914319396018982\n",
            "Iter 1679: train loss: 0.6914297938346863\n",
            "Iter 1680: train loss: 0.6914275884628296\n",
            "Iter 1681: train loss: 0.6914254426956177\n",
            "Iter 1682: train loss: 0.691423237323761\n",
            "Iter 1683: train loss: 0.6914210915565491\n",
            "Iter 1684: train loss: 0.6914188265800476\n",
            "Iter 1685: train loss: 0.6914166808128357\n",
            "Iter 1686: train loss: 0.6914145350456238\n",
            "Iter 1687: train loss: 0.6914123296737671\n",
            "Iter 1688: train loss: 0.6914101839065552\n",
            "Iter 1689: train loss: 0.6914079189300537\n",
            "Iter 1690: train loss: 0.6914057731628418\n",
            "Iter 1691: train loss: 0.6914035677909851\n",
            "Iter 1692: train loss: 0.6914013028144836\n",
            "Iter 1693: train loss: 0.6913991570472717\n",
            "Iter 1694: train loss: 0.6913970112800598\n",
            "Iter 1695: train loss: 0.6913946866989136\n",
            "Iter 1696: train loss: 0.6913924813270569\n",
            "Iter 1697: train loss: 0.691390335559845\n",
            "Iter 1698: train loss: 0.6913880705833435\n",
            "Iter 1699: train loss: 0.6913858652114868\n",
            "Iter 1700: train loss: 0.6913836598396301\n",
            "Iter 1701: train loss: 0.6913814544677734\n",
            "Iter 1702: train loss: 0.6913792490959167\n",
            "Iter 1703: train loss: 0.6913770437240601\n",
            "Iter 1704: train loss: 0.6913748383522034\n",
            "Iter 1705: train loss: 0.6913725733757019\n",
            "Iter 1706: train loss: 0.6913703680038452\n",
            "Iter 1707: train loss: 0.6913681030273438\n",
            "Iter 1708: train loss: 0.6913657784461975\n",
            "Iter 1709: train loss: 0.6913636326789856\n",
            "Iter 1710: train loss: 0.6913613080978394\n",
            "Iter 1711: train loss: 0.6913591027259827\n",
            "Iter 1712: train loss: 0.691356897354126\n",
            "Iter 1713: train loss: 0.6913546919822693\n",
            "Iter 1714: train loss: 0.691352367401123\n",
            "Iter 1715: train loss: 0.6913501024246216\n",
            "Iter 1716: train loss: 0.6913478970527649\n",
            "Iter 1717: train loss: 0.6913456916809082\n",
            "Iter 1718: train loss: 0.6913434267044067\n",
            "Iter 1719: train loss: 0.6913411021232605\n",
            "Iter 1720: train loss: 0.6913388967514038\n",
            "Iter 1721: train loss: 0.6913366317749023\n",
            "Iter 1722: train loss: 0.6913343667984009\n",
            "Iter 1723: train loss: 0.6913319826126099\n",
            "Iter 1724: train loss: 0.6913297772407532\n",
            "Iter 1725: train loss: 0.6913275122642517\n",
            "Iter 1726: train loss: 0.691325306892395\n",
            "Iter 1727: train loss: 0.6913229823112488\n",
            "Iter 1728: train loss: 0.6913206577301025\n",
            "Iter 1729: train loss: 0.6913184523582458\n",
            "Iter 1730: train loss: 0.6913161277770996\n",
            "Iter 1731: train loss: 0.6913138031959534\n",
            "Iter 1732: train loss: 0.6913115382194519\n",
            "Iter 1733: train loss: 0.6913092136383057\n",
            "Iter 1734: train loss: 0.6913069486618042\n",
            "Iter 1735: train loss: 0.691304624080658\n",
            "Iter 1736: train loss: 0.6913023591041565\n",
            "Iter 1737: train loss: 0.6913000345230103\n",
            "Iter 1738: train loss: 0.691297709941864\n",
            "Iter 1739: train loss: 0.6912954449653625\n",
            "Iter 1740: train loss: 0.6912931799888611\n",
            "Iter 1741: train loss: 0.6912908554077148\n",
            "Iter 1742: train loss: 0.6912884712219238\n",
            "Iter 1743: train loss: 0.6912861466407776\n",
            "Iter 1744: train loss: 0.6912838220596313\n",
            "Iter 1745: train loss: 0.6912814974784851\n",
            "Iter 1746: train loss: 0.6912792325019836\n",
            "Iter 1747: train loss: 0.6912769079208374\n",
            "Iter 1748: train loss: 0.6912745237350464\n",
            "Iter 1749: train loss: 0.6912721395492554\n",
            "Iter 1750: train loss: 0.6912698745727539\n",
            "Iter 1751: train loss: 0.6912675499916077\n",
            "Iter 1752: train loss: 0.6912652254104614\n",
            "Iter 1753: train loss: 0.6912629008293152\n",
            "Iter 1754: train loss: 0.6912606358528137\n",
            "Iter 1755: train loss: 0.6912582516670227\n",
            "Iter 1756: train loss: 0.6912558078765869\n",
            "Iter 1757: train loss: 0.6912534832954407\n",
            "Iter 1758: train loss: 0.6912511587142944\n",
            "Iter 1759: train loss: 0.6912488341331482\n",
            "Iter 1760: train loss: 0.6912464499473572\n",
            "Iter 1761: train loss: 0.6912441253662109\n",
            "Iter 1762: train loss: 0.6912416815757751\n",
            "Iter 1763: train loss: 0.6912392973899841\n",
            "Iter 1764: train loss: 0.6912369728088379\n",
            "Iter 1765: train loss: 0.6912346482276917\n",
            "Iter 1766: train loss: 0.6912322640419006\n",
            "Iter 1767: train loss: 0.6912298798561096\n",
            "Iter 1768: train loss: 0.6912274956703186\n",
            "Iter 1769: train loss: 0.6912250518798828\n",
            "Iter 1770: train loss: 0.691222608089447\n",
            "Iter 1771: train loss: 0.6912202835083008\n",
            "Iter 1772: train loss: 0.6912178993225098\n",
            "Iter 1773: train loss: 0.6912155151367188\n",
            "Iter 1774: train loss: 0.6912131905555725\n",
            "Iter 1775: train loss: 0.6912107467651367\n",
            "Iter 1776: train loss: 0.6912083625793457\n",
            "Iter 1777: train loss: 0.6912059783935547\n",
            "Iter 1778: train loss: 0.6912034749984741\n",
            "Iter 1779: train loss: 0.6912010908126831\n",
            "Iter 1780: train loss: 0.6911987066268921\n",
            "Iter 1781: train loss: 0.6911963820457458\n",
            "Iter 1782: train loss: 0.6911938786506653\n",
            "Iter 1783: train loss: 0.6911914348602295\n",
            "Iter 1784: train loss: 0.6911890506744385\n",
            "Iter 1785: train loss: 0.6911866664886475\n",
            "Iter 1786: train loss: 0.6911842226982117\n",
            "Iter 1787: train loss: 0.6911817193031311\n",
            "Iter 1788: train loss: 0.6911792755126953\n",
            "Iter 1789: train loss: 0.6911768913269043\n",
            "Iter 1790: train loss: 0.6911744475364685\n",
            "Iter 1791: train loss: 0.6911720037460327\n",
            "Iter 1792: train loss: 0.6911696195602417\n",
            "Iter 1793: train loss: 0.6911671161651611\n",
            "Iter 1794: train loss: 0.6911647319793701\n",
            "Iter 1795: train loss: 0.6911622285842896\n",
            "Iter 1796: train loss: 0.691159725189209\n",
            "Iter 1797: train loss: 0.691157341003418\n",
            "Iter 1798: train loss: 0.6911548972129822\n",
            "Iter 1799: train loss: 0.6911524534225464\n",
            "Iter 1800: train loss: 0.6911499500274658\n",
            "Iter 1801: train loss: 0.6911474466323853\n",
            "Iter 1802: train loss: 0.6911449432373047\n",
            "Iter 1803: train loss: 0.6911424994468689\n",
            "Iter 1804: train loss: 0.6911401152610779\n",
            "Iter 1805: train loss: 0.6911375522613525\n",
            "Iter 1806: train loss: 0.6911351084709167\n",
            "Iter 1807: train loss: 0.6911326050758362\n",
            "Iter 1808: train loss: 0.6911301016807556\n",
            "Iter 1809: train loss: 0.6911276578903198\n",
            "Iter 1810: train loss: 0.6911250948905945\n",
            "Iter 1811: train loss: 0.6911226511001587\n",
            "Iter 1812: train loss: 0.6911201477050781\n",
            "Iter 1813: train loss: 0.6911176443099976\n",
            "Iter 1814: train loss: 0.691115140914917\n",
            "Iter 1815: train loss: 0.6911126375198364\n",
            "Iter 1816: train loss: 0.6911101341247559\n",
            "Iter 1817: train loss: 0.6911075711250305\n",
            "Iter 1818: train loss: 0.69110506772995\n",
            "Iter 1819: train loss: 0.6911025643348694\n",
            "Iter 1820: train loss: 0.691100001335144\n",
            "Iter 1821: train loss: 0.6910974979400635\n",
            "Iter 1822: train loss: 0.6910949945449829\n",
            "Iter 1823: train loss: 0.6910924315452576\n",
            "Iter 1824: train loss: 0.691089928150177\n",
            "Iter 1825: train loss: 0.6910873651504517\n",
            "Iter 1826: train loss: 0.6910848021507263\n",
            "Iter 1827: train loss: 0.691082239151001\n",
            "Iter 1828: train loss: 0.6910797953605652\n",
            "Iter 1829: train loss: 0.6910772323608398\n",
            "Iter 1830: train loss: 0.6910746693611145\n",
            "Iter 1831: train loss: 0.6910720467567444\n",
            "Iter 1832: train loss: 0.6910695433616638\n",
            "Iter 1833: train loss: 0.6910669803619385\n",
            "Iter 1834: train loss: 0.6910644173622131\n",
            "Iter 1835: train loss: 0.691061794757843\n",
            "Iter 1836: train loss: 0.6910592317581177\n",
            "Iter 1837: train loss: 0.6910566687583923\n",
            "Iter 1838: train loss: 0.6910540461540222\n",
            "Iter 1839: train loss: 0.6910514831542969\n",
            "Iter 1840: train loss: 0.6910489201545715\n",
            "Iter 1841: train loss: 0.6910462975502014\n",
            "Iter 1842: train loss: 0.6910437345504761\n",
            "Iter 1843: train loss: 0.691041111946106\n",
            "Iter 1844: train loss: 0.6910384893417358\n",
            "Iter 1845: train loss: 0.6910359859466553\n",
            "Iter 1846: train loss: 0.6910333037376404\n",
            "Iter 1847: train loss: 0.691030740737915\n",
            "Iter 1848: train loss: 0.6910281181335449\n",
            "Iter 1849: train loss: 0.6910254955291748\n",
            "Iter 1850: train loss: 0.6910228729248047\n",
            "Iter 1851: train loss: 0.6910203099250793\n",
            "Iter 1852: train loss: 0.6910176873207092\n",
            "Iter 1853: train loss: 0.6910150647163391\n",
            "Iter 1854: train loss: 0.691012442111969\n",
            "Iter 1855: train loss: 0.6910097599029541\n",
            "Iter 1856: train loss: 0.6910071969032288\n",
            "Iter 1857: train loss: 0.6910044550895691\n",
            "Iter 1858: train loss: 0.691001832485199\n",
            "Iter 1859: train loss: 0.6909991502761841\n",
            "Iter 1860: train loss: 0.690996527671814\n",
            "Iter 1861: train loss: 0.6909938454627991\n",
            "Iter 1862: train loss: 0.690991222858429\n",
            "Iter 1863: train loss: 0.6909885406494141\n",
            "Iter 1864: train loss: 0.6909859776496887\n",
            "Iter 1865: train loss: 0.690983235836029\n",
            "Iter 1866: train loss: 0.6909805536270142\n",
            "Iter 1867: train loss: 0.6909778714179993\n",
            "Iter 1868: train loss: 0.6909753084182739\n",
            "Iter 1869: train loss: 0.6909725069999695\n",
            "Iter 1870: train loss: 0.6909698247909546\n",
            "Iter 1871: train loss: 0.6909671425819397\n",
            "Iter 1872: train loss: 0.6909644603729248\n",
            "Iter 1873: train loss: 0.6909618377685547\n",
            "Iter 1874: train loss: 0.6909591555595398\n",
            "Iter 1875: train loss: 0.6909564137458801\n",
            "Iter 1876: train loss: 0.6909536719322205\n",
            "Iter 1877: train loss: 0.6909509897232056\n",
            "Iter 1878: train loss: 0.6909482479095459\n",
            "Iter 1879: train loss: 0.6909455060958862\n",
            "Iter 1880: train loss: 0.6909427642822266\n",
            "Iter 1881: train loss: 0.6909402012825012\n",
            "Iter 1882: train loss: 0.6909373998641968\n",
            "Iter 1883: train loss: 0.6909347176551819\n",
            "Iter 1884: train loss: 0.6909319162368774\n",
            "Iter 1885: train loss: 0.6909292340278625\n",
            "Iter 1886: train loss: 0.6909265518188477\n",
            "Iter 1887: train loss: 0.6909236907958984\n",
            "Iter 1888: train loss: 0.6909210085868835\n",
            "Iter 1889: train loss: 0.6909183263778687\n",
            "Iter 1890: train loss: 0.6909154653549194\n",
            "Iter 1891: train loss: 0.6909127235412598\n",
            "Iter 1892: train loss: 0.6909099221229553\n",
            "Iter 1893: train loss: 0.6909071803092957\n",
            "Iter 1894: train loss: 0.690904438495636\n",
            "Iter 1895: train loss: 0.6909016370773315\n",
            "Iter 1896: train loss: 0.6908989548683167\n",
            "Iter 1897: train loss: 0.6908960938453674\n",
            "Iter 1898: train loss: 0.690893292427063\n",
            "Iter 1899: train loss: 0.6908905506134033\n",
            "Iter 1900: train loss: 0.6908877491950989\n",
            "Iter 1901: train loss: 0.6908849477767944\n",
            "Iter 1902: train loss: 0.6908822059631348\n",
            "Iter 1903: train loss: 0.6908793449401855\n",
            "Iter 1904: train loss: 0.6908766031265259\n",
            "Iter 1905: train loss: 0.6908737421035767\n",
            "Iter 1906: train loss: 0.6908709406852722\n",
            "Iter 1907: train loss: 0.690868079662323\n",
            "Iter 1908: train loss: 0.6908653378486633\n",
            "Iter 1909: train loss: 0.6908625960350037\n",
            "Iter 1910: train loss: 0.6908596158027649\n",
            "Iter 1911: train loss: 0.6908568143844604\n",
            "Iter 1912: train loss: 0.6908539533615112\n",
            "Iter 1913: train loss: 0.6908511519432068\n",
            "Iter 1914: train loss: 0.6908482909202576\n",
            "Iter 1915: train loss: 0.6908454895019531\n",
            "Iter 1916: train loss: 0.6908425688743591\n",
            "Iter 1917: train loss: 0.6908397674560547\n",
            "Iter 1918: train loss: 0.6908369660377502\n",
            "Iter 1919: train loss: 0.6908339858055115\n",
            "Iter 1920: train loss: 0.6908311247825623\n",
            "Iter 1921: train loss: 0.6908283233642578\n",
            "Iter 1922: train loss: 0.6908254623413086\n",
            "Iter 1923: train loss: 0.6908225417137146\n",
            "Iter 1924: train loss: 0.6908196210861206\n",
            "Iter 1925: train loss: 0.6908167600631714\n",
            "Iter 1926: train loss: 0.6908138990402222\n",
            "Iter 1927: train loss: 0.690811038017273\n",
            "Iter 1928: train loss: 0.6908080577850342\n",
            "Iter 1929: train loss: 0.6908052563667297\n",
            "Iter 1930: train loss: 0.6908023357391357\n",
            "Iter 1931: train loss: 0.6907994151115417\n",
            "Iter 1932: train loss: 0.6907964944839478\n",
            "Iter 1933: train loss: 0.690793514251709\n",
            "Iter 1934: train loss: 0.690790593624115\n",
            "Iter 1935: train loss: 0.690787672996521\n",
            "Iter 1936: train loss: 0.690784752368927\n",
            "Iter 1937: train loss: 0.6907818913459778\n",
            "Iter 1938: train loss: 0.690778911113739\n",
            "Iter 1939: train loss: 0.690775990486145\n",
            "Iter 1940: train loss: 0.6907730102539062\n",
            "Iter 1941: train loss: 0.6907700896263123\n",
            "Iter 1942: train loss: 0.6907671093940735\n",
            "Iter 1943: train loss: 0.6907641291618347\n",
            "Iter 1944: train loss: 0.6907612085342407\n",
            "Iter 1945: train loss: 0.690758228302002\n",
            "Iter 1946: train loss: 0.6907551884651184\n",
            "Iter 1947: train loss: 0.6907522082328796\n",
            "Iter 1948: train loss: 0.6907492876052856\n",
            "Iter 1949: train loss: 0.6907462477684021\n",
            "Iter 1950: train loss: 0.6907433271408081\n",
            "Iter 1951: train loss: 0.6907403469085693\n",
            "Iter 1952: train loss: 0.6907373666763306\n",
            "Iter 1953: train loss: 0.690734326839447\n",
            "Iter 1954: train loss: 0.6907313466072083\n",
            "Iter 1955: train loss: 0.6907282471656799\n",
            "Iter 1956: train loss: 0.6907253265380859\n",
            "Iter 1957: train loss: 0.6907222270965576\n",
            "Iter 1958: train loss: 0.6907192468643188\n",
            "Iter 1959: train loss: 0.6907162666320801\n",
            "Iter 1960: train loss: 0.6907131671905518\n",
            "Iter 1961: train loss: 0.690710186958313\n",
            "Iter 1962: train loss: 0.6907071471214294\n",
            "Iter 1963: train loss: 0.6907041072845459\n",
            "Iter 1964: train loss: 0.6907010078430176\n",
            "Iter 1965: train loss: 0.690697968006134\n",
            "Iter 1966: train loss: 0.6906949877738953\n",
            "Iter 1967: train loss: 0.6906918287277222\n",
            "Iter 1968: train loss: 0.6906888484954834\n",
            "Iter 1969: train loss: 0.6906857490539551\n",
            "Iter 1970: train loss: 0.6906826496124268\n",
            "Iter 1971: train loss: 0.6906795501708984\n",
            "Iter 1972: train loss: 0.6906765699386597\n",
            "Iter 1973: train loss: 0.6906734108924866\n",
            "Iter 1974: train loss: 0.6906703114509583\n",
            "Iter 1975: train loss: 0.6906672120094299\n",
            "Iter 1976: train loss: 0.6906641721725464\n",
            "Iter 1977: train loss: 0.6906609535217285\n",
            "Iter 1978: train loss: 0.690657913684845\n",
            "Iter 1979: train loss: 0.6906547546386719\n",
            "Iter 1980: train loss: 0.6906516551971436\n",
            "Iter 1981: train loss: 0.6906484961509705\n",
            "Iter 1982: train loss: 0.6906453371047974\n",
            "Iter 1983: train loss: 0.690642237663269\n",
            "Iter 1984: train loss: 0.690639078617096\n",
            "Iter 1985: train loss: 0.6906360387802124\n",
            "Iter 1986: train loss: 0.6906328201293945\n",
            "Iter 1987: train loss: 0.6906296610832214\n",
            "Iter 1988: train loss: 0.6906264424324036\n",
            "Iter 1989: train loss: 0.6906233429908752\n",
            "Iter 1990: train loss: 0.6906201839447021\n",
            "Iter 1991: train loss: 0.690617024898529\n",
            "Iter 1992: train loss: 0.6906139254570007\n",
            "Iter 1993: train loss: 0.6906106472015381\n",
            "Iter 1994: train loss: 0.6906074285507202\n",
            "Iter 1995: train loss: 0.6906042695045471\n",
            "Iter 1996: train loss: 0.6906010508537292\n",
            "Iter 1997: train loss: 0.6905978918075562\n",
            "Iter 1998: train loss: 0.6905946731567383\n",
            "Iter 1999: train loss: 0.6905914545059204\n",
            "Iter 2000: train loss: 0.6905882358551025\n",
            "Iter 2001: train loss: 0.6905850172042847\n",
            "Iter 2002: train loss: 0.690581738948822\n",
            "Iter 2003: train loss: 0.6905785799026489\n",
            "Iter 2004: train loss: 0.6905753016471863\n",
            "Iter 2005: train loss: 0.6905721426010132\n",
            "Iter 2006: train loss: 0.6905689239501953\n",
            "Iter 2007: train loss: 0.6905655264854431\n",
            "Iter 2008: train loss: 0.69056236743927\n",
            "Iter 2009: train loss: 0.6905590891838074\n",
            "Iter 2010: train loss: 0.6905558109283447\n",
            "Iter 2011: train loss: 0.6905525326728821\n",
            "Iter 2012: train loss: 0.6905492544174194\n",
            "Iter 2013: train loss: 0.6905460357666016\n",
            "Iter 2014: train loss: 0.6905427575111389\n",
            "Iter 2015: train loss: 0.6905394792556763\n",
            "Iter 2016: train loss: 0.6905361413955688\n",
            "Iter 2017: train loss: 0.6905328035354614\n",
            "Iter 2018: train loss: 0.6905295252799988\n",
            "Iter 2019: train loss: 0.6905262470245361\n",
            "Iter 2020: train loss: 0.6905228495597839\n",
            "Iter 2021: train loss: 0.6905195713043213\n",
            "Iter 2022: train loss: 0.6905162334442139\n",
            "Iter 2023: train loss: 0.6905129551887512\n",
            "Iter 2024: train loss: 0.6905096173286438\n",
            "Iter 2025: train loss: 0.6905062198638916\n",
            "Iter 2026: train loss: 0.6905028223991394\n",
            "Iter 2027: train loss: 0.690499484539032\n",
            "Iter 2028: train loss: 0.6904962062835693\n",
            "Iter 2029: train loss: 0.6904928684234619\n",
            "Iter 2030: train loss: 0.6904894709587097\n",
            "Iter 2031: train loss: 0.6904861330986023\n",
            "Iter 2032: train loss: 0.6904826760292053\n",
            "Iter 2033: train loss: 0.6904793381690979\n",
            "Iter 2034: train loss: 0.6904758810997009\n",
            "Iter 2035: train loss: 0.6904725432395935\n",
            "Iter 2036: train loss: 0.6904692053794861\n",
            "Iter 2037: train loss: 0.6904656291007996\n",
            "Iter 2038: train loss: 0.6904622912406921\n",
            "Iter 2039: train loss: 0.6904589533805847\n",
            "Iter 2040: train loss: 0.6904555559158325\n",
            "Iter 2041: train loss: 0.6904520392417908\n",
            "Iter 2042: train loss: 0.6904485821723938\n",
            "Iter 2043: train loss: 0.6904451847076416\n",
            "Iter 2044: train loss: 0.6904417276382446\n",
            "Iter 2045: train loss: 0.6904382705688477\n",
            "Iter 2046: train loss: 0.6904348134994507\n",
            "Iter 2047: train loss: 0.6904314160346985\n",
            "Iter 2048: train loss: 0.6904278993606567\n",
            "Iter 2049: train loss: 0.690424382686615\n",
            "Iter 2050: train loss: 0.690420925617218\n",
            "Iter 2051: train loss: 0.6904175281524658\n",
            "Iter 2052: train loss: 0.6904139518737793\n",
            "Iter 2053: train loss: 0.6904104948043823\n",
            "Iter 2054: train loss: 0.6904069781303406\n",
            "Iter 2055: train loss: 0.6904034614562988\n",
            "Iter 2056: train loss: 0.6903999447822571\n",
            "Iter 2057: train loss: 0.6903964281082153\n",
            "Iter 2058: train loss: 0.6903929114341736\n",
            "Iter 2059: train loss: 0.6903893947601318\n",
            "Iter 2060: train loss: 0.6903858184814453\n",
            "Iter 2061: train loss: 0.6903823018074036\n",
            "Iter 2062: train loss: 0.6903787851333618\n",
            "Iter 2063: train loss: 0.6903752684593201\n",
            "Iter 2064: train loss: 0.6903716325759888\n",
            "Iter 2065: train loss: 0.690368115901947\n",
            "Iter 2066: train loss: 0.6903645396232605\n",
            "Iter 2067: train loss: 0.690360963344574\n",
            "Iter 2068: train loss: 0.6903574466705322\n",
            "Iter 2069: train loss: 0.6903538107872009\n",
            "Iter 2070: train loss: 0.6903502345085144\n",
            "Iter 2071: train loss: 0.6903465986251831\n",
            "Iter 2072: train loss: 0.6903429627418518\n",
            "Iter 2073: train loss: 0.6903393864631653\n",
            "Iter 2074: train loss: 0.690335750579834\n",
            "Iter 2075: train loss: 0.6903321146965027\n",
            "Iter 2076: train loss: 0.6903284788131714\n",
            "Iter 2077: train loss: 0.6903247833251953\n",
            "Iter 2078: train loss: 0.6903212070465088\n",
            "Iter 2079: train loss: 0.6903175711631775\n",
            "Iter 2080: train loss: 0.6903139352798462\n",
            "Iter 2081: train loss: 0.6903102993965149\n",
            "Iter 2082: train loss: 0.6903066039085388\n",
            "Iter 2083: train loss: 0.6903029680252075\n",
            "Iter 2084: train loss: 0.6902992129325867\n",
            "Iter 2085: train loss: 0.6902955174446106\n",
            "Iter 2086: train loss: 0.6902918815612793\n",
            "Iter 2087: train loss: 0.6902881860733032\n",
            "Iter 2088: train loss: 0.6902844309806824\n",
            "Iter 2089: train loss: 0.6902807354927063\n",
            "Iter 2090: train loss: 0.690277099609375\n",
            "Iter 2091: train loss: 0.6902733445167542\n",
            "Iter 2092: train loss: 0.6902695894241333\n",
            "Iter 2093: train loss: 0.6902658343315125\n",
            "Iter 2094: train loss: 0.6902621388435364\n",
            "Iter 2095: train loss: 0.6902583837509155\n",
            "Iter 2096: train loss: 0.6902546286582947\n",
            "Iter 2097: train loss: 0.6902508735656738\n",
            "Iter 2098: train loss: 0.6902471780776978\n",
            "Iter 2099: train loss: 0.6902433633804321\n",
            "Iter 2100: train loss: 0.6902396082878113\n",
            "Iter 2101: train loss: 0.6902357935905457\n",
            "Iter 2102: train loss: 0.69023197889328\n",
            "Iter 2103: train loss: 0.6902281641960144\n",
            "Iter 2104: train loss: 0.6902244091033936\n",
            "Iter 2105: train loss: 0.6902205348014832\n",
            "Iter 2106: train loss: 0.6902167201042175\n",
            "Iter 2107: train loss: 0.6902129054069519\n",
            "Iter 2108: train loss: 0.6902090907096863\n",
            "Iter 2109: train loss: 0.6902052760124207\n",
            "Iter 2110: train loss: 0.690201461315155\n",
            "Iter 2111: train loss: 0.6901975870132446\n",
            "Iter 2112: train loss: 0.6901937127113342\n",
            "Iter 2113: train loss: 0.6901898384094238\n",
            "Iter 2114: train loss: 0.6901859641075134\n",
            "Iter 2115: train loss: 0.690182089805603\n",
            "Iter 2116: train loss: 0.6901781558990479\n",
            "Iter 2117: train loss: 0.6901742815971375\n",
            "Iter 2118: train loss: 0.690170407295227\n",
            "Iter 2119: train loss: 0.6901665329933167\n",
            "Iter 2120: train loss: 0.6901625990867615\n",
            "Iter 2121: train loss: 0.6901586055755615\n",
            "Iter 2122: train loss: 0.6901547312736511\n",
            "Iter 2123: train loss: 0.690150797367096\n",
            "Iter 2124: train loss: 0.690146803855896\n",
            "Iter 2125: train loss: 0.6901428699493408\n",
            "Iter 2126: train loss: 0.6901389956474304\n",
            "Iter 2127: train loss: 0.6901350617408752\n",
            "Iter 2128: train loss: 0.6901310086250305\n",
            "Iter 2129: train loss: 0.6901270747184753\n",
            "Iter 2130: train loss: 0.6901231408119202\n",
            "Iter 2131: train loss: 0.6901190876960754\n",
            "Iter 2132: train loss: 0.6901150345802307\n",
            "Iter 2133: train loss: 0.6901111006736755\n",
            "Iter 2134: train loss: 0.6901071071624756\n",
            "Iter 2135: train loss: 0.6901031136512756\n",
            "Iter 2136: train loss: 0.6900990605354309\n",
            "Iter 2137: train loss: 0.6900949478149414\n",
            "Iter 2138: train loss: 0.6900908946990967\n",
            "Iter 2139: train loss: 0.6900869011878967\n",
            "Iter 2140: train loss: 0.690082848072052\n",
            "Iter 2141: train loss: 0.6900787949562073\n",
            "Iter 2142: train loss: 0.6900747418403625\n",
            "Iter 2143: train loss: 0.690070629119873\n",
            "Iter 2144: train loss: 0.6900665760040283\n",
            "Iter 2145: train loss: 0.6900625824928284\n",
            "Iter 2146: train loss: 0.6900583505630493\n",
            "Iter 2147: train loss: 0.690054178237915\n",
            "Iter 2148: train loss: 0.6900501251220703\n",
            "Iter 2149: train loss: 0.6900460720062256\n",
            "Iter 2150: train loss: 0.6900419592857361\n",
            "Iter 2151: train loss: 0.6900378465652466\n",
            "Iter 2152: train loss: 0.6900336146354675\n",
            "Iter 2153: train loss: 0.690029501914978\n",
            "Iter 2154: train loss: 0.6900253891944885\n",
            "Iter 2155: train loss: 0.6900211572647095\n",
            "Iter 2156: train loss: 0.69001704454422\n",
            "Iter 2157: train loss: 0.6900128722190857\n",
            "Iter 2158: train loss: 0.6900085806846619\n",
            "Iter 2159: train loss: 0.6900044083595276\n",
            "Iter 2160: train loss: 0.6900002360343933\n",
            "Iter 2161: train loss: 0.6899960041046143\n",
            "Iter 2162: train loss: 0.6899917125701904\n",
            "Iter 2163: train loss: 0.6899875402450562\n",
            "Iter 2164: train loss: 0.6899833679199219\n",
            "Iter 2165: train loss: 0.689979076385498\n",
            "Iter 2166: train loss: 0.689974844455719\n",
            "Iter 2167: train loss: 0.6899705529212952\n",
            "Iter 2168: train loss: 0.6899663209915161\n",
            "Iter 2169: train loss: 0.6899620294570923\n",
            "Iter 2170: train loss: 0.6899577975273132\n",
            "Iter 2171: train loss: 0.6899535059928894\n",
            "Iter 2172: train loss: 0.6899491548538208\n",
            "Iter 2173: train loss: 0.6899448037147522\n",
            "Iter 2174: train loss: 0.6899405717849731\n",
            "Iter 2175: train loss: 0.6899362206459045\n",
            "Iter 2176: train loss: 0.6899318695068359\n",
            "Iter 2177: train loss: 0.6899275779724121\n",
            "Iter 2178: train loss: 0.6899232864379883\n",
            "Iter 2179: train loss: 0.6899188756942749\n",
            "Iter 2180: train loss: 0.6899145245552063\n",
            "Iter 2181: train loss: 0.6899102330207825\n",
            "Iter 2182: train loss: 0.6899057626724243\n",
            "Iter 2183: train loss: 0.6899013519287109\n",
            "Iter 2184: train loss: 0.6898970007896423\n",
            "Iter 2185: train loss: 0.6898925304412842\n",
            "Iter 2186: train loss: 0.6898881196975708\n",
            "Iter 2187: train loss: 0.6898837089538574\n",
            "Iter 2188: train loss: 0.6898793578147888\n",
            "Iter 2189: train loss: 0.6898749470710754\n",
            "Iter 2190: train loss: 0.6898704171180725\n",
            "Iter 2191: train loss: 0.6898660063743591\n",
            "Iter 2192: train loss: 0.689861536026001\n",
            "Iter 2193: train loss: 0.6898570656776428\n",
            "Iter 2194: train loss: 0.6898525953292847\n",
            "Iter 2195: train loss: 0.6898481249809265\n",
            "Iter 2196: train loss: 0.6898435950279236\n",
            "Iter 2197: train loss: 0.6898391246795654\n",
            "Iter 2198: train loss: 0.6898345351219177\n",
            "Iter 2199: train loss: 0.6898300647735596\n",
            "Iter 2200: train loss: 0.6898255348205566\n",
            "Iter 2201: train loss: 0.6898209452629089\n",
            "Iter 2202: train loss: 0.689816415309906\n",
            "Iter 2203: train loss: 0.6898118257522583\n",
            "Iter 2204: train loss: 0.6898072957992554\n",
            "Iter 2205: train loss: 0.6898027062416077\n",
            "Iter 2206: train loss: 0.6897981762886047\n",
            "Iter 2207: train loss: 0.6897935271263123\n",
            "Iter 2208: train loss: 0.6897889375686646\n",
            "Iter 2209: train loss: 0.6897843480110168\n",
            "Iter 2210: train loss: 0.6897796988487244\n",
            "Iter 2211: train loss: 0.6897751688957214\n",
            "Iter 2212: train loss: 0.6897704601287842\n",
            "Iter 2213: train loss: 0.6897658109664917\n",
            "Iter 2214: train loss: 0.6897611618041992\n",
            "Iter 2215: train loss: 0.6897565126419067\n",
            "Iter 2216: train loss: 0.6897518038749695\n",
            "Iter 2217: train loss: 0.689747154712677\n",
            "Iter 2218: train loss: 0.6897424459457397\n",
            "Iter 2219: train loss: 0.6897377371788025\n",
            "Iter 2220: train loss: 0.68973308801651\n",
            "Iter 2221: train loss: 0.6897283792495728\n",
            "Iter 2222: train loss: 0.689723551273346\n",
            "Iter 2223: train loss: 0.6897189021110535\n",
            "Iter 2224: train loss: 0.6897141337394714\n",
            "Iter 2225: train loss: 0.6897093653678894\n",
            "Iter 2226: train loss: 0.6897045373916626\n",
            "Iter 2227: train loss: 0.6896998882293701\n",
            "Iter 2228: train loss: 0.6896950006484985\n",
            "Iter 2229: train loss: 0.6896902322769165\n",
            "Iter 2230: train loss: 0.6896854639053345\n",
            "Iter 2231: train loss: 0.6896805763244629\n",
            "Iter 2232: train loss: 0.6896758675575256\n",
            "Iter 2233: train loss: 0.689670979976654\n",
            "Iter 2234: train loss: 0.6896660923957825\n",
            "Iter 2235: train loss: 0.6896612644195557\n",
            "Iter 2236: train loss: 0.6896564364433289\n",
            "Iter 2237: train loss: 0.689651608467102\n",
            "Iter 2238: train loss: 0.6896467208862305\n",
            "Iter 2239: train loss: 0.6896418929100037\n",
            "Iter 2240: train loss: 0.6896368861198425\n",
            "Iter 2241: train loss: 0.6896319389343262\n",
            "Iter 2242: train loss: 0.6896271109580994\n",
            "Iter 2243: train loss: 0.6896221041679382\n",
            "Iter 2244: train loss: 0.6896171569824219\n",
            "Iter 2245: train loss: 0.6896123290061951\n",
            "Iter 2246: train loss: 0.6896072626113892\n",
            "Iter 2247: train loss: 0.6896024346351624\n",
            "Iter 2248: train loss: 0.6895974278450012\n",
            "Iter 2249: train loss: 0.6895923614501953\n",
            "Iter 2250: train loss: 0.6895873546600342\n",
            "Iter 2251: train loss: 0.6895822882652283\n",
            "Iter 2252: train loss: 0.6895772814750671\n",
            "Iter 2253: train loss: 0.6895723342895508\n",
            "Iter 2254: train loss: 0.6895672082901001\n",
            "Iter 2255: train loss: 0.689562201499939\n",
            "Iter 2256: train loss: 0.6895570755004883\n",
            "Iter 2257: train loss: 0.6895520687103271\n",
            "Iter 2258: train loss: 0.6895470023155212\n",
            "Iter 2259: train loss: 0.6895419359207153\n",
            "Iter 2260: train loss: 0.6895368099212646\n",
            "Iter 2261: train loss: 0.689531683921814\n",
            "Iter 2262: train loss: 0.6895266771316528\n",
            "Iter 2263: train loss: 0.6895214319229126\n",
            "Iter 2264: train loss: 0.6895162463188171\n",
            "Iter 2265: train loss: 0.6895111799240112\n",
            "Iter 2266: train loss: 0.689505934715271\n",
            "Iter 2267: train loss: 0.6895008087158203\n",
            "Iter 2268: train loss: 0.6894956231117249\n",
            "Iter 2269: train loss: 0.6894904971122742\n",
            "Iter 2270: train loss: 0.6894851922988892\n",
            "Iter 2271: train loss: 0.6894800066947937\n",
            "Iter 2272: train loss: 0.6894747614860535\n",
            "Iter 2273: train loss: 0.6894695162773132\n",
            "Iter 2274: train loss: 0.689464271068573\n",
            "Iter 2275: train loss: 0.6894590258598328\n",
            "Iter 2276: train loss: 0.6894537806510925\n",
            "Iter 2277: train loss: 0.6894484758377075\n",
            "Iter 2278: train loss: 0.6894431710243225\n",
            "Iter 2279: train loss: 0.6894378662109375\n",
            "Iter 2280: train loss: 0.6894326210021973\n",
            "Iter 2281: train loss: 0.6894272565841675\n",
            "Iter 2282: train loss: 0.6894219517707825\n",
            "Iter 2283: train loss: 0.6894165873527527\n",
            "Iter 2284: train loss: 0.6894112229347229\n",
            "Iter 2285: train loss: 0.6894057989120483\n",
            "Iter 2286: train loss: 0.6894004940986633\n",
            "Iter 2287: train loss: 0.6893951296806335\n",
            "Iter 2288: train loss: 0.6893896460533142\n",
            "Iter 2289: train loss: 0.6893842816352844\n",
            "Iter 2290: train loss: 0.6893788576126099\n",
            "Iter 2291: train loss: 0.6893734931945801\n",
            "Iter 2292: train loss: 0.689367949962616\n",
            "Iter 2293: train loss: 0.6893624663352966\n",
            "Iter 2294: train loss: 0.6893570423126221\n",
            "Iter 2295: train loss: 0.689351499080658\n",
            "Iter 2296: train loss: 0.6893460154533386\n",
            "Iter 2297: train loss: 0.6893405318260193\n",
            "Iter 2298: train loss: 0.6893350481987\n",
            "Iter 2299: train loss: 0.6893294453620911\n",
            "Iter 2300: train loss: 0.6893239617347717\n",
            "Iter 2301: train loss: 0.6893183588981628\n",
            "Iter 2302: train loss: 0.6893128156661987\n",
            "Iter 2303: train loss: 0.6893072724342346\n",
            "Iter 2304: train loss: 0.689301609992981\n",
            "Iter 2305: train loss: 0.6892960667610168\n",
            "Iter 2306: train loss: 0.6892904043197632\n",
            "Iter 2307: train loss: 0.6892847418785095\n",
            "Iter 2308: train loss: 0.6892791986465454\n",
            "Iter 2309: train loss: 0.6892735362052917\n",
            "Iter 2310: train loss: 0.6892679333686829\n",
            "Iter 2311: train loss: 0.6892622113227844\n",
            "Iter 2312: train loss: 0.6892565488815308\n",
            "Iter 2313: train loss: 0.6892507672309875\n",
            "Iter 2314: train loss: 0.6892451047897339\n",
            "Iter 2315: train loss: 0.6892393827438354\n",
            "Iter 2316: train loss: 0.6892336010932922\n",
            "Iter 2317: train loss: 0.6892279386520386\n",
            "Iter 2318: train loss: 0.6892221570014954\n",
            "Iter 2319: train loss: 0.6892163157463074\n",
            "Iter 2320: train loss: 0.6892105937004089\n",
            "Iter 2321: train loss: 0.6892048120498657\n",
            "Iter 2322: train loss: 0.6891990303993225\n",
            "Iter 2323: train loss: 0.6891931295394897\n",
            "Iter 2324: train loss: 0.6891873478889465\n",
            "Iter 2325: train loss: 0.6891815662384033\n",
            "Iter 2326: train loss: 0.6891756057739258\n",
            "Iter 2327: train loss: 0.6891697645187378\n",
            "Iter 2328: train loss: 0.689163863658905\n",
            "Iter 2329: train loss: 0.6891578435897827\n",
            "Iter 2330: train loss: 0.6891520619392395\n",
            "Iter 2331: train loss: 0.689146101474762\n",
            "Iter 2332: train loss: 0.6891402006149292\n",
            "Iter 2333: train loss: 0.6891342997550964\n",
            "Iter 2334: train loss: 0.6891283392906189\n",
            "Iter 2335: train loss: 0.6891222596168518\n",
            "Iter 2336: train loss: 0.6891162991523743\n",
            "Iter 2337: train loss: 0.689110279083252\n",
            "Iter 2338: train loss: 0.6891043186187744\n",
            "Iter 2339: train loss: 0.6890982985496521\n",
            "Iter 2340: train loss: 0.689092218875885\n",
            "Iter 2341: train loss: 0.6890861392021179\n",
            "Iter 2342: train loss: 0.6890800595283508\n",
            "Iter 2343: train loss: 0.6890740394592285\n",
            "Iter 2344: train loss: 0.6890679001808167\n",
            "Iter 2345: train loss: 0.6890618801116943\n",
            "Iter 2346: train loss: 0.6890557408332825\n",
            "Iter 2347: train loss: 0.6890496015548706\n",
            "Iter 2348: train loss: 0.689043402671814\n",
            "Iter 2349: train loss: 0.6890372633934021\n",
            "Iter 2350: train loss: 0.6890311241149902\n",
            "Iter 2351: train loss: 0.6890249848365784\n",
            "Iter 2352: train loss: 0.689018726348877\n",
            "Iter 2353: train loss: 0.6890125274658203\n",
            "Iter 2354: train loss: 0.6890062093734741\n",
            "Iter 2355: train loss: 0.6889999508857727\n",
            "Iter 2356: train loss: 0.6889937520027161\n",
            "Iter 2357: train loss: 0.6889874935150146\n",
            "Iter 2358: train loss: 0.6889811754226685\n",
            "Iter 2359: train loss: 0.688974916934967\n",
            "Iter 2360: train loss: 0.6889685392379761\n",
            "Iter 2361: train loss: 0.6889622807502747\n",
            "Iter 2362: train loss: 0.6889558434486389\n",
            "Iter 2363: train loss: 0.6889495849609375\n",
            "Iter 2364: train loss: 0.6889432072639465\n",
            "Iter 2365: train loss: 0.6889367699623108\n",
            "Iter 2366: train loss: 0.6889304518699646\n",
            "Iter 2367: train loss: 0.6889240145683289\n",
            "Iter 2368: train loss: 0.6889176368713379\n",
            "Iter 2369: train loss: 0.6889110803604126\n",
            "Iter 2370: train loss: 0.6889046430587769\n",
            "Iter 2371: train loss: 0.6888982057571411\n",
            "Iter 2372: train loss: 0.6888917088508606\n",
            "Iter 2373: train loss: 0.6888851523399353\n",
            "Iter 2374: train loss: 0.6888786554336548\n",
            "Iter 2375: train loss: 0.6888721585273743\n",
            "Iter 2376: train loss: 0.688865602016449\n",
            "Iter 2377: train loss: 0.6888590455055237\n",
            "Iter 2378: train loss: 0.6888524889945984\n",
            "Iter 2379: train loss: 0.6888459324836731\n",
            "Iter 2380: train loss: 0.6888392567634583\n",
            "Iter 2381: train loss: 0.6888326406478882\n",
            "Iter 2382: train loss: 0.6888260245323181\n",
            "Iter 2383: train loss: 0.688819408416748\n",
            "Iter 2384: train loss: 0.6888127326965332\n",
            "Iter 2385: train loss: 0.6888060569763184\n",
            "Iter 2386: train loss: 0.6887993216514587\n",
            "Iter 2387: train loss: 0.6887925863265991\n",
            "Iter 2388: train loss: 0.688785970211029\n",
            "Iter 2389: train loss: 0.6887791156768799\n",
            "Iter 2390: train loss: 0.6887723803520203\n",
            "Iter 2391: train loss: 0.6887656450271606\n",
            "Iter 2392: train loss: 0.6887588500976562\n",
            "Iter 2393: train loss: 0.6887519955635071\n",
            "Iter 2394: train loss: 0.6887451410293579\n",
            "Iter 2395: train loss: 0.6887384057044983\n",
            "Iter 2396: train loss: 0.6887315511703491\n",
            "Iter 2397: train loss: 0.6887246966362\n",
            "Iter 2398: train loss: 0.6887177228927612\n",
            "Iter 2399: train loss: 0.6887108683586121\n",
            "Iter 2400: train loss: 0.6887039542198181\n",
            "Iter 2401: train loss: 0.688697099685669\n",
            "Iter 2402: train loss: 0.6886901259422302\n",
            "Iter 2403: train loss: 0.6886832118034363\n",
            "Iter 2404: train loss: 0.688676118850708\n",
            "Iter 2405: train loss: 0.6886690855026245\n",
            "Iter 2406: train loss: 0.6886621713638306\n",
            "Iter 2407: train loss: 0.6886551380157471\n",
            "Iter 2408: train loss: 0.6886480450630188\n",
            "Iter 2409: train loss: 0.6886410713195801\n",
            "Iter 2410: train loss: 0.688633918762207\n",
            "Iter 2411: train loss: 0.6886268854141235\n",
            "Iter 2412: train loss: 0.6886197328567505\n",
            "Iter 2413: train loss: 0.6886125802993774\n",
            "Iter 2414: train loss: 0.6886054873466492\n",
            "Iter 2415: train loss: 0.6885982751846313\n",
            "Iter 2416: train loss: 0.6885911822319031\n",
            "Iter 2417: train loss: 0.6885839700698853\n",
            "Iter 2418: train loss: 0.6885766983032227\n",
            "Iter 2419: train loss: 0.6885694861412048\n",
            "Iter 2420: train loss: 0.6885622143745422\n",
            "Iter 2421: train loss: 0.6885549426078796\n",
            "Iter 2422: train loss: 0.688547670841217\n",
            "Iter 2423: train loss: 0.6885404586791992\n",
            "Iter 2424: train loss: 0.6885330677032471\n",
            "Iter 2425: train loss: 0.6885257959365845\n",
            "Iter 2426: train loss: 0.6885184645652771\n",
            "Iter 2427: train loss: 0.688511073589325\n",
            "Iter 2428: train loss: 0.688503623008728\n",
            "Iter 2429: train loss: 0.6884962916374207\n",
            "Iter 2430: train loss: 0.6884888410568237\n",
            "Iter 2431: train loss: 0.6884814500808716\n",
            "Iter 2432: train loss: 0.6884739398956299\n",
            "Iter 2433: train loss: 0.6884665489196777\n",
            "Iter 2434: train loss: 0.688459038734436\n",
            "Iter 2435: train loss: 0.6884515285491943\n",
            "Iter 2436: train loss: 0.6884438991546631\n",
            "Iter 2437: train loss: 0.6884363889694214\n",
            "Iter 2438: train loss: 0.6884288787841797\n",
            "Iter 2439: train loss: 0.6884213089942932\n",
            "Iter 2440: train loss: 0.6884136199951172\n",
            "Iter 2441: train loss: 0.6884060502052307\n",
            "Iter 2442: train loss: 0.6883984208106995\n",
            "Iter 2443: train loss: 0.6883907318115234\n",
            "Iter 2444: train loss: 0.6883831024169922\n",
            "Iter 2445: train loss: 0.6883754730224609\n",
            "Iter 2446: train loss: 0.6883677840232849\n",
            "Iter 2447: train loss: 0.6883600354194641\n",
            "Iter 2448: train loss: 0.6883522868156433\n",
            "Iter 2449: train loss: 0.6883445978164673\n",
            "Iter 2450: train loss: 0.6883367300033569\n",
            "Iter 2451: train loss: 0.6883288621902466\n",
            "Iter 2452: train loss: 0.688321053981781\n",
            "Iter 2453: train loss: 0.6883131861686707\n",
            "Iter 2454: train loss: 0.6883053779602051\n",
            "Iter 2455: train loss: 0.6882975697517395\n",
            "Iter 2456: train loss: 0.6882896423339844\n",
            "Iter 2457: train loss: 0.6882817149162292\n",
            "Iter 2458: train loss: 0.6882737874984741\n",
            "Iter 2459: train loss: 0.688265860080719\n",
            "Iter 2460: train loss: 0.6882578730583191\n",
            "Iter 2461: train loss: 0.6882498264312744\n",
            "Iter 2462: train loss: 0.6882418990135193\n",
            "Iter 2463: train loss: 0.6882338523864746\n",
            "Iter 2464: train loss: 0.6882257461547852\n",
            "Iter 2465: train loss: 0.68821781873703\n",
            "Iter 2466: train loss: 0.6882096529006958\n",
            "Iter 2467: train loss: 0.6882015466690063\n",
            "Iter 2468: train loss: 0.6881933808326721\n",
            "Iter 2469: train loss: 0.6881853342056274\n",
            "Iter 2470: train loss: 0.6881771087646484\n",
            "Iter 2471: train loss: 0.6881688833236694\n",
            "Iter 2472: train loss: 0.6881606578826904\n",
            "Iter 2473: train loss: 0.6881524920463562\n",
            "Iter 2474: train loss: 0.6881442070007324\n",
            "Iter 2475: train loss: 0.6881359219551086\n",
            "Iter 2476: train loss: 0.6881276369094849\n",
            "Iter 2477: train loss: 0.6881194114685059\n",
            "Iter 2478: train loss: 0.6881110072135925\n",
            "Iter 2479: train loss: 0.688102662563324\n",
            "Iter 2480: train loss: 0.6880943179130554\n",
            "Iter 2481: train loss: 0.6880859136581421\n",
            "Iter 2482: train loss: 0.6880775094032288\n",
            "Iter 2483: train loss: 0.6880690455436707\n",
            "Iter 2484: train loss: 0.6880607008934021\n",
            "Iter 2485: train loss: 0.6880521774291992\n",
            "Iter 2486: train loss: 0.6880436539649963\n",
            "Iter 2487: train loss: 0.6880350708961487\n",
            "Iter 2488: train loss: 0.6880265474319458\n",
            "Iter 2489: train loss: 0.6880180835723877\n",
            "Iter 2490: train loss: 0.68800950050354\n",
            "Iter 2491: train loss: 0.6880007982254028\n",
            "Iter 2492: train loss: 0.6879922151565552\n",
            "Iter 2493: train loss: 0.6879836320877075\n",
            "Iter 2494: train loss: 0.6879749894142151\n",
            "Iter 2495: train loss: 0.6879662275314331\n",
            "Iter 2496: train loss: 0.6879575252532959\n",
            "Iter 2497: train loss: 0.6879488229751587\n",
            "Iter 2498: train loss: 0.6879400014877319\n",
            "Iter 2499: train loss: 0.6879312992095947\n",
            "Iter 2500: train loss: 0.687922477722168\n",
            "Iter 2501: train loss: 0.687913715839386\n",
            "Iter 2502: train loss: 0.6879048347473145\n",
            "Iter 2503: train loss: 0.6878959536552429\n",
            "Iter 2504: train loss: 0.6878870725631714\n",
            "Iter 2505: train loss: 0.6878781914710999\n",
            "Iter 2506: train loss: 0.6878692507743835\n",
            "Iter 2507: train loss: 0.6878603100776672\n",
            "Iter 2508: train loss: 0.6878513097763062\n",
            "Iter 2509: train loss: 0.6878423094749451\n",
            "Iter 2510: train loss: 0.687833309173584\n",
            "Iter 2511: train loss: 0.6878242492675781\n",
            "Iter 2512: train loss: 0.687815248966217\n",
            "Iter 2513: train loss: 0.6878060698509216\n",
            "Iter 2514: train loss: 0.687796950340271\n",
            "Iter 2515: train loss: 0.6877878904342651\n",
            "Iter 2516: train loss: 0.6877787709236145\n",
            "Iter 2517: train loss: 0.6877694725990295\n",
            "Iter 2518: train loss: 0.6877602934837341\n",
            "Iter 2519: train loss: 0.6877511143684387\n",
            "Iter 2520: train loss: 0.6877419352531433\n",
            "Iter 2521: train loss: 0.6877325773239136\n",
            "Iter 2522: train loss: 0.6877232789993286\n",
            "Iter 2523: train loss: 0.6877139806747437\n",
            "Iter 2524: train loss: 0.6877046227455139\n",
            "Iter 2525: train loss: 0.6876952648162842\n",
            "Iter 2526: train loss: 0.6876858472824097\n",
            "Iter 2527: train loss: 0.6876764297485352\n",
            "Iter 2528: train loss: 0.6876670122146606\n",
            "Iter 2529: train loss: 0.6876574754714966\n",
            "Iter 2530: train loss: 0.6876480579376221\n",
            "Iter 2531: train loss: 0.687638521194458\n",
            "Iter 2532: train loss: 0.687628984451294\n",
            "Iter 2533: train loss: 0.6876194477081299\n",
            "Iter 2534: train loss: 0.6876099109649658\n",
            "Iter 2535: train loss: 0.6876002550125122\n",
            "Iter 2536: train loss: 0.6875906586647034\n",
            "Iter 2537: train loss: 0.687580943107605\n",
            "Iter 2538: train loss: 0.6875711679458618\n",
            "Iter 2539: train loss: 0.6875616312026978\n",
            "Iter 2540: train loss: 0.6875517964363098\n",
            "Iter 2541: train loss: 0.6875421404838562\n",
            "Iter 2542: train loss: 0.6875323057174683\n",
            "Iter 2543: train loss: 0.6875224709510803\n",
            "Iter 2544: train loss: 0.6875126361846924\n",
            "Iter 2545: train loss: 0.6875027418136597\n",
            "Iter 2546: train loss: 0.6874929666519165\n",
            "Iter 2547: train loss: 0.687483012676239\n",
            "Iter 2548: train loss: 0.6874730587005615\n",
            "Iter 2549: train loss: 0.6874631643295288\n",
            "Iter 2550: train loss: 0.6874530911445618\n",
            "Iter 2551: train loss: 0.6874431371688843\n",
            "Iter 2552: train loss: 0.687433123588562\n",
            "Iter 2553: train loss: 0.6874229907989502\n",
            "Iter 2554: train loss: 0.6874129176139832\n",
            "Iter 2555: train loss: 0.6874027848243713\n",
            "Iter 2556: train loss: 0.6873925924301147\n",
            "Iter 2557: train loss: 0.6873824596405029\n",
            "Iter 2558: train loss: 0.6873722672462463\n",
            "Iter 2559: train loss: 0.687362015247345\n",
            "Iter 2560: train loss: 0.6873518228530884\n",
            "Iter 2561: train loss: 0.687341570854187\n",
            "Iter 2562: train loss: 0.6873312592506409\n",
            "Iter 2563: train loss: 0.68732088804245\n",
            "Iter 2564: train loss: 0.687310516834259\n",
            "Iter 2565: train loss: 0.6873000860214233\n",
            "Iter 2566: train loss: 0.6872897744178772\n",
            "Iter 2567: train loss: 0.6872793436050415\n",
            "Iter 2568: train loss: 0.687268853187561\n",
            "Iter 2569: train loss: 0.687258243560791\n",
            "Iter 2570: train loss: 0.6872478127479553\n",
            "Iter 2571: train loss: 0.6872372627258301\n",
            "Iter 2572: train loss: 0.6872266530990601\n",
            "Iter 2573: train loss: 0.68721604347229\n",
            "Iter 2574: train loss: 0.6872054934501648\n",
            "Iter 2575: train loss: 0.6871947646141052\n",
            "Iter 2576: train loss: 0.6871840953826904\n",
            "Iter 2577: train loss: 0.6871733665466309\n",
            "Iter 2578: train loss: 0.6871626377105713\n",
            "Iter 2579: train loss: 0.6871518492698669\n",
            "Iter 2580: train loss: 0.6871411204338074\n",
            "Iter 2581: train loss: 0.6871302723884583\n",
            "Iter 2582: train loss: 0.6871194243431091\n",
            "Iter 2583: train loss: 0.6871085166931152\n",
            "Iter 2584: train loss: 0.6870975494384766\n",
            "Iter 2585: train loss: 0.6870866417884827\n",
            "Iter 2586: train loss: 0.687075674533844\n",
            "Iter 2587: train loss: 0.6870646476745605\n",
            "Iter 2588: train loss: 0.6870537400245667\n",
            "Iter 2589: train loss: 0.6870425939559937\n",
            "Iter 2590: train loss: 0.6870314478874207\n",
            "Iter 2591: train loss: 0.6870203614234924\n",
            "Iter 2592: train loss: 0.6870092749595642\n",
            "Iter 2593: train loss: 0.6869980692863464\n",
            "Iter 2594: train loss: 0.6869869232177734\n",
            "Iter 2595: train loss: 0.6869755983352661\n",
            "Iter 2596: train loss: 0.6869642734527588\n",
            "Iter 2597: train loss: 0.6869530081748962\n",
            "Iter 2598: train loss: 0.6869416832923889\n",
            "Iter 2599: train loss: 0.6869303584098816\n",
            "Iter 2600: train loss: 0.6869189739227295\n",
            "Iter 2601: train loss: 0.6869075894355774\n",
            "Iter 2602: train loss: 0.686896026134491\n",
            "Iter 2603: train loss: 0.6868846416473389\n",
            "Iter 2604: train loss: 0.6868730783462524\n",
            "Iter 2605: train loss: 0.686861515045166\n",
            "Iter 2606: train loss: 0.6868499517440796\n",
            "Iter 2607: train loss: 0.6868383884429932\n",
            "Iter 2608: train loss: 0.686826765537262\n",
            "Iter 2609: train loss: 0.6868150234222412\n",
            "Iter 2610: train loss: 0.68680340051651\n",
            "Iter 2611: train loss: 0.6867916584014893\n",
            "Iter 2612: train loss: 0.6867798566818237\n",
            "Iter 2613: train loss: 0.6867680549621582\n",
            "Iter 2614: train loss: 0.6867561936378479\n",
            "Iter 2615: train loss: 0.6867443919181824\n",
            "Iter 2616: train loss: 0.6867325305938721\n",
            "Iter 2617: train loss: 0.686720609664917\n",
            "Iter 2618: train loss: 0.6867086887359619\n",
            "Iter 2619: train loss: 0.6866967082023621\n",
            "Iter 2620: train loss: 0.6866847276687622\n",
            "Iter 2621: train loss: 0.686672568321228\n",
            "Iter 2622: train loss: 0.6866604685783386\n",
            "Iter 2623: train loss: 0.6866483688354492\n",
            "Iter 2624: train loss: 0.6866362690925598\n",
            "Iter 2625: train loss: 0.6866241097450256\n",
            "Iter 2626: train loss: 0.6866118311882019\n",
            "Iter 2627: train loss: 0.686599612236023\n",
            "Iter 2628: train loss: 0.6865874528884888\n",
            "Iter 2629: train loss: 0.6865750551223755\n",
            "Iter 2630: train loss: 0.6865626573562622\n",
            "Iter 2631: train loss: 0.6865503787994385\n",
            "Iter 2632: train loss: 0.6865379810333252\n",
            "Iter 2633: train loss: 0.6865253448486328\n",
            "Iter 2634: train loss: 0.6865129470825195\n",
            "Iter 2635: train loss: 0.6865004301071167\n",
            "Iter 2636: train loss: 0.6864879727363586\n",
            "Iter 2637: train loss: 0.6864753365516663\n",
            "Iter 2638: train loss: 0.6864627003669739\n",
            "Iter 2639: train loss: 0.6864501237869263\n",
            "Iter 2640: train loss: 0.6864374279975891\n",
            "Iter 2641: train loss: 0.6864246726036072\n",
            "Iter 2642: train loss: 0.6864118576049805\n",
            "Iter 2643: train loss: 0.6863991022109985\n",
            "Iter 2644: train loss: 0.6863862872123718\n",
            "Iter 2645: train loss: 0.6863734126091003\n",
            "Iter 2646: train loss: 0.6863604784011841\n",
            "Iter 2647: train loss: 0.6863476037979126\n",
            "Iter 2648: train loss: 0.6863346099853516\n",
            "Iter 2649: train loss: 0.6863216757774353\n",
            "Iter 2650: train loss: 0.6863086223602295\n",
            "Iter 2651: train loss: 0.6862955093383789\n",
            "Iter 2652: train loss: 0.6862824559211731\n",
            "Iter 2653: train loss: 0.686269223690033\n",
            "Iter 2654: train loss: 0.6862560510635376\n",
            "Iter 2655: train loss: 0.6862428784370422\n",
            "Iter 2656: train loss: 0.6862296462059021\n",
            "Iter 2657: train loss: 0.6862163543701172\n",
            "Iter 2658: train loss: 0.6862030625343323\n",
            "Iter 2659: train loss: 0.6861896514892578\n",
            "Iter 2660: train loss: 0.6861762404441833\n",
            "Iter 2661: train loss: 0.6861627697944641\n",
            "Iter 2662: train loss: 0.6861492991447449\n",
            "Iter 2663: train loss: 0.6861358284950256\n",
            "Iter 2664: train loss: 0.6861222386360168\n",
            "Iter 2665: train loss: 0.6861085891723633\n",
            "Iter 2666: train loss: 0.6860949993133545\n",
            "Iter 2667: train loss: 0.6860813498497009\n",
            "Iter 2668: train loss: 0.6860676407814026\n",
            "Iter 2669: train loss: 0.6860539317131042\n",
            "Iter 2670: train loss: 0.6860401630401611\n",
            "Iter 2671: train loss: 0.6860262751579285\n",
            "Iter 2672: train loss: 0.6860125660896301\n",
            "Iter 2673: train loss: 0.6859986186027527\n",
            "Iter 2674: train loss: 0.6859846711158752\n",
            "Iter 2675: train loss: 0.6859708428382874\n",
            "Iter 2676: train loss: 0.6859567165374756\n",
            "Iter 2677: train loss: 0.6859427094459534\n",
            "Iter 2678: train loss: 0.6859285831451416\n",
            "Iter 2679: train loss: 0.6859144568443298\n",
            "Iter 2680: train loss: 0.6859002709388733\n",
            "Iter 2681: train loss: 0.6858860850334167\n",
            "Iter 2682: train loss: 0.6858718395233154\n",
            "Iter 2683: train loss: 0.6858575940132141\n",
            "Iter 2684: train loss: 0.6858432292938232\n",
            "Iter 2685: train loss: 0.6858288645744324\n",
            "Iter 2686: train loss: 0.6858144998550415\n",
            "Iter 2687: train loss: 0.6858000755310059\n",
            "Iter 2688: train loss: 0.6857855319976807\n",
            "Iter 2689: train loss: 0.6857709884643555\n",
            "Iter 2690: train loss: 0.6857563853263855\n",
            "Iter 2691: train loss: 0.6857419013977051\n",
            "Iter 2692: train loss: 0.6857271790504456\n",
            "Iter 2693: train loss: 0.6857125759124756\n",
            "Iter 2694: train loss: 0.6856977343559265\n",
            "Iter 2695: train loss: 0.6856830716133118\n",
            "Iter 2696: train loss: 0.6856682896614075\n",
            "Iter 2697: train loss: 0.6856533885002136\n",
            "Iter 2698: train loss: 0.6856384873390198\n",
            "Iter 2699: train loss: 0.6856235265731812\n",
            "Iter 2700: train loss: 0.6856085658073425\n",
            "Iter 2701: train loss: 0.6855935454368591\n",
            "Iter 2702: train loss: 0.685578465461731\n",
            "Iter 2703: train loss: 0.6855633854866028\n",
            "Iter 2704: train loss: 0.6855483055114746\n",
            "Iter 2705: train loss: 0.6855331063270569\n",
            "Iter 2706: train loss: 0.6855178475379944\n",
            "Iter 2707: train loss: 0.6855025887489319\n",
            "Iter 2708: train loss: 0.6854872703552246\n",
            "Iter 2709: train loss: 0.6854718923568726\n",
            "Iter 2710: train loss: 0.6854564547538757\n",
            "Iter 2711: train loss: 0.6854410171508789\n",
            "Iter 2712: train loss: 0.6854254603385925\n",
            "Iter 2713: train loss: 0.6854100227355957\n",
            "Iter 2714: train loss: 0.6853944063186646\n",
            "Iter 2715: train loss: 0.6853787899017334\n",
            "Iter 2716: train loss: 0.6853631138801575\n",
            "Iter 2717: train loss: 0.6853473782539368\n",
            "Iter 2718: train loss: 0.6853316426277161\n",
            "Iter 2719: train loss: 0.6853159666061401\n",
            "Iter 2720: train loss: 0.6852999925613403\n",
            "Iter 2721: train loss: 0.6852841973304749\n",
            "Iter 2722: train loss: 0.685268223285675\n",
            "Iter 2723: train loss: 0.6852522492408752\n",
            "Iter 2724: train loss: 0.6852362155914307\n",
            "Iter 2725: train loss: 0.6852201223373413\n",
            "Iter 2726: train loss: 0.685204029083252\n",
            "Iter 2727: train loss: 0.685187816619873\n",
            "Iter 2728: train loss: 0.6851716041564941\n",
            "Iter 2729: train loss: 0.6851553916931152\n",
            "Iter 2730: train loss: 0.6851391196250916\n",
            "Iter 2731: train loss: 0.6851227879524231\n",
            "Iter 2732: train loss: 0.6851063370704651\n",
            "Iter 2733: train loss: 0.6850898861885071\n",
            "Iter 2734: train loss: 0.6850733757019043\n",
            "Iter 2735: train loss: 0.6850568652153015\n",
            "Iter 2736: train loss: 0.6850402355194092\n",
            "Iter 2737: train loss: 0.6850236654281616\n",
            "Iter 2738: train loss: 0.6850070953369141\n",
            "Iter 2739: train loss: 0.6849902868270874\n",
            "Iter 2740: train loss: 0.6849734783172607\n",
            "Iter 2741: train loss: 0.6849567890167236\n",
            "Iter 2742: train loss: 0.6849399209022522\n",
            "Iter 2743: train loss: 0.6849228739738464\n",
            "Iter 2744: train loss: 0.6849059462547302\n",
            "Iter 2745: train loss: 0.6848889589309692\n",
            "Iter 2746: train loss: 0.6848719716072083\n",
            "Iter 2747: train loss: 0.6848548054695129\n",
            "Iter 2748: train loss: 0.6848376393318176\n",
            "Iter 2749: train loss: 0.6848204135894775\n",
            "Iter 2750: train loss: 0.6848032474517822\n",
            "Iter 2751: train loss: 0.6847859025001526\n",
            "Iter 2752: train loss: 0.6847684383392334\n",
            "Iter 2753: train loss: 0.6847510933876038\n",
            "Iter 2754: train loss: 0.6847336888313293\n",
            "Iter 2755: train loss: 0.6847161650657654\n",
            "Iter 2756: train loss: 0.6846985220909119\n",
            "Iter 2757: train loss: 0.6846809983253479\n",
            "Iter 2758: train loss: 0.6846633553504944\n",
            "Iter 2759: train loss: 0.6846455931663513\n",
            "Iter 2760: train loss: 0.684627890586853\n",
            "Iter 2761: train loss: 0.6846100687980652\n",
            "Iter 2762: train loss: 0.6845921874046326\n",
            "Iter 2763: train loss: 0.6845743060112\n",
            "Iter 2764: train loss: 0.6845563650131226\n",
            "Iter 2765: train loss: 0.6845383048057556\n",
            "Iter 2766: train loss: 0.6845202445983887\n",
            "Iter 2767: train loss: 0.684502124786377\n",
            "Iter 2768: train loss: 0.6844840049743652\n",
            "Iter 2769: train loss: 0.684465765953064\n",
            "Iter 2770: train loss: 0.6844475269317627\n",
            "Iter 2771: train loss: 0.6844291687011719\n",
            "Iter 2772: train loss: 0.6844107508659363\n",
            "Iter 2773: train loss: 0.6843922734260559\n",
            "Iter 2774: train loss: 0.6843738555908203\n",
            "Iter 2775: train loss: 0.6843553185462952\n",
            "Iter 2776: train loss: 0.6843366622924805\n",
            "Iter 2777: train loss: 0.6843180656433105\n",
            "Iter 2778: train loss: 0.6842993497848511\n",
            "Iter 2779: train loss: 0.6842805743217468\n",
            "Iter 2780: train loss: 0.6842617988586426\n",
            "Iter 2781: train loss: 0.6842429041862488\n",
            "Iter 2782: train loss: 0.6842239499092102\n",
            "Iter 2783: train loss: 0.6842049956321716\n",
            "Iter 2784: train loss: 0.6841859817504883\n",
            "Iter 2785: train loss: 0.6841669678688049\n",
            "Iter 2786: train loss: 0.684147834777832\n",
            "Iter 2787: train loss: 0.6841286420822144\n",
            "Iter 2788: train loss: 0.6841093897819519\n",
            "Iter 2789: train loss: 0.6840901374816895\n",
            "Iter 2790: train loss: 0.6840707659721375\n",
            "Iter 2791: train loss: 0.6840513348579407\n",
            "Iter 2792: train loss: 0.6840317845344543\n",
            "Iter 2793: train loss: 0.6840123534202576\n",
            "Iter 2794: train loss: 0.6839926838874817\n",
            "Iter 2795: train loss: 0.6839730739593506\n",
            "Iter 2796: train loss: 0.6839534640312195\n",
            "Iter 2797: train loss: 0.6839337348937988\n",
            "Iter 2798: train loss: 0.6839137673377991\n",
            "Iter 2799: train loss: 0.6838939785957336\n",
            "Iter 2800: train loss: 0.6838740706443787\n",
            "Iter 2801: train loss: 0.6838540434837341\n",
            "Iter 2802: train loss: 0.6838340163230896\n",
            "Iter 2803: train loss: 0.6838139891624451\n",
            "Iter 2804: train loss: 0.6837937235832214\n",
            "Iter 2805: train loss: 0.6837735772132874\n",
            "Iter 2806: train loss: 0.683753252029419\n",
            "Iter 2807: train loss: 0.6837329268455505\n",
            "Iter 2808: train loss: 0.6837126016616821\n",
            "Iter 2809: train loss: 0.6836920976638794\n",
            "Iter 2810: train loss: 0.6836715340614319\n",
            "Iter 2811: train loss: 0.6836509704589844\n",
            "Iter 2812: train loss: 0.6836302876472473\n",
            "Iter 2813: train loss: 0.683609664440155\n",
            "Iter 2814: train loss: 0.6835889220237732\n",
            "Iter 2815: train loss: 0.683568000793457\n",
            "Iter 2816: train loss: 0.6835471987724304\n",
            "Iter 2817: train loss: 0.6835262775421143\n",
            "Iter 2818: train loss: 0.6835052967071533\n",
            "Iter 2819: train loss: 0.6834841966629028\n",
            "Iter 2820: train loss: 0.6834630966186523\n",
            "Iter 2821: train loss: 0.6834418773651123\n",
            "Iter 2822: train loss: 0.6834206581115723\n",
            "Iter 2823: train loss: 0.6833993792533875\n",
            "Iter 2824: train loss: 0.6833779215812683\n",
            "Iter 2825: train loss: 0.6833565831184387\n",
            "Iter 2826: train loss: 0.68333500623703\n",
            "Iter 2827: train loss: 0.6833135485649109\n",
            "Iter 2828: train loss: 0.6832918524742126\n",
            "Iter 2829: train loss: 0.6832701563835144\n",
            "Iter 2830: train loss: 0.6832485198974609\n",
            "Iter 2831: train loss: 0.6832267045974731\n",
            "Iter 2832: train loss: 0.6832048296928406\n",
            "Iter 2833: train loss: 0.6831828355789185\n",
            "Iter 2834: train loss: 0.6831608414649963\n",
            "Iter 2835: train loss: 0.6831387877464294\n",
            "Iter 2836: train loss: 0.683116614818573\n",
            "Iter 2837: train loss: 0.6830945014953613\n",
            "Iter 2838: train loss: 0.6830722093582153\n",
            "Iter 2839: train loss: 0.6830499172210693\n",
            "Iter 2840: train loss: 0.6830275058746338\n",
            "Iter 2841: train loss: 0.6830050945281982\n",
            "Iter 2842: train loss: 0.6829825639724731\n",
            "Iter 2843: train loss: 0.682960033416748\n",
            "Iter 2844: train loss: 0.6829373240470886\n",
            "Iter 2845: train loss: 0.6829145550727844\n",
            "Iter 2846: train loss: 0.6828917264938354\n",
            "Iter 2847: train loss: 0.6828688979148865\n",
            "Iter 2848: train loss: 0.6828460097312927\n",
            "Iter 2849: train loss: 0.6828230619430542\n",
            "Iter 2850: train loss: 0.6828000545501709\n",
            "Iter 2851: train loss: 0.6827768087387085\n",
            "Iter 2852: train loss: 0.6827536821365356\n",
            "Iter 2853: train loss: 0.682730495929718\n",
            "Iter 2854: train loss: 0.6827071309089661\n",
            "Iter 2855: train loss: 0.6826837658882141\n",
            "Iter 2856: train loss: 0.6826602220535278\n",
            "Iter 2857: train loss: 0.6826366782188416\n",
            "Iter 2858: train loss: 0.6826130747795105\n",
            "Iter 2859: train loss: 0.6825895309448242\n",
            "Iter 2860: train loss: 0.6825656890869141\n",
            "Iter 2861: train loss: 0.6825419068336487\n",
            "Iter 2862: train loss: 0.6825180649757385\n",
            "Iter 2863: train loss: 0.6824941039085388\n",
            "Iter 2864: train loss: 0.6824701428413391\n",
            "Iter 2865: train loss: 0.6824460029602051\n",
            "Iter 2866: train loss: 0.682421863079071\n",
            "Iter 2867: train loss: 0.6823976635932922\n",
            "Iter 2868: train loss: 0.6823732852935791\n",
            "Iter 2869: train loss: 0.6823490262031555\n",
            "Iter 2870: train loss: 0.6823245286941528\n",
            "Iter 2871: train loss: 0.6822999715805054\n",
            "Iter 2872: train loss: 0.6822754740715027\n",
            "Iter 2873: train loss: 0.6822506785392761\n",
            "Iter 2874: train loss: 0.6822260618209839\n",
            "Iter 2875: train loss: 0.6822012662887573\n",
            "Iter 2876: train loss: 0.682176411151886\n",
            "Iter 2877: train loss: 0.6821514368057251\n",
            "Iter 2878: train loss: 0.6821264624595642\n",
            "Iter 2879: train loss: 0.682101309299469\n",
            "Iter 2880: train loss: 0.6820761561393738\n",
            "Iter 2881: train loss: 0.682050883769989\n",
            "Iter 2882: train loss: 0.6820255517959595\n",
            "Iter 2883: train loss: 0.6820001602172852\n",
            "Iter 2884: train loss: 0.6819747090339661\n",
            "Iter 2885: train loss: 0.6819491982460022\n",
            "Iter 2886: train loss: 0.6819235682487488\n",
            "Iter 2887: train loss: 0.6818978786468506\n",
            "Iter 2888: train loss: 0.6818721890449524\n",
            "Iter 2889: train loss: 0.6818462610244751\n",
            "Iter 2890: train loss: 0.6818203926086426\n",
            "Iter 2891: train loss: 0.6817944049835205\n",
            "Iter 2892: train loss: 0.6817683577537537\n",
            "Iter 2893: train loss: 0.6817421317100525\n",
            "Iter 2894: train loss: 0.6817159056663513\n",
            "Iter 2895: train loss: 0.6816896796226501\n",
            "Iter 2896: train loss: 0.6816632747650146\n",
            "Iter 2897: train loss: 0.6816368699073792\n",
            "Iter 2898: train loss: 0.6816102862358093\n",
            "Iter 2899: train loss: 0.6815837025642395\n",
            "Iter 2900: train loss: 0.6815570592880249\n",
            "Iter 2901: train loss: 0.681530237197876\n",
            "Iter 2902: train loss: 0.6815033555030823\n",
            "Iter 2903: train loss: 0.6814764142036438\n",
            "Iter 2904: train loss: 0.6814494132995605\n",
            "Iter 2905: train loss: 0.6814224123954773\n",
            "Iter 2906: train loss: 0.6813952326774597\n",
            "Iter 2907: train loss: 0.6813679933547974\n",
            "Iter 2908: train loss: 0.6813406944274902\n",
            "Iter 2909: train loss: 0.6813132762908936\n",
            "Iter 2910: train loss: 0.6812857985496521\n",
            "Iter 2911: train loss: 0.6812582612037659\n",
            "Iter 2912: train loss: 0.6812306046485901\n",
            "Iter 2913: train loss: 0.6812028884887695\n",
            "Iter 2914: train loss: 0.6811751127243042\n",
            "Iter 2915: train loss: 0.6811470985412598\n",
            "Iter 2916: train loss: 0.6811192035675049\n",
            "Iter 2917: train loss: 0.6810911893844604\n",
            "Iter 2918: train loss: 0.6810630559921265\n",
            "Iter 2919: train loss: 0.6810348629951477\n",
            "Iter 2920: train loss: 0.6810065507888794\n",
            "Iter 2921: train loss: 0.6809781789779663\n",
            "Iter 2922: train loss: 0.6809496879577637\n",
            "Iter 2923: train loss: 0.680921196937561\n",
            "Iter 2924: train loss: 0.6808924674987793\n",
            "Iter 2925: train loss: 0.6808637976646423\n",
            "Iter 2926: train loss: 0.6808350086212158\n",
            "Iter 2927: train loss: 0.6808061003684998\n",
            "Iter 2928: train loss: 0.6807771325111389\n",
            "Iter 2929: train loss: 0.6807481050491333\n",
            "Iter 2930: train loss: 0.6807189583778381\n",
            "Iter 2931: train loss: 0.680689811706543\n",
            "Iter 2932: train loss: 0.6806604266166687\n",
            "Iter 2933: train loss: 0.6806311011314392\n",
            "Iter 2934: train loss: 0.6806015372276306\n",
            "Iter 2935: train loss: 0.680571973323822\n",
            "Iter 2936: train loss: 0.6805424094200134\n",
            "Iter 2937: train loss: 0.6805126070976257\n",
            "Iter 2938: train loss: 0.680482804775238\n",
            "Iter 2939: train loss: 0.680452823638916\n",
            "Iter 2940: train loss: 0.6804229617118835\n",
            "Iter 2941: train loss: 0.6803927421569824\n",
            "Iter 2942: train loss: 0.6803626418113708\n",
            "Iter 2943: train loss: 0.680332362651825\n",
            "Iter 2944: train loss: 0.6803020238876343\n",
            "Iter 2945: train loss: 0.680271565914154\n",
            "Iter 2946: train loss: 0.6802411079406738\n",
            "Iter 2947: train loss: 0.6802104115486145\n",
            "Iter 2948: train loss: 0.6801797151565552\n",
            "Iter 2949: train loss: 0.6801489591598511\n",
            "Iter 2950: train loss: 0.6801180243492126\n",
            "Iter 2951: train loss: 0.6800870299339294\n",
            "Iter 2952: train loss: 0.6800559759140015\n",
            "Iter 2953: train loss: 0.6800248622894287\n",
            "Iter 2954: train loss: 0.6799935698509216\n",
            "Iter 2955: train loss: 0.6799622774124146\n",
            "Iter 2956: train loss: 0.6799308657646179\n",
            "Iter 2957: train loss: 0.6798992156982422\n",
            "Iter 2958: train loss: 0.679867684841156\n",
            "Iter 2959: train loss: 0.6798359751701355\n",
            "Iter 2960: train loss: 0.6798040866851807\n",
            "Iter 2961: train loss: 0.6797722578048706\n",
            "Iter 2962: train loss: 0.6797402501106262\n",
            "Iter 2963: train loss: 0.6797081828117371\n",
            "Iter 2964: train loss: 0.6796760559082031\n",
            "Iter 2965: train loss: 0.6796436905860901\n",
            "Iter 2966: train loss: 0.6796113848686218\n",
            "Iter 2967: train loss: 0.6795789003372192\n",
            "Iter 2968: train loss: 0.6795464158058167\n",
            "Iter 2969: train loss: 0.6795137524604797\n",
            "Iter 2970: train loss: 0.679481029510498\n",
            "Iter 2971: train loss: 0.6794482469558716\n",
            "Iter 2972: train loss: 0.679415225982666\n",
            "Iter 2973: train loss: 0.6793822050094604\n",
            "Iter 2974: train loss: 0.6793491244316101\n",
            "Iter 2975: train loss: 0.6793158650398254\n",
            "Iter 2976: train loss: 0.679282546043396\n",
            "Iter 2977: train loss: 0.6792492270469666\n",
            "Iter 2978: train loss: 0.679215669631958\n",
            "Iter 2979: train loss: 0.6791820526123047\n",
            "Iter 2980: train loss: 0.6791483759880066\n",
            "Iter 2981: train loss: 0.6791146397590637\n",
            "Iter 2982: train loss: 0.6790806651115417\n",
            "Iter 2983: train loss: 0.679046630859375\n",
            "Iter 2984: train loss: 0.679012656211853\n",
            "Iter 2985: train loss: 0.678978443145752\n",
            "Iter 2986: train loss: 0.6789440512657166\n",
            "Iter 2987: train loss: 0.6789097189903259\n",
            "Iter 2988: train loss: 0.678875207901001\n",
            "Iter 2989: train loss: 0.6788405776023865\n",
            "Iter 2990: train loss: 0.678805947303772\n",
            "Iter 2991: train loss: 0.6787711381912231\n",
            "Iter 2992: train loss: 0.6787362098693848\n",
            "Iter 2993: train loss: 0.6787012815475464\n",
            "Iter 2994: train loss: 0.6786661744117737\n",
            "Iter 2995: train loss: 0.6786310076713562\n",
            "Iter 2996: train loss: 0.6785957217216492\n",
            "Iter 2997: train loss: 0.6785602569580078\n",
            "Iter 2998: train loss: 0.6785247921943665\n",
            "Iter 2999: train loss: 0.6784892082214355\n",
            "Iter 3000: train loss: 0.6784534454345703\n",
            "Iter 3001: train loss: 0.6784177422523499\n",
            "Iter 3002: train loss: 0.6783818006515503\n",
            "Iter 3003: train loss: 0.6783457398414612\n",
            "Iter 3004: train loss: 0.6783096790313721\n",
            "Iter 3005: train loss: 0.6782733798027039\n",
            "Iter 3006: train loss: 0.6782370805740356\n",
            "Iter 3007: train loss: 0.6782006621360779\n",
            "Iter 3008: train loss: 0.6781641244888306\n",
            "Iter 3009: train loss: 0.6781274676322937\n",
            "Iter 3010: train loss: 0.6780908107757568\n",
            "Iter 3011: train loss: 0.6780539751052856\n",
            "Iter 3012: train loss: 0.6780170202255249\n",
            "Iter 3013: train loss: 0.6779798865318298\n",
            "Iter 3014: train loss: 0.67794269323349\n",
            "Iter 3015: train loss: 0.6779054999351501\n",
            "Iter 3016: train loss: 0.6778680086135864\n",
            "Iter 3017: train loss: 0.6778305768966675\n",
            "Iter 3018: train loss: 0.677793025970459\n",
            "Iter 3019: train loss: 0.6777552962303162\n",
            "Iter 3020: train loss: 0.6777174472808838\n",
            "Iter 3021: train loss: 0.6776795387268066\n",
            "Iter 3022: train loss: 0.6776414513587952\n",
            "Iter 3023: train loss: 0.6776034235954285\n",
            "Iter 3024: train loss: 0.6775650978088379\n",
            "Iter 3025: train loss: 0.6775267720222473\n",
            "Iter 3026: train loss: 0.6774883270263672\n",
            "Iter 3027: train loss: 0.6774497032165527\n",
            "Iter 3028: train loss: 0.6774110794067383\n",
            "Iter 3029: train loss: 0.6773722767829895\n",
            "Iter 3030: train loss: 0.6773333549499512\n",
            "Iter 3031: train loss: 0.6772943735122681\n",
            "Iter 3032: train loss: 0.6772553324699402\n",
            "Iter 3033: train loss: 0.677216112613678\n",
            "Iter 3034: train loss: 0.6771766543388367\n",
            "Iter 3035: train loss: 0.6771371960639954\n",
            "Iter 3036: train loss: 0.6770976781845093\n",
            "Iter 3037: train loss: 0.6770579814910889\n",
            "Iter 3038: train loss: 0.6770181059837341\n",
            "Iter 3039: train loss: 0.6769782900810242\n",
            "Iter 3040: train loss: 0.6769381761550903\n",
            "Iter 3041: train loss: 0.6768980622291565\n",
            "Iter 3042: train loss: 0.6768577694892883\n",
            "Iter 3043: train loss: 0.6768174767494202\n",
            "Iter 3044: train loss: 0.6767769455909729\n",
            "Iter 3045: train loss: 0.6767364144325256\n",
            "Iter 3046: train loss: 0.6766956448554993\n",
            "Iter 3047: train loss: 0.6766548752784729\n",
            "Iter 3048: train loss: 0.6766139268875122\n",
            "Iter 3049: train loss: 0.676572859287262\n",
            "Iter 3050: train loss: 0.6765317320823669\n",
            "Iter 3051: train loss: 0.6764904260635376\n",
            "Iter 3052: train loss: 0.6764490604400635\n",
            "Iter 3053: train loss: 0.676407516002655\n",
            "Iter 3054: train loss: 0.676365852355957\n",
            "Iter 3055: train loss: 0.6763241291046143\n",
            "Iter 3056: train loss: 0.6762822866439819\n",
            "Iter 3057: train loss: 0.6762402653694153\n",
            "Iter 3058: train loss: 0.6761981248855591\n",
            "Iter 3059: train loss: 0.6761559844017029\n",
            "Iter 3060: train loss: 0.6761136651039124\n",
            "Iter 3061: train loss: 0.6760711669921875\n",
            "Iter 3062: train loss: 0.6760286092758179\n",
            "Iter 3063: train loss: 0.6759858727455139\n",
            "Iter 3064: train loss: 0.6759430766105652\n",
            "Iter 3065: train loss: 0.6759001612663269\n",
            "Iter 3066: train loss: 0.6758570671081543\n",
            "Iter 3067: train loss: 0.6758138537406921\n",
            "Iter 3068: train loss: 0.67577064037323\n",
            "Iter 3069: train loss: 0.6757271885871887\n",
            "Iter 3070: train loss: 0.6756837368011475\n",
            "Iter 3071: train loss: 0.6756400465965271\n",
            "Iter 3072: train loss: 0.6755962371826172\n",
            "Iter 3073: train loss: 0.6755523681640625\n",
            "Iter 3074: train loss: 0.6755082011222839\n",
            "Iter 3075: train loss: 0.6754640936851501\n",
            "Iter 3076: train loss: 0.6754198670387268\n",
            "Iter 3077: train loss: 0.6753755211830139\n",
            "Iter 3078: train loss: 0.6753309965133667\n",
            "Iter 3079: train loss: 0.6752863526344299\n",
            "Iter 3080: train loss: 0.6752415299415588\n",
            "Iter 3081: train loss: 0.6751967072486877\n",
            "Iter 3082: train loss: 0.6751516461372375\n",
            "Iter 3083: train loss: 0.6751066446304321\n",
            "Iter 3084: train loss: 0.6750613451004028\n",
            "Iter 3085: train loss: 0.6750158667564392\n",
            "Iter 3086: train loss: 0.6749703884124756\n",
            "Iter 3087: train loss: 0.6749247312545776\n",
            "Iter 3088: train loss: 0.6748790740966797\n",
            "Iter 3089: train loss: 0.6748331785202026\n",
            "Iter 3090: train loss: 0.674787163734436\n",
            "Iter 3091: train loss: 0.6747410297393799\n",
            "Iter 3092: train loss: 0.6746947169303894\n",
            "Iter 3093: train loss: 0.6746483445167542\n",
            "Iter 3094: train loss: 0.6746018528938293\n",
            "Iter 3095: train loss: 0.6745551824569702\n",
            "Iter 3096: train loss: 0.6745084524154663\n",
            "Iter 3097: train loss: 0.6744615435600281\n",
            "Iter 3098: train loss: 0.6744145154953003\n",
            "Iter 3099: train loss: 0.674367368221283\n",
            "Iter 3100: train loss: 0.6743200421333313\n",
            "Iter 3101: train loss: 0.6742725372314453\n",
            "Iter 3102: train loss: 0.6742250919342041\n",
            "Iter 3103: train loss: 0.6741774082183838\n",
            "Iter 3104: train loss: 0.6741295456886292\n",
            "Iter 3105: train loss: 0.6740817427635193\n",
            "Iter 3106: train loss: 0.6740335822105408\n",
            "Iter 3107: train loss: 0.6739853620529175\n",
            "Iter 3108: train loss: 0.6739370822906494\n",
            "Iter 3109: train loss: 0.673888623714447\n",
            "Iter 3110: train loss: 0.6738400459289551\n",
            "Iter 3111: train loss: 0.6737913489341736\n",
            "Iter 3112: train loss: 0.6737424731254578\n",
            "Iter 3113: train loss: 0.6736934781074524\n",
            "Iter 3114: train loss: 0.6736443638801575\n",
            "Iter 3115: train loss: 0.673595130443573\n",
            "Iter 3116: train loss: 0.6735457181930542\n",
            "Iter 3117: train loss: 0.6734963059425354\n",
            "Iter 3118: train loss: 0.6734466552734375\n",
            "Iter 3119: train loss: 0.6733967661857605\n",
            "Iter 3120: train loss: 0.6733469367027283\n",
            "Iter 3121: train loss: 0.6732968688011169\n",
            "Iter 3122: train loss: 0.6732467412948608\n",
            "Iter 3123: train loss: 0.6731964349746704\n",
            "Iter 3124: train loss: 0.6731459498405457\n",
            "Iter 3125: train loss: 0.6730953454971313\n",
            "Iter 3126: train loss: 0.6730446219444275\n",
            "Iter 3127: train loss: 0.6729937791824341\n",
            "Iter 3128: train loss: 0.6729427576065063\n",
            "Iter 3129: train loss: 0.6728916764259338\n",
            "Iter 3130: train loss: 0.6728404760360718\n",
            "Iter 3131: train loss: 0.6727890372276306\n",
            "Iter 3132: train loss: 0.6727375388145447\n",
            "Iter 3133: train loss: 0.6726858615875244\n",
            "Iter 3134: train loss: 0.672633945941925\n",
            "Iter 3135: train loss: 0.6725820302963257\n",
            "Iter 3136: train loss: 0.6725299954414368\n",
            "Iter 3137: train loss: 0.6724778413772583\n",
            "Iter 3138: train loss: 0.672425389289856\n",
            "Iter 3139: train loss: 0.6723728775978088\n",
            "Iter 3140: train loss: 0.6723202466964722\n",
            "Iter 3141: train loss: 0.672267496585846\n",
            "Iter 3142: train loss: 0.6722146272659302\n",
            "Iter 3143: train loss: 0.6721615791320801\n",
            "Iter 3144: train loss: 0.6721083521842957\n",
            "Iter 3145: train loss: 0.6720550060272217\n",
            "Iter 3146: train loss: 0.6720015406608582\n",
            "Iter 3147: train loss: 0.6719480156898499\n",
            "Iter 3148: train loss: 0.6718941926956177\n",
            "Iter 3149: train loss: 0.671840250492096\n",
            "Iter 3150: train loss: 0.6717863082885742\n",
            "Iter 3151: train loss: 0.6717320680618286\n",
            "Iter 3152: train loss: 0.6716777682304382\n",
            "Iter 3153: train loss: 0.6716233491897583\n",
            "Iter 3154: train loss: 0.671568751335144\n",
            "Iter 3155: train loss: 0.6715140342712402\n",
            "Iter 3156: train loss: 0.6714590787887573\n",
            "Iter 3157: train loss: 0.6714041233062744\n",
            "Iter 3158: train loss: 0.6713489294052124\n",
            "Iter 3159: train loss: 0.6712936162948608\n",
            "Iter 3160: train loss: 0.6712382435798645\n",
            "Iter 3161: train loss: 0.6711825728416443\n",
            "Iter 3162: train loss: 0.6711268424987793\n",
            "Iter 3163: train loss: 0.67107093334198\n",
            "Iter 3164: train loss: 0.6710147857666016\n",
            "Iter 3165: train loss: 0.6709588170051575\n",
            "Iter 3166: train loss: 0.6709024310112\n",
            "Iter 3167: train loss: 0.6708459854125977\n",
            "Iter 3168: train loss: 0.6707894206047058\n",
            "Iter 3169: train loss: 0.6707326173782349\n",
            "Iter 3170: train loss: 0.6706756949424744\n",
            "Iter 3171: train loss: 0.6706187725067139\n",
            "Iter 3172: train loss: 0.6705614924430847\n",
            "Iter 3173: train loss: 0.6705042719841003\n",
            "Iter 3174: train loss: 0.6704467535018921\n",
            "Iter 3175: train loss: 0.6703891158103943\n",
            "Iter 3176: train loss: 0.6703312993049622\n",
            "Iter 3177: train loss: 0.6702734231948853\n",
            "Iter 3178: train loss: 0.670215368270874\n",
            "Iter 3179: train loss: 0.6701571941375732\n",
            "Iter 3180: train loss: 0.6700988411903381\n",
            "Iter 3181: train loss: 0.6700402498245239\n",
            "Iter 3182: train loss: 0.6699816584587097\n",
            "Iter 3183: train loss: 0.6699228286743164\n",
            "Iter 3184: train loss: 0.6698639392852783\n",
            "Iter 3185: train loss: 0.6698048114776611\n",
            "Iter 3186: train loss: 0.6697455644607544\n",
            "Iter 3187: train loss: 0.6696861982345581\n",
            "Iter 3188: train loss: 0.6696266531944275\n",
            "Iter 3189: train loss: 0.6695669889450073\n",
            "Iter 3190: train loss: 0.6695070862770081\n",
            "Iter 3191: train loss: 0.669447124004364\n",
            "Iter 3192: train loss: 0.6693871021270752\n",
            "Iter 3193: train loss: 0.669326663017273\n",
            "Iter 3194: train loss: 0.6692662835121155\n",
            "Iter 3195: train loss: 0.6692056655883789\n",
            "Iter 3196: train loss: 0.6691449880599976\n",
            "Iter 3197: train loss: 0.6690840721130371\n",
            "Iter 3198: train loss: 0.6690230369567871\n",
            "Iter 3199: train loss: 0.6689618229866028\n",
            "Iter 3200: train loss: 0.6689004302024841\n",
            "Iter 3201: train loss: 0.6688390374183655\n",
            "Iter 3202: train loss: 0.668777346611023\n",
            "Iter 3203: train loss: 0.6687155961990356\n",
            "Iter 3204: train loss: 0.6686536073684692\n",
            "Iter 3205: train loss: 0.6685914993286133\n",
            "Iter 3206: train loss: 0.668529212474823\n",
            "Iter 3207: train loss: 0.6684668660163879\n",
            "Iter 3208: train loss: 0.6684043407440186\n",
            "Iter 3209: train loss: 0.6683416366577148\n",
            "Iter 3210: train loss: 0.6682787537574768\n",
            "Iter 3211: train loss: 0.6682157516479492\n",
            "Iter 3212: train loss: 0.6681526303291321\n",
            "Iter 3213: train loss: 0.6680892705917358\n",
            "Iter 3214: train loss: 0.66802579164505\n",
            "Iter 3215: train loss: 0.6679621338844299\n",
            "Iter 3216: train loss: 0.6678983569145203\n",
            "Iter 3217: train loss: 0.667834460735321\n",
            "Iter 3218: train loss: 0.6677703857421875\n",
            "Iter 3219: train loss: 0.6677061915397644\n",
            "Iter 3220: train loss: 0.6676417589187622\n",
            "Iter 3221: train loss: 0.6675772666931152\n",
            "Iter 3222: train loss: 0.6675125360488892\n",
            "Iter 3223: train loss: 0.6674476265907288\n",
            "Iter 3224: train loss: 0.6673826575279236\n",
            "Iter 3225: train loss: 0.6673174500465393\n",
            "Iter 3226: train loss: 0.6672521829605103\n",
            "Iter 3227: train loss: 0.6671865582466125\n",
            "Iter 3228: train loss: 0.6671209931373596\n",
            "Iter 3229: train loss: 0.6670551896095276\n",
            "Iter 3230: train loss: 0.666989266872406\n",
            "Iter 3231: train loss: 0.6669231653213501\n",
            "Iter 3232: train loss: 0.6668568849563599\n",
            "Iter 3233: train loss: 0.6667905449867249\n",
            "Iter 3234: train loss: 0.6667238473892212\n",
            "Iter 3235: train loss: 0.6666571497917175\n",
            "Iter 3236: train loss: 0.6665902733802795\n",
            "Iter 3237: train loss: 0.6665233373641968\n",
            "Iter 3238: train loss: 0.6664561033248901\n",
            "Iter 3239: train loss: 0.666388750076294\n",
            "Iter 3240: train loss: 0.6663212180137634\n",
            "Iter 3241: train loss: 0.6662535071372986\n",
            "Iter 3242: train loss: 0.6661856174468994\n",
            "Iter 3243: train loss: 0.6661177277565002\n",
            "Iter 3244: train loss: 0.666049599647522\n",
            "Iter 3245: train loss: 0.6659812331199646\n",
            "Iter 3246: train loss: 0.6659128069877625\n",
            "Iter 3247: train loss: 0.6658441424369812\n",
            "Iter 3248: train loss: 0.6657754182815552\n",
            "Iter 3249: train loss: 0.66570645570755\n",
            "Iter 3250: train loss: 0.6656373143196106\n",
            "Iter 3251: train loss: 0.6655681729316711\n",
            "Iter 3252: train loss: 0.6654987335205078\n",
            "Iter 3253: train loss: 0.6654291152954102\n",
            "Iter 3254: train loss: 0.6653594374656677\n",
            "Iter 3255: train loss: 0.6652894616127014\n",
            "Iter 3256: train loss: 0.6652195453643799\n",
            "Iter 3257: train loss: 0.6651492714881897\n",
            "Iter 3258: train loss: 0.6650789380073547\n",
            "Iter 3259: train loss: 0.6650083661079407\n",
            "Iter 3260: train loss: 0.6649377346038818\n",
            "Iter 3261: train loss: 0.6648668050765991\n",
            "Iter 3262: train loss: 0.6647958159446716\n",
            "Iter 3263: train loss: 0.6647247076034546\n",
            "Iter 3264: train loss: 0.6646533608436584\n",
            "Iter 3265: train loss: 0.664581835269928\n",
            "Iter 3266: train loss: 0.6645102500915527\n",
            "Iter 3267: train loss: 0.6644384264945984\n",
            "Iter 3268: train loss: 0.6643664836883545\n",
            "Iter 3269: train loss: 0.6642943024635315\n",
            "Iter 3270: train loss: 0.6642220616340637\n",
            "Iter 3271: train loss: 0.6641495227813721\n",
            "Iter 3272: train loss: 0.6640769243240356\n",
            "Iter 3273: train loss: 0.6640042066574097\n",
            "Iter 3274: train loss: 0.6639312505722046\n",
            "Iter 3275: train loss: 0.6638582348823547\n",
            "Iter 3276: train loss: 0.663784921169281\n",
            "Iter 3277: train loss: 0.6637115478515625\n",
            "Iter 3278: train loss: 0.6636379361152649\n",
            "Iter 3279: train loss: 0.6635642051696777\n",
            "Iter 3280: train loss: 0.6634902954101562\n",
            "Iter 3281: train loss: 0.66341632604599\n",
            "Iter 3282: train loss: 0.6633420586585999\n",
            "Iter 3283: train loss: 0.6632676720619202\n",
            "Iter 3284: train loss: 0.6631931662559509\n",
            "Iter 3285: train loss: 0.6631183624267578\n",
            "Iter 3286: train loss: 0.6630434989929199\n",
            "Iter 3287: train loss: 0.6629685163497925\n",
            "Iter 3288: train loss: 0.6628932952880859\n",
            "Iter 3289: train loss: 0.6628180146217346\n",
            "Iter 3290: train loss: 0.6627424955368042\n",
            "Iter 3291: train loss: 0.6626667976379395\n",
            "Iter 3292: train loss: 0.6625908613204956\n",
            "Iter 3293: train loss: 0.6625149250030518\n",
            "Iter 3294: train loss: 0.6624388098716736\n",
            "Iter 3295: train loss: 0.6623624563217163\n",
            "Iter 3296: train loss: 0.6622859239578247\n",
            "Iter 3297: train loss: 0.6622093319892883\n",
            "Iter 3298: train loss: 0.6621324419975281\n",
            "Iter 3299: train loss: 0.662055492401123\n",
            "Iter 3300: train loss: 0.6619783639907837\n",
            "Iter 3301: train loss: 0.6619011163711548\n",
            "Iter 3302: train loss: 0.6618236899375916\n",
            "Iter 3303: train loss: 0.6617460250854492\n",
            "Iter 3304: train loss: 0.6616681814193726\n",
            "Iter 3305: train loss: 0.6615902185440063\n",
            "Iter 3306: train loss: 0.6615121364593506\n",
            "Iter 3307: train loss: 0.6614339351654053\n",
            "Iter 3308: train loss: 0.6613554358482361\n",
            "Iter 3309: train loss: 0.6612768769264221\n",
            "Iter 3310: train loss: 0.6611980199813843\n",
            "Iter 3311: train loss: 0.6611191630363464\n",
            "Iter 3312: train loss: 0.6610400676727295\n",
            "Iter 3313: train loss: 0.6609607934951782\n",
            "Iter 3314: train loss: 0.6608814001083374\n",
            "Iter 3315: train loss: 0.6608017683029175\n",
            "Iter 3316: train loss: 0.6607220768928528\n",
            "Iter 3317: train loss: 0.660642147064209\n",
            "Iter 3318: train loss: 0.6605620980262756\n",
            "Iter 3319: train loss: 0.660481870174408\n",
            "Iter 3320: train loss: 0.660401463508606\n",
            "Iter 3321: train loss: 0.6603209376335144\n",
            "Iter 3322: train loss: 0.6602402329444885\n",
            "Iter 3323: train loss: 0.6601593494415283\n",
            "Iter 3324: train loss: 0.660078227519989\n",
            "Iter 3325: train loss: 0.6599970459938049\n",
            "Iter 3326: train loss: 0.6599156260490417\n",
            "Iter 3327: train loss: 0.6598341464996338\n",
            "Iter 3328: train loss: 0.6597524881362915\n",
            "Iter 3329: train loss: 0.6596705913543701\n",
            "Iter 3330: train loss: 0.6595885753631592\n",
            "Iter 3331: train loss: 0.6595063805580139\n",
            "Iter 3332: train loss: 0.6594240665435791\n",
            "Iter 3333: train loss: 0.6593415141105652\n",
            "Iter 3334: train loss: 0.6592589020729065\n",
            "Iter 3335: train loss: 0.6591761112213135\n",
            "Iter 3336: train loss: 0.6590930223464966\n",
            "Iter 3337: train loss: 0.6590098738670349\n",
            "Iter 3338: train loss: 0.6589265465736389\n",
            "Iter 3339: train loss: 0.6588430404663086\n",
            "Iter 3340: train loss: 0.6587594151496887\n",
            "Iter 3341: train loss: 0.6586755514144897\n",
            "Iter 3342: train loss: 0.658591628074646\n",
            "Iter 3343: train loss: 0.6585074663162231\n",
            "Iter 3344: train loss: 0.6584232449531555\n",
            "Iter 3345: train loss: 0.6583386659622192\n",
            "Iter 3346: train loss: 0.6582540273666382\n",
            "Iter 3347: train loss: 0.6581693887710571\n",
            "Iter 3348: train loss: 0.6580843925476074\n",
            "Iter 3349: train loss: 0.6579992771148682\n",
            "Iter 3350: train loss: 0.6579139828681946\n",
            "Iter 3351: train loss: 0.6578285098075867\n",
            "Iter 3352: train loss: 0.657742977142334\n",
            "Iter 3353: train loss: 0.6576572060585022\n",
            "Iter 3354: train loss: 0.6575713157653809\n",
            "Iter 3355: train loss: 0.6574851870536804\n",
            "Iter 3356: train loss: 0.6573988795280457\n",
            "Iter 3357: train loss: 0.6573125720024109\n",
            "Iter 3358: train loss: 0.6572259664535522\n",
            "Iter 3359: train loss: 0.657139241695404\n",
            "Iter 3360: train loss: 0.6570523381233215\n",
            "Iter 3361: train loss: 0.6569653153419495\n",
            "Iter 3362: train loss: 0.6568780541419983\n",
            "Iter 3363: train loss: 0.6567907333374023\n",
            "Iter 3364: train loss: 0.6567031741142273\n",
            "Iter 3365: train loss: 0.6566154956817627\n",
            "Iter 3366: train loss: 0.6565276384353638\n",
            "Iter 3367: train loss: 0.6564396023750305\n",
            "Iter 3368: train loss: 0.6563513278961182\n",
            "Iter 3369: train loss: 0.6562631130218506\n",
            "Iter 3370: train loss: 0.6561745405197144\n",
            "Iter 3371: train loss: 0.6560859084129333\n",
            "Iter 3372: train loss: 0.6559970378875732\n",
            "Iter 3373: train loss: 0.6559080481529236\n",
            "Iter 3374: train loss: 0.6558189392089844\n",
            "Iter 3375: train loss: 0.6557295918464661\n",
            "Iter 3376: train loss: 0.655640184879303\n",
            "Iter 3377: train loss: 0.6555505990982056\n",
            "Iter 3378: train loss: 0.6554608345031738\n",
            "Iter 3379: train loss: 0.6553707718849182\n",
            "Iter 3380: train loss: 0.6552807688713074\n",
            "Iter 3381: train loss: 0.6551904082298279\n",
            "Iter 3382: train loss: 0.6550999283790588\n",
            "Iter 3383: train loss: 0.655009388923645\n",
            "Iter 3384: train loss: 0.6549186706542969\n",
            "Iter 3385: train loss: 0.6548277735710144\n",
            "Iter 3386: train loss: 0.6547366976737976\n",
            "Iter 3387: train loss: 0.654645562171936\n",
            "Iter 3388: train loss: 0.6545541286468506\n",
            "Iter 3389: train loss: 0.6544625759124756\n",
            "Iter 3390: train loss: 0.6543708443641663\n",
            "Iter 3391: train loss: 0.6542789936065674\n",
            "Iter 3392: train loss: 0.6541869640350342\n",
            "Iter 3393: train loss: 0.6540948152542114\n",
            "Iter 3394: train loss: 0.6540024876594543\n",
            "Iter 3395: train loss: 0.6539099216461182\n",
            "Iter 3396: train loss: 0.653817355632782\n",
            "Iter 3397: train loss: 0.6537245512008667\n",
            "Iter 3398: train loss: 0.6536315083503723\n",
            "Iter 3399: train loss: 0.6535384654998779\n",
            "Iter 3400: train loss: 0.6534452438354492\n",
            "Iter 3401: train loss: 0.6533517241477966\n",
            "Iter 3402: train loss: 0.6532581448554993\n",
            "Iter 3403: train loss: 0.6531643867492676\n",
            "Iter 3404: train loss: 0.6530705094337463\n",
            "Iter 3405: train loss: 0.652976393699646\n",
            "Iter 3406: train loss: 0.6528822779655457\n",
            "Iter 3407: train loss: 0.6527878642082214\n",
            "Iter 3408: train loss: 0.6526932716369629\n",
            "Iter 3409: train loss: 0.6525986790657043\n",
            "Iter 3410: train loss: 0.6525037884712219\n",
            "Iter 3411: train loss: 0.6524088382720947\n",
            "Iter 3412: train loss: 0.6523137092590332\n",
            "Iter 3413: train loss: 0.6522184014320374\n",
            "Iter 3414: train loss: 0.6521229147911072\n",
            "Iter 3415: train loss: 0.6520272493362427\n",
            "Iter 3416: train loss: 0.6519314050674438\n",
            "Iter 3417: train loss: 0.6518356204032898\n",
            "Iter 3418: train loss: 0.6517394185066223\n",
            "Iter 3419: train loss: 0.6516432166099548\n",
            "Iter 3420: train loss: 0.651546835899353\n",
            "Iter 3421: train loss: 0.6514503359794617\n",
            "Iter 3422: train loss: 0.6513535976409912\n",
            "Iter 3423: train loss: 0.6512567400932312\n",
            "Iter 3424: train loss: 0.6511596441268921\n",
            "Iter 3425: train loss: 0.651062548160553\n",
            "Iter 3426: train loss: 0.6509652733802795\n",
            "Iter 3427: train loss: 0.6508678197860718\n",
            "Iter 3428: train loss: 0.6507701873779297\n",
            "Iter 3429: train loss: 0.6506723761558533\n",
            "Iter 3430: train loss: 0.6505743861198425\n",
            "Iter 3431: train loss: 0.6504763960838318\n",
            "Iter 3432: train loss: 0.6503781676292419\n",
            "Iter 3433: train loss: 0.6502797603607178\n",
            "Iter 3434: train loss: 0.6501812934875488\n",
            "Iter 3435: train loss: 0.6500825881958008\n",
            "Iter 3436: train loss: 0.6499837636947632\n",
            "Iter 3437: train loss: 0.6498847007751465\n",
            "Iter 3438: train loss: 0.6497856378555298\n",
            "Iter 3439: train loss: 0.6496862769126892\n",
            "Iter 3440: train loss: 0.6495868563652039\n",
            "Iter 3441: train loss: 0.649487316608429\n",
            "Iter 3442: train loss: 0.649387538433075\n",
            "Iter 3443: train loss: 0.6492876410484314\n",
            "Iter 3444: train loss: 0.6491876840591431\n",
            "Iter 3445: train loss: 0.6490874290466309\n",
            "Iter 3446: train loss: 0.6489871144294739\n",
            "Iter 3447: train loss: 0.6488866806030273\n",
            "Iter 3448: train loss: 0.6487860679626465\n",
            "Iter 3449: train loss: 0.6486851572990417\n",
            "Iter 3450: train loss: 0.6485843062400818\n",
            "Iter 3451: train loss: 0.6484832763671875\n",
            "Iter 3452: train loss: 0.6483820676803589\n",
            "Iter 3453: train loss: 0.6482806205749512\n",
            "Iter 3454: train loss: 0.6481791138648987\n",
            "Iter 3455: train loss: 0.6480774879455566\n",
            "Iter 3456: train loss: 0.6479756832122803\n",
            "Iter 3457: train loss: 0.6478736400604248\n",
            "Iter 3458: train loss: 0.6477716565132141\n",
            "Iter 3459: train loss: 0.6476693749427795\n",
            "Iter 3460: train loss: 0.6475670337677002\n",
            "Iter 3461: train loss: 0.6474644541740417\n",
            "Iter 3462: train loss: 0.6473617553710938\n",
            "Iter 3463: train loss: 0.6472588777542114\n",
            "Iter 3464: train loss: 0.6471558809280396\n",
            "Iter 3465: train loss: 0.6470528244972229\n",
            "Iter 3466: train loss: 0.6469495296478271\n",
            "Iter 3467: train loss: 0.6468461751937866\n",
            "Iter 3468: train loss: 0.6467426419258118\n",
            "Iter 3469: train loss: 0.6466388702392578\n",
            "Iter 3470: train loss: 0.6465350985527039\n",
            "Iter 3471: train loss: 0.6464310884475708\n",
            "Iter 3472: train loss: 0.646327018737793\n",
            "Iter 3473: train loss: 0.646222710609436\n",
            "Iter 3474: train loss: 0.6461183428764343\n",
            "Iter 3475: train loss: 0.6460137963294983\n",
            "Iter 3476: train loss: 0.6459091305732727\n",
            "Iter 3477: train loss: 0.645804226398468\n",
            "Iter 3478: train loss: 0.6456992626190186\n",
            "Iter 3479: train loss: 0.6455941200256348\n",
            "Iter 3480: train loss: 0.6454887986183167\n",
            "Iter 3481: train loss: 0.6453835368156433\n",
            "Iter 3482: train loss: 0.6452779769897461\n",
            "Iter 3483: train loss: 0.6451723575592041\n",
            "Iter 3484: train loss: 0.6450664401054382\n",
            "Iter 3485: train loss: 0.6449605226516724\n",
            "Iter 3486: train loss: 0.6448543667793274\n",
            "Iter 3487: train loss: 0.6447482109069824\n",
            "Iter 3488: train loss: 0.6446418166160583\n",
            "Iter 3489: train loss: 0.6445354223251343\n",
            "Iter 3490: train loss: 0.6444286704063416\n",
            "Iter 3491: train loss: 0.6443219184875488\n",
            "Iter 3492: train loss: 0.6442149877548218\n",
            "Iter 3493: train loss: 0.6441079378128052\n",
            "Iter 3494: train loss: 0.6440007090568542\n",
            "Iter 3495: train loss: 0.6438934206962585\n",
            "Iter 3496: train loss: 0.6437860131263733\n",
            "Iter 3497: train loss: 0.6436783671379089\n",
            "Iter 3498: train loss: 0.6435706615447998\n",
            "Iter 3499: train loss: 0.6434627771377563\n",
            "Iter 3500: train loss: 0.6433547139167786\n",
            "Iter 3501: train loss: 0.6432465314865112\n",
            "Iter 3502: train loss: 0.6431382894515991\n",
            "Iter 3503: train loss: 0.6430298686027527\n",
            "Iter 3504: train loss: 0.6429213285446167\n",
            "Iter 3505: train loss: 0.6428127288818359\n",
            "Iter 3506: train loss: 0.6427039504051208\n",
            "Iter 3507: train loss: 0.6425949931144714\n",
            "Iter 3508: train loss: 0.6424859166145325\n",
            "Iter 3509: train loss: 0.6423766613006592\n",
            "Iter 3510: train loss: 0.6422673463821411\n",
            "Iter 3511: train loss: 0.6421578526496887\n",
            "Iter 3512: train loss: 0.6420482993125916\n",
            "Iter 3513: train loss: 0.6419386267662048\n",
            "Iter 3514: train loss: 0.6418286561965942\n",
            "Iter 3515: train loss: 0.6417187452316284\n",
            "Iter 3516: train loss: 0.6416085362434387\n",
            "Iter 3517: train loss: 0.6414982676506042\n",
            "Iter 3518: train loss: 0.6413879990577698\n",
            "Iter 3519: train loss: 0.6412774920463562\n",
            "Iter 3520: train loss: 0.6411668062210083\n",
            "Iter 3521: train loss: 0.6410560607910156\n",
            "Iter 3522: train loss: 0.6409451961517334\n",
            "Iter 3523: train loss: 0.6408341526985168\n",
            "Iter 3524: train loss: 0.6407230496406555\n",
            "Iter 3525: train loss: 0.6406117081642151\n",
            "Iter 3526: train loss: 0.6405003070831299\n",
            "Iter 3527: train loss: 0.6403888463973999\n",
            "Iter 3528: train loss: 0.6402772068977356\n",
            "Iter 3529: train loss: 0.640165388584137\n",
            "Iter 3530: train loss: 0.6400535702705383\n",
            "Iter 3531: train loss: 0.6399415135383606\n",
            "Iter 3532: train loss: 0.6398293972015381\n",
            "Iter 3533: train loss: 0.6397170424461365\n",
            "Iter 3534: train loss: 0.6396046280860901\n",
            "Iter 3535: train loss: 0.6394921541213989\n",
            "Iter 3536: train loss: 0.6393795013427734\n",
            "Iter 3537: train loss: 0.6392667293548584\n",
            "Iter 3538: train loss: 0.6391538977622986\n",
            "Iter 3539: train loss: 0.6390408873558044\n",
            "Iter 3540: train loss: 0.638927698135376\n",
            "Iter 3541: train loss: 0.6388144493103027\n",
            "Iter 3542: train loss: 0.6387011408805847\n",
            "Iter 3543: train loss: 0.6385875940322876\n",
            "Iter 3544: train loss: 0.6384739279747009\n",
            "Iter 3545: train loss: 0.6383602023124695\n",
            "Iter 3546: train loss: 0.6382463574409485\n",
            "Iter 3547: train loss: 0.6381323337554932\n",
            "Iter 3548: train loss: 0.6380183100700378\n",
            "Iter 3549: train loss: 0.6379040479660034\n",
            "Iter 3550: train loss: 0.6377897262573242\n",
            "Iter 3551: train loss: 0.6376753449440002\n",
            "Iter 3552: train loss: 0.6375606656074524\n",
            "Iter 3553: train loss: 0.6374459862709045\n",
            "Iter 3554: train loss: 0.6373312473297119\n",
            "Iter 3555: train loss: 0.637216329574585\n",
            "Iter 3556: train loss: 0.6371012926101685\n",
            "Iter 3557: train loss: 0.6369861364364624\n",
            "Iter 3558: train loss: 0.6368708610534668\n",
            "Iter 3559: train loss: 0.6367554664611816\n",
            "Iter 3560: train loss: 0.6366400122642517\n",
            "Iter 3561: train loss: 0.6365243196487427\n",
            "Iter 3562: train loss: 0.6364086270332336\n",
            "Iter 3563: train loss: 0.6362928152084351\n",
            "Iter 3564: train loss: 0.6361768245697021\n",
            "Iter 3565: train loss: 0.6360607743263245\n",
            "Iter 3566: train loss: 0.6359445452690125\n",
            "Iter 3567: train loss: 0.6358282566070557\n",
            "Iter 3568: train loss: 0.6357119083404541\n",
            "Iter 3569: train loss: 0.6355953216552734\n",
            "Iter 3570: train loss: 0.6354787349700928\n",
            "Iter 3571: train loss: 0.6353619694709778\n",
            "Iter 3572: train loss: 0.6352452039718628\n",
            "Iter 3573: train loss: 0.6351282000541687\n",
            "Iter 3574: train loss: 0.6350111365318298\n",
            "Iter 3575: train loss: 0.6348939538002014\n",
            "Iter 3576: train loss: 0.6347766518592834\n",
            "Iter 3577: train loss: 0.6346592903137207\n",
            "Iter 3578: train loss: 0.6345417499542236\n",
            "Iter 3579: train loss: 0.6344242095947266\n",
            "Iter 3580: train loss: 0.6343064904212952\n",
            "Iter 3581: train loss: 0.634188711643219\n",
            "Iter 3582: train loss: 0.6340706944465637\n",
            "Iter 3583: train loss: 0.6339527368545532\n",
            "Iter 3584: train loss: 0.6338345408439636\n",
            "Iter 3585: train loss: 0.6337162852287292\n",
            "Iter 3586: train loss: 0.6335979700088501\n",
            "Iter 3587: train loss: 0.6334794759750366\n",
            "Iter 3588: train loss: 0.6333609223365784\n",
            "Iter 3589: train loss: 0.6332422494888306\n",
            "Iter 3590: train loss: 0.6331234574317932\n",
            "Iter 3591: train loss: 0.6330046057701111\n",
            "Iter 3592: train loss: 0.6328856348991394\n",
            "Iter 3593: train loss: 0.632766604423523\n",
            "Iter 3594: train loss: 0.6326473951339722\n",
            "Iter 3595: train loss: 0.6325280666351318\n",
            "Iter 3596: train loss: 0.6324087381362915\n",
            "Iter 3597: train loss: 0.6322892308235168\n",
            "Iter 3598: train loss: 0.6321697235107422\n",
            "Iter 3599: train loss: 0.6320499777793884\n",
            "Iter 3600: train loss: 0.6319301128387451\n",
            "Iter 3601: train loss: 0.6318103075027466\n",
            "Iter 3602: train loss: 0.6316903233528137\n",
            "Iter 3603: train loss: 0.6315702199935913\n",
            "Iter 3604: train loss: 0.6314499974250793\n",
            "Iter 3605: train loss: 0.6313297748565674\n",
            "Iter 3606: train loss: 0.6312093138694763\n",
            "Iter 3607: train loss: 0.63108891248703\n",
            "Iter 3608: train loss: 0.6309683918952942\n",
            "Iter 3609: train loss: 0.6308476328849792\n",
            "Iter 3610: train loss: 0.6307268738746643\n",
            "Iter 3611: train loss: 0.6306060552597046\n",
            "Iter 3612: train loss: 0.6304850578308105\n",
            "Iter 3613: train loss: 0.6303640604019165\n",
            "Iter 3614: train loss: 0.6302428841590881\n",
            "Iter 3615: train loss: 0.6301217079162598\n",
            "Iter 3616: train loss: 0.6300003528594971\n",
            "Iter 3617: train loss: 0.6298789381980896\n",
            "Iter 3618: train loss: 0.6297574639320374\n",
            "Iter 3619: train loss: 0.6296358108520508\n",
            "Iter 3620: train loss: 0.6295140981674194\n",
            "Iter 3621: train loss: 0.6293923258781433\n",
            "Iter 3622: train loss: 0.6292704343795776\n",
            "Iter 3623: train loss: 0.6291484832763672\n",
            "Iter 3624: train loss: 0.6290264129638672\n",
            "Iter 3625: train loss: 0.6289042234420776\n",
            "Iter 3626: train loss: 0.6287820339202881\n",
            "Iter 3627: train loss: 0.6286596059799194\n",
            "Iter 3628: train loss: 0.628537118434906\n",
            "Iter 3629: train loss: 0.6284147500991821\n",
            "Iter 3630: train loss: 0.6282921433448792\n",
            "Iter 3631: train loss: 0.6281693577766418\n",
            "Iter 3632: train loss: 0.6280466318130493\n",
            "Iter 3633: train loss: 0.6279237866401672\n",
            "Iter 3634: train loss: 0.6278007626533508\n",
            "Iter 3635: train loss: 0.6276777982711792\n",
            "Iter 3636: train loss: 0.6275546550750732\n",
            "Iter 3637: train loss: 0.6274314522743225\n",
            "Iter 3638: train loss: 0.627308189868927\n",
            "Iter 3639: train loss: 0.6271847486495972\n",
            "Iter 3640: train loss: 0.6270613670349121\n",
            "Iter 3641: train loss: 0.626937747001648\n",
            "Iter 3642: train loss: 0.6268141269683838\n",
            "Iter 3643: train loss: 0.6266904473304749\n",
            "Iter 3644: train loss: 0.6265667080879211\n",
            "Iter 3645: train loss: 0.6264427304267883\n",
            "Iter 3646: train loss: 0.6263188123703003\n",
            "Iter 3647: train loss: 0.6261947751045227\n",
            "Iter 3648: train loss: 0.6260706186294556\n",
            "Iter 3649: train loss: 0.6259464025497437\n",
            "Iter 3650: train loss: 0.625822126865387\n",
            "Iter 3651: train loss: 0.6256977915763855\n",
            "Iter 3652: train loss: 0.6255733370780945\n",
            "Iter 3653: train loss: 0.6254488825798035\n",
            "Iter 3654: train loss: 0.6253242492675781\n",
            "Iter 3655: train loss: 0.6251994967460632\n",
            "Iter 3656: train loss: 0.6250747442245483\n",
            "Iter 3657: train loss: 0.6249499320983887\n",
            "Iter 3658: train loss: 0.6248250603675842\n",
            "Iter 3659: train loss: 0.6247000098228455\n",
            "Iter 3660: train loss: 0.6245750188827515\n",
            "Iter 3661: train loss: 0.6244498491287231\n",
            "Iter 3662: train loss: 0.62432461977005\n",
            "Iter 3663: train loss: 0.6241993308067322\n",
            "Iter 3664: train loss: 0.6240739226341248\n",
            "Iter 3665: train loss: 0.6239485144615173\n",
            "Iter 3666: train loss: 0.6238230466842651\n",
            "Iter 3667: train loss: 0.6236973404884338\n",
            "Iter 3668: train loss: 0.6235718131065369\n",
            "Iter 3669: train loss: 0.623445987701416\n",
            "Iter 3670: train loss: 0.6233202219009399\n",
            "Iter 3671: train loss: 0.6231942772865295\n",
            "Iter 3672: train loss: 0.6230683326721191\n",
            "Iter 3673: train loss: 0.6229422688484192\n",
            "Iter 3674: train loss: 0.6228162050247192\n",
            "Iter 3675: train loss: 0.6226900815963745\n",
            "Iter 3676: train loss: 0.6225638389587402\n",
            "Iter 3677: train loss: 0.6224375367164612\n",
            "Iter 3678: train loss: 0.6223111748695374\n",
            "Iter 3679: train loss: 0.622184693813324\n",
            "Iter 3680: train loss: 0.6220582127571106\n",
            "Iter 3681: train loss: 0.6219315528869629\n",
            "Iter 3682: train loss: 0.62180495262146\n",
            "Iter 3683: train loss: 0.6216782331466675\n",
            "Iter 3684: train loss: 0.6215514540672302\n",
            "Iter 3685: train loss: 0.6214246153831482\n",
            "Iter 3686: train loss: 0.6212977170944214\n",
            "Iter 3687: train loss: 0.621170699596405\n",
            "Iter 3688: train loss: 0.6210436224937439\n",
            "Iter 3689: train loss: 0.620916485786438\n",
            "Iter 3690: train loss: 0.6207893490791321\n",
            "Iter 3691: train loss: 0.6206620335578918\n",
            "Iter 3692: train loss: 0.6205348372459412\n",
            "Iter 3693: train loss: 0.6204074025154114\n",
            "Iter 3694: train loss: 0.6202799677848816\n",
            "Iter 3695: train loss: 0.620152473449707\n",
            "Iter 3696: train loss: 0.6200249195098877\n",
            "Iter 3697: train loss: 0.6198972463607788\n",
            "Iter 3698: train loss: 0.6197695732116699\n",
            "Iter 3699: train loss: 0.619641900062561\n",
            "Iter 3700: train loss: 0.619513988494873\n",
            "Iter 3701: train loss: 0.6193861365318298\n",
            "Iter 3702: train loss: 0.6192582249641418\n",
            "Iter 3703: train loss: 0.6191302537918091\n",
            "Iter 3704: train loss: 0.6190021634101868\n",
            "Iter 3705: train loss: 0.6188741326332092\n",
            "Iter 3706: train loss: 0.6187459230422974\n",
            "Iter 3707: train loss: 0.6186177730560303\n",
            "Iter 3708: train loss: 0.6184893846511841\n",
            "Iter 3709: train loss: 0.6183611154556274\n",
            "Iter 3710: train loss: 0.6182327270507812\n",
            "Iter 3711: train loss: 0.6181042194366455\n",
            "Iter 3712: train loss: 0.6179757118225098\n",
            "Iter 3713: train loss: 0.6178471446037292\n",
            "Iter 3714: train loss: 0.6177184581756592\n",
            "Iter 3715: train loss: 0.6175898313522339\n",
            "Iter 3716: train loss: 0.6174611449241638\n",
            "Iter 3717: train loss: 0.6173323392868042\n",
            "Iter 3718: train loss: 0.6172035336494446\n",
            "Iter 3719: train loss: 0.6170746684074402\n",
            "Iter 3720: train loss: 0.6169456243515015\n",
            "Iter 3721: train loss: 0.6168166399002075\n",
            "Iter 3722: train loss: 0.6166875958442688\n",
            "Iter 3723: train loss: 0.6165584921836853\n",
            "Iter 3724: train loss: 0.616429328918457\n",
            "Iter 3725: train loss: 0.616300106048584\n",
            "Iter 3726: train loss: 0.6161708235740662\n",
            "Iter 3727: train loss: 0.6160414814949036\n",
            "Iter 3728: train loss: 0.615912139415741\n",
            "Iter 3729: train loss: 0.6157827377319336\n",
            "Iter 3730: train loss: 0.6156533360481262\n",
            "Iter 3731: train loss: 0.6155236959457397\n",
            "Iter 3732: train loss: 0.6153941750526428\n",
            "Iter 3733: train loss: 0.6152645945549011\n",
            "Iter 3734: train loss: 0.6151348948478699\n",
            "Iter 3735: train loss: 0.6150051951408386\n",
            "Iter 3736: train loss: 0.6148754358291626\n",
            "Iter 3737: train loss: 0.6147456169128418\n",
            "Iter 3738: train loss: 0.6146157383918762\n",
            "Iter 3739: train loss: 0.6144859194755554\n",
            "Iter 3740: train loss: 0.6143559217453003\n",
            "Iter 3741: train loss: 0.6142259240150452\n",
            "Iter 3742: train loss: 0.6140958666801453\n",
            "Iter 3743: train loss: 0.6139658689498901\n",
            "Iter 3744: train loss: 0.6138356924057007\n",
            "Iter 3745: train loss: 0.6137054562568665\n",
            "Iter 3746: train loss: 0.6135753393173218\n",
            "Iter 3747: train loss: 0.6134450435638428\n",
            "Iter 3748: train loss: 0.6133148074150085\n",
            "Iter 3749: train loss: 0.6131844520568848\n",
            "Iter 3750: train loss: 0.6130540370941162\n",
            "Iter 3751: train loss: 0.6129235625267029\n",
            "Iter 3752: train loss: 0.6127931475639343\n",
            "Iter 3753: train loss: 0.6126626133918762\n",
            "Iter 3754: train loss: 0.6125320196151733\n",
            "Iter 3755: train loss: 0.6124014258384705\n",
            "Iter 3756: train loss: 0.6122707724571228\n",
            "Iter 3757: train loss: 0.6121401190757751\n",
            "Iter 3758: train loss: 0.6120093464851379\n",
            "Iter 3759: train loss: 0.6118786334991455\n",
            "Iter 3760: train loss: 0.6117478609085083\n",
            "Iter 3761: train loss: 0.6116170287132263\n",
            "Iter 3762: train loss: 0.6114861965179443\n",
            "Iter 3763: train loss: 0.611355185508728\n",
            "Iter 3764: train loss: 0.6112242937088013\n",
            "Iter 3765: train loss: 0.6110933423042297\n",
            "Iter 3766: train loss: 0.6109622716903687\n",
            "Iter 3767: train loss: 0.6108312010765076\n",
            "Iter 3768: train loss: 0.6107001304626465\n",
            "Iter 3769: train loss: 0.6105688810348511\n",
            "Iter 3770: train loss: 0.6104376912117004\n",
            "Iter 3771: train loss: 0.6103065013885498\n",
            "Iter 3772: train loss: 0.6101753115653992\n",
            "Iter 3773: train loss: 0.6100440621376038\n",
            "Iter 3774: train loss: 0.6099126935005188\n",
            "Iter 3775: train loss: 0.6097813248634338\n",
            "Iter 3776: train loss: 0.6096500158309937\n",
            "Iter 3777: train loss: 0.6095186471939087\n",
            "Iter 3778: train loss: 0.6093871593475342\n",
            "Iter 3779: train loss: 0.6092556715011597\n",
            "Iter 3780: train loss: 0.6091241836547852\n",
            "Iter 3781: train loss: 0.6089926362037659\n",
            "Iter 3782: train loss: 0.6088610291481018\n",
            "Iter 3783: train loss: 0.6087294816970825\n",
            "Iter 3784: train loss: 0.6085978150367737\n",
            "Iter 3785: train loss: 0.6084661483764648\n",
            "Iter 3786: train loss: 0.6083344221115112\n",
            "Iter 3787: train loss: 0.6082026958465576\n",
            "Iter 3788: train loss: 0.608070969581604\n",
            "Iter 3789: train loss: 0.6079391241073608\n",
            "Iter 3790: train loss: 0.6078073978424072\n",
            "Iter 3791: train loss: 0.6076755523681641\n",
            "Iter 3792: train loss: 0.6075436472892761\n",
            "Iter 3793: train loss: 0.6074117422103882\n",
            "Iter 3794: train loss: 0.6072797775268555\n",
            "Iter 3795: train loss: 0.6071478128433228\n",
            "Iter 3796: train loss: 0.6070157885551453\n",
            "Iter 3797: train loss: 0.6068838238716125\n",
            "Iter 3798: train loss: 0.6067517399787903\n",
            "Iter 3799: train loss: 0.6066197156906128\n",
            "Iter 3800: train loss: 0.6064876317977905\n",
            "Iter 3801: train loss: 0.6063555479049683\n",
            "Iter 3802: train loss: 0.6062234044075012\n",
            "Iter 3803: train loss: 0.6060912013053894\n",
            "Iter 3804: train loss: 0.6059589385986328\n",
            "Iter 3805: train loss: 0.605826735496521\n",
            "Iter 3806: train loss: 0.6056944727897644\n",
            "Iter 3807: train loss: 0.6055622100830078\n",
            "Iter 3808: train loss: 0.6054299473762512\n",
            "Iter 3809: train loss: 0.6052976250648499\n",
            "Iter 3810: train loss: 0.6051653027534485\n",
            "Iter 3811: train loss: 0.6050329208374023\n",
            "Iter 3812: train loss: 0.604900598526001\n",
            "Iter 3813: train loss: 0.6047681570053101\n",
            "Iter 3814: train loss: 0.6046357154846191\n",
            "Iter 3815: train loss: 0.6045032143592834\n",
            "Iter 3816: train loss: 0.6043707728385925\n",
            "Iter 3817: train loss: 0.6042383909225464\n",
            "Iter 3818: train loss: 0.6041057705879211\n",
            "Iter 3819: train loss: 0.6039732694625854\n",
            "Iter 3820: train loss: 0.603840708732605\n",
            "Iter 3821: train loss: 0.6037082076072693\n",
            "Iter 3822: train loss: 0.6035755276679993\n",
            "Iter 3823: train loss: 0.6034429669380188\n",
            "Iter 3824: train loss: 0.6033102869987488\n",
            "Iter 3825: train loss: 0.6031776666641235\n",
            "Iter 3826: train loss: 0.6030449867248535\n",
            "Iter 3827: train loss: 0.6029122471809387\n",
            "Iter 3828: train loss: 0.6027796268463135\n",
            "Iter 3829: train loss: 0.6026468873023987\n",
            "Iter 3830: train loss: 0.6025141477584839\n",
            "Iter 3831: train loss: 0.6023813486099243\n",
            "Iter 3832: train loss: 0.6022485494613647\n",
            "Iter 3833: train loss: 0.60211580991745\n",
            "Iter 3834: train loss: 0.6019830703735352\n",
            "Iter 3835: train loss: 0.6018502712249756\n",
            "Iter 3836: train loss: 0.6017174124717712\n",
            "Iter 3837: train loss: 0.6015845537185669\n",
            "Iter 3838: train loss: 0.6014516353607178\n",
            "Iter 3839: train loss: 0.6013188362121582\n",
            "Iter 3840: train loss: 0.6011859178543091\n",
            "Iter 3841: train loss: 0.60105299949646\n",
            "Iter 3842: train loss: 0.6009200811386108\n",
            "Iter 3843: train loss: 0.6007871627807617\n",
            "Iter 3844: train loss: 0.600654125213623\n",
            "Iter 3845: train loss: 0.6005212664604187\n",
            "Iter 3846: train loss: 0.60038822889328\n",
            "Iter 3847: train loss: 0.6002552509307861\n",
            "Iter 3848: train loss: 0.6001222729682922\n",
            "Iter 3849: train loss: 0.5999892354011536\n",
            "Iter 3850: train loss: 0.5998562574386597\n",
            "Iter 3851: train loss: 0.599723219871521\n",
            "Iter 3852: train loss: 0.5995901823043823\n",
            "Iter 3853: train loss: 0.5994571447372437\n",
            "Iter 3854: train loss: 0.5993240475654602\n",
            "Iter 3855: train loss: 0.5991910099983215\n",
            "Iter 3856: train loss: 0.5990579128265381\n",
            "Iter 3857: train loss: 0.5989247560501099\n",
            "Iter 3858: train loss: 0.5987917184829712\n",
            "Iter 3859: train loss: 0.598658561706543\n",
            "Iter 3860: train loss: 0.5985254049301147\n",
            "Iter 3861: train loss: 0.5983923077583313\n",
            "Iter 3862: train loss: 0.5982592105865479\n",
            "Iter 3863: train loss: 0.5981261134147644\n",
            "Iter 3864: train loss: 0.5979928374290466\n",
            "Iter 3865: train loss: 0.5978596806526184\n",
            "Iter 3866: train loss: 0.5977266430854797\n",
            "Iter 3867: train loss: 0.597593367099762\n",
            "Iter 3868: train loss: 0.5974602103233337\n",
            "Iter 3869: train loss: 0.5973269939422607\n",
            "Iter 3870: train loss: 0.5971938371658325\n",
            "Iter 3871: train loss: 0.5970606207847595\n",
            "Iter 3872: train loss: 0.5969274044036865\n",
            "Iter 3873: train loss: 0.5967941880226135\n",
            "Iter 3874: train loss: 0.5966609716415405\n",
            "Iter 3875: train loss: 0.5965277552604675\n",
            "Iter 3876: train loss: 0.5963944792747498\n",
            "Iter 3877: train loss: 0.5962612628936768\n",
            "Iter 3878: train loss: 0.5961280465126038\n",
            "Iter 3879: train loss: 0.5959948897361755\n",
            "Iter 3880: train loss: 0.595861554145813\n",
            "Iter 3881: train loss: 0.5957282781600952\n",
            "Iter 3882: train loss: 0.5955950617790222\n",
            "Iter 3883: train loss: 0.5954618453979492\n",
            "Iter 3884: train loss: 0.5953285694122314\n",
            "Iter 3885: train loss: 0.5951952338218689\n",
            "Iter 3886: train loss: 0.5950620174407959\n",
            "Iter 3887: train loss: 0.5949286818504333\n",
            "Iter 3888: train loss: 0.5947954654693604\n",
            "Iter 3889: train loss: 0.5946622490882874\n",
            "Iter 3890: train loss: 0.59452885389328\n",
            "Iter 3891: train loss: 0.5943955183029175\n",
            "Iter 3892: train loss: 0.594262421131134\n",
            "Iter 3893: train loss: 0.5941290855407715\n",
            "Iter 3894: train loss: 0.5939958691596985\n",
            "Iter 3895: train loss: 0.5938625335693359\n",
            "Iter 3896: train loss: 0.5937292575836182\n",
            "Iter 3897: train loss: 0.5935959815979004\n",
            "Iter 3898: train loss: 0.5934627056121826\n",
            "Iter 3899: train loss: 0.5933293700218201\n",
            "Iter 3900: train loss: 0.5931961536407471\n",
            "Iter 3901: train loss: 0.5930628180503845\n",
            "Iter 3902: train loss: 0.5929295420646667\n",
            "Iter 3903: train loss: 0.5927963256835938\n",
            "Iter 3904: train loss: 0.592663049697876\n",
            "Iter 3905: train loss: 0.592529833316803\n",
            "Iter 3906: train loss: 0.5923964977264404\n",
            "Iter 3907: train loss: 0.5922632217407227\n",
            "Iter 3908: train loss: 0.5921300053596497\n",
            "Iter 3909: train loss: 0.5919967293739319\n",
            "Iter 3910: train loss: 0.5918635129928589\n",
            "Iter 3911: train loss: 0.5917301177978516\n",
            "Iter 3912: train loss: 0.5915969014167786\n",
            "Iter 3913: train loss: 0.5914636850357056\n",
            "Iter 3914: train loss: 0.5913304686546326\n",
            "Iter 3915: train loss: 0.5911971926689148\n",
            "Iter 3916: train loss: 0.591063916683197\n",
            "Iter 3917: train loss: 0.5909307599067688\n",
            "Iter 3918: train loss: 0.590797483921051\n",
            "Iter 3919: train loss: 0.590664267539978\n",
            "Iter 3920: train loss: 0.590531051158905\n",
            "Iter 3921: train loss: 0.590397834777832\n",
            "Iter 3922: train loss: 0.590264618396759\n",
            "Iter 3923: train loss: 0.5901315212249756\n",
            "Iter 3924: train loss: 0.5899982452392578\n",
            "Iter 3925: train loss: 0.5898650288581848\n",
            "Iter 3926: train loss: 0.5897318720817566\n",
            "Iter 3927: train loss: 0.5895986557006836\n",
            "Iter 3928: train loss: 0.5894654989242554\n",
            "Iter 3929: train loss: 0.5893322825431824\n",
            "Iter 3930: train loss: 0.5891991853713989\n",
            "Iter 3931: train loss: 0.5890660285949707\n",
            "Iter 3932: train loss: 0.5889328718185425\n",
            "Iter 3933: train loss: 0.588799774646759\n",
            "Iter 3934: train loss: 0.5886666774749756\n",
            "Iter 3935: train loss: 0.5885334610939026\n",
            "Iter 3936: train loss: 0.5884003043174744\n",
            "Iter 3937: train loss: 0.5882672667503357\n",
            "Iter 3938: train loss: 0.5881341099739075\n",
            "Iter 3939: train loss: 0.5880010724067688\n",
            "Iter 3940: train loss: 0.5878679752349854\n",
            "Iter 3941: train loss: 0.5877348780632019\n",
            "Iter 3942: train loss: 0.5876018404960632\n",
            "Iter 3943: train loss: 0.5874687433242798\n",
            "Iter 3944: train loss: 0.5873357057571411\n",
            "Iter 3945: train loss: 0.5872027277946472\n",
            "Iter 3946: train loss: 0.5870696902275085\n",
            "Iter 3947: train loss: 0.5869366526603699\n",
            "Iter 3948: train loss: 0.586803674697876\n",
            "Iter 3949: train loss: 0.5866705775260925\n",
            "Iter 3950: train loss: 0.5865376591682434\n",
            "Iter 3951: train loss: 0.5864047408103943\n",
            "Iter 3952: train loss: 0.5862717628479004\n",
            "Iter 3953: train loss: 0.5861387252807617\n",
            "Iter 3954: train loss: 0.5860058665275574\n",
            "Iter 3955: train loss: 0.5858729481697083\n",
            "Iter 3956: train loss: 0.5857399702072144\n",
            "Iter 3957: train loss: 0.58560711145401\n",
            "Iter 3958: train loss: 0.5854741334915161\n",
            "Iter 3959: train loss: 0.5853413343429565\n",
            "Iter 3960: train loss: 0.5852084159851074\n",
            "Iter 3961: train loss: 0.5850755572319031\n",
            "Iter 3962: train loss: 0.5849426984786987\n",
            "Iter 3963: train loss: 0.5848098993301392\n",
            "Iter 3964: train loss: 0.5846770405769348\n",
            "Iter 3965: train loss: 0.58454430103302\n",
            "Iter 3966: train loss: 0.5844114422798157\n",
            "Iter 3967: train loss: 0.5842787027359009\n",
            "Iter 3968: train loss: 0.5841459631919861\n",
            "Iter 3969: train loss: 0.5840131640434265\n",
            "Iter 3970: train loss: 0.5838804244995117\n",
            "Iter 3971: train loss: 0.5837476849555969\n",
            "Iter 3972: train loss: 0.5836149454116821\n",
            "Iter 3973: train loss: 0.5834822058677673\n",
            "Iter 3974: train loss: 0.5833495259284973\n",
            "Iter 3975: train loss: 0.5832169055938721\n",
            "Iter 3976: train loss: 0.583084225654602\n",
            "Iter 3977: train loss: 0.5829516053199768\n",
            "Iter 3978: train loss: 0.5828189849853516\n",
            "Iter 3979: train loss: 0.5826863646507263\n",
            "Iter 3980: train loss: 0.5825538039207458\n",
            "Iter 3981: train loss: 0.5824211239814758\n",
            "Iter 3982: train loss: 0.5822886228561401\n",
            "Iter 3983: train loss: 0.5821561217308044\n",
            "Iter 3984: train loss: 0.5820235013961792\n",
            "Iter 3985: train loss: 0.5818910002708435\n",
            "Iter 3986: train loss: 0.5817584991455078\n",
            "Iter 3987: train loss: 0.5816259980201721\n",
            "Iter 3988: train loss: 0.5814935564994812\n",
            "Iter 3989: train loss: 0.5813611149787903\n",
            "Iter 3990: train loss: 0.5812286734580994\n",
            "Iter 3991: train loss: 0.5810962319374084\n",
            "Iter 3992: train loss: 0.5809638500213623\n",
            "Iter 3993: train loss: 0.5808315277099609\n",
            "Iter 3994: train loss: 0.58069908618927\n",
            "Iter 3995: train loss: 0.5805667042732239\n",
            "Iter 3996: train loss: 0.5804344415664673\n",
            "Iter 3997: train loss: 0.5803021192550659\n",
            "Iter 3998: train loss: 0.5801697969436646\n",
            "Iter 3999: train loss: 0.5800374746322632\n",
            "Iter 4000: train loss: 0.5799052715301514\n",
            "Iter 4001: train loss: 0.57977294921875\n",
            "Iter 4002: train loss: 0.5796407461166382\n",
            "Iter 4003: train loss: 0.5795085430145264\n",
            "Iter 4004: train loss: 0.5793763995170593\n",
            "Iter 4005: train loss: 0.5792442560195923\n",
            "Iter 4006: train loss: 0.5791120529174805\n",
            "Iter 4007: train loss: 0.5789799690246582\n",
            "Iter 4008: train loss: 0.5788477659225464\n",
            "Iter 4009: train loss: 0.5787156820297241\n",
            "Iter 4010: train loss: 0.5785835981369019\n",
            "Iter 4011: train loss: 0.5784515142440796\n",
            "Iter 4012: train loss: 0.5783194899559021\n",
            "Iter 4013: train loss: 0.5781875252723694\n",
            "Iter 4014: train loss: 0.5780555009841919\n",
            "Iter 4015: train loss: 0.5779234766960144\n",
            "Iter 4016: train loss: 0.5777915120124817\n",
            "Iter 4017: train loss: 0.577659547328949\n",
            "Iter 4018: train loss: 0.5775277018547058\n",
            "Iter 4019: train loss: 0.5773957967758179\n",
            "Iter 4020: train loss: 0.5772638916969299\n",
            "Iter 4021: train loss: 0.5771320462226868\n",
            "Iter 4022: train loss: 0.5770002603530884\n",
            "Iter 4023: train loss: 0.5768683552742004\n",
            "Iter 4024: train loss: 0.576736569404602\n",
            "Iter 4025: train loss: 0.5766048431396484\n",
            "Iter 4026: train loss: 0.57647305727005\n",
            "Iter 4027: train loss: 0.5763413906097412\n",
            "Iter 4028: train loss: 0.576209545135498\n",
            "Iter 4029: train loss: 0.576077938079834\n",
            "Iter 4030: train loss: 0.5759462118148804\n",
            "Iter 4031: train loss: 0.5758145451545715\n",
            "Iter 4032: train loss: 0.5756829380989075\n",
            "Iter 4033: train loss: 0.5755513906478882\n",
            "Iter 4034: train loss: 0.5754197239875793\n",
            "Iter 4035: train loss: 0.5752882361412048\n",
            "Iter 4036: train loss: 0.5751566886901855\n",
            "Iter 4037: train loss: 0.5750251412391663\n",
            "Iter 4038: train loss: 0.574893593788147\n",
            "Iter 4039: train loss: 0.5747621655464172\n",
            "Iter 4040: train loss: 0.5746307373046875\n",
            "Iter 4041: train loss: 0.5744993090629578\n",
            "Iter 4042: train loss: 0.574367880821228\n",
            "Iter 4043: train loss: 0.5742365717887878\n",
            "Iter 4044: train loss: 0.5741052031517029\n",
            "Iter 4045: train loss: 0.5739738345146179\n",
            "Iter 4046: train loss: 0.5738425254821777\n",
            "Iter 4047: train loss: 0.5737111568450928\n",
            "Iter 4048: train loss: 0.5735799074172974\n",
            "Iter 4049: train loss: 0.5734487175941467\n",
            "Iter 4050: train loss: 0.5733174681663513\n",
            "Iter 4051: train loss: 0.5731862783432007\n",
            "Iter 4052: train loss: 0.57305508852005\n",
            "Iter 4053: train loss: 0.5729238986968994\n",
            "Iter 4054: train loss: 0.5727927684783936\n",
            "Iter 4055: train loss: 0.5726616978645325\n",
            "Iter 4056: train loss: 0.5725305676460266\n",
            "Iter 4057: train loss: 0.5723995566368103\n",
            "Iter 4058: train loss: 0.5722684860229492\n",
            "Iter 4059: train loss: 0.5721375346183777\n",
            "Iter 4060: train loss: 0.5720064640045166\n",
            "Iter 4061: train loss: 0.5718755125999451\n",
            "Iter 4062: train loss: 0.5717446208000183\n",
            "Iter 4063: train loss: 0.5716137290000916\n",
            "Iter 4064: train loss: 0.57148277759552\n",
            "Iter 4065: train loss: 0.571351945400238\n",
            "Iter 4066: train loss: 0.5712210536003113\n",
            "Iter 4067: train loss: 0.5710902214050293\n",
            "Iter 4068: train loss: 0.5709595084190369\n",
            "Iter 4069: train loss: 0.5708286762237549\n",
            "Iter 4070: train loss: 0.5706979632377625\n",
            "Iter 4071: train loss: 0.57056725025177\n",
            "Iter 4072: train loss: 0.5704365372657776\n",
            "Iter 4073: train loss: 0.5703058838844299\n",
            "Iter 4074: train loss: 0.5701752305030823\n",
            "Iter 4075: train loss: 0.5700445771217346\n",
            "Iter 4076: train loss: 0.5699139833450317\n",
            "Iter 4077: train loss: 0.5697834491729736\n",
            "Iter 4078: train loss: 0.5696528553962708\n",
            "Iter 4079: train loss: 0.5695223212242126\n",
            "Iter 4080: train loss: 0.5693919062614441\n",
            "Iter 4081: train loss: 0.5692614912986755\n",
            "Iter 4082: train loss: 0.5691309571266174\n",
            "Iter 4083: train loss: 0.5690006017684937\n",
            "Iter 4084: train loss: 0.5688701272010803\n",
            "Iter 4085: train loss: 0.5687398314476013\n",
            "Iter 4086: train loss: 0.5686094164848328\n",
            "Iter 4087: train loss: 0.5684791803359985\n",
            "Iter 4088: train loss: 0.5683488249778748\n",
            "Iter 4089: train loss: 0.5682186484336853\n",
            "Iter 4090: train loss: 0.5680883526802063\n",
            "Iter 4091: train loss: 0.5679581165313721\n",
            "Iter 4092: train loss: 0.5678280591964722\n",
            "Iter 4093: train loss: 0.5676977634429932\n",
            "Iter 4094: train loss: 0.5675676465034485\n",
            "Iter 4095: train loss: 0.5674375891685486\n",
            "Iter 4096: train loss: 0.5673074722290039\n",
            "Iter 4097: train loss: 0.5671774744987488\n",
            "Iter 4098: train loss: 0.5670473575592041\n",
            "Iter 4099: train loss: 0.5669174790382385\n",
            "Iter 4100: train loss: 0.5667874813079834\n",
            "Iter 4101: train loss: 0.566657543182373\n",
            "Iter 4102: train loss: 0.5665276050567627\n",
            "Iter 4103: train loss: 0.5663977265357971\n",
            "Iter 4104: train loss: 0.5662678480148315\n",
            "Iter 4105: train loss: 0.566137969493866\n",
            "Iter 4106: train loss: 0.5660081505775452\n",
            "Iter 4107: train loss: 0.5658783912658691\n",
            "Iter 4108: train loss: 0.5657486319541931\n",
            "Iter 4109: train loss: 0.5656188726425171\n",
            "Iter 4110: train loss: 0.5654891729354858\n",
            "Iter 4111: train loss: 0.5653594136238098\n",
            "Iter 4112: train loss: 0.5652298331260681\n",
            "Iter 4113: train loss: 0.5651002526283264\n",
            "Iter 4114: train loss: 0.5649706125259399\n",
            "Iter 4115: train loss: 0.564841091632843\n",
            "Iter 4116: train loss: 0.5647115111351013\n",
            "Iter 4117: train loss: 0.5645820498466492\n",
            "Iter 4118: train loss: 0.5644525289535522\n",
            "Iter 4119: train loss: 0.5643230676651001\n",
            "Iter 4120: train loss: 0.5641935467720032\n",
            "Iter 4121: train loss: 0.5640642046928406\n",
            "Iter 4122: train loss: 0.5639348030090332\n",
            "Iter 4123: train loss: 0.5638054013252258\n",
            "Iter 4124: train loss: 0.5636761784553528\n",
            "Iter 4125: train loss: 0.5635468363761902\n",
            "Iter 4126: train loss: 0.5634175539016724\n",
            "Iter 4127: train loss: 0.5632883906364441\n",
            "Iter 4128: train loss: 0.5631591081619263\n",
            "Iter 4129: train loss: 0.563029944896698\n",
            "Iter 4130: train loss: 0.5629008412361145\n",
            "Iter 4131: train loss: 0.5627716183662415\n",
            "Iter 4132: train loss: 0.562642514705658\n",
            "Iter 4133: train loss: 0.5625134110450745\n",
            "Iter 4134: train loss: 0.5623844265937805\n",
            "Iter 4135: train loss: 0.5622553825378418\n",
            "Iter 4136: train loss: 0.5621263384819031\n",
            "Iter 4137: train loss: 0.5619974136352539\n",
            "Iter 4138: train loss: 0.5618684887886047\n",
            "Iter 4139: train loss: 0.5617395639419556\n",
            "Iter 4140: train loss: 0.5616106986999512\n",
            "Iter 4141: train loss: 0.5614818930625916\n",
            "Iter 4142: train loss: 0.5613530278205872\n",
            "Iter 4143: train loss: 0.5612242221832275\n",
            "Iter 4144: train loss: 0.5610955357551575\n",
            "Iter 4145: train loss: 0.5609667301177979\n",
            "Iter 4146: train loss: 0.5608380436897278\n",
            "Iter 4147: train loss: 0.5607092976570129\n",
            "Iter 4148: train loss: 0.5605806708335876\n",
            "Iter 4149: train loss: 0.5604520440101624\n",
            "Iter 4150: train loss: 0.5603234171867371\n",
            "Iter 4151: train loss: 0.5601947903633118\n",
            "Iter 4152: train loss: 0.5600663423538208\n",
            "Iter 4153: train loss: 0.5599377751350403\n",
            "Iter 4154: train loss: 0.5598092675209045\n",
            "Iter 4155: train loss: 0.5596808195114136\n",
            "Iter 4156: train loss: 0.5595524311065674\n",
            "Iter 4157: train loss: 0.5594239830970764\n",
            "Iter 4158: train loss: 0.559295654296875\n",
            "Iter 4159: train loss: 0.559167206287384\n",
            "Iter 4160: train loss: 0.5590388774871826\n",
            "Iter 4161: train loss: 0.5589106678962708\n",
            "Iter 4162: train loss: 0.5587823390960693\n",
            "Iter 4163: train loss: 0.5586541295051575\n",
            "Iter 4164: train loss: 0.5585258603096008\n",
            "Iter 4165: train loss: 0.5583977103233337\n",
            "Iter 4166: train loss: 0.5582695603370667\n",
            "Iter 4167: train loss: 0.5581415295600891\n",
            "Iter 4168: train loss: 0.5580133199691772\n",
            "Iter 4169: train loss: 0.5578852295875549\n",
            "Iter 4170: train loss: 0.5577571988105774\n",
            "Iter 4171: train loss: 0.5576292276382446\n",
            "Iter 4172: train loss: 0.5575012564659119\n",
            "Iter 4173: train loss: 0.5573732852935791\n",
            "Iter 4174: train loss: 0.5572453141212463\n",
            "Iter 4175: train loss: 0.5571174621582031\n",
            "Iter 4176: train loss: 0.5569896101951599\n",
            "Iter 4177: train loss: 0.5568616986274719\n",
            "Iter 4178: train loss: 0.5567339062690735\n",
            "Iter 4179: train loss: 0.556606113910675\n",
            "Iter 4180: train loss: 0.5564784407615662\n",
            "Iter 4181: train loss: 0.5563506484031677\n",
            "Iter 4182: train loss: 0.5562229156494141\n",
            "Iter 4183: train loss: 0.5560952425003052\n",
            "Iter 4184: train loss: 0.5559676289558411\n",
            "Iter 4185: train loss: 0.555840015411377\n",
            "Iter 4186: train loss: 0.5557124018669128\n",
            "Iter 4187: train loss: 0.5555847883224487\n",
            "Iter 4188: train loss: 0.5554572939872742\n",
            "Iter 4189: train loss: 0.5553297400474548\n",
            "Iter 4190: train loss: 0.555202305316925\n",
            "Iter 4191: train loss: 0.5550748705863953\n",
            "Iter 4192: train loss: 0.5549473762512207\n",
            "Iter 4193: train loss: 0.5548200011253357\n",
            "Iter 4194: train loss: 0.5546926259994507\n",
            "Iter 4195: train loss: 0.5545653104782104\n",
            "Iter 4196: train loss: 0.5544379949569702\n",
            "Iter 4197: train loss: 0.55431067943573\n",
            "Iter 4198: train loss: 0.5541834831237793\n",
            "Iter 4199: train loss: 0.5540561676025391\n",
            "Iter 4200: train loss: 0.5539290308952332\n",
            "Iter 4201: train loss: 0.5538018345832825\n",
            "Iter 4202: train loss: 0.5536746978759766\n",
            "Iter 4203: train loss: 0.5535475611686707\n",
            "Iter 4204: train loss: 0.5534205436706543\n",
            "Iter 4205: train loss: 0.5532934665679932\n",
            "Iter 4206: train loss: 0.553166389465332\n",
            "Iter 4207: train loss: 0.5530393719673157\n",
            "Iter 4208: train loss: 0.5529124140739441\n",
            "Iter 4209: train loss: 0.5527854561805725\n",
            "Iter 4210: train loss: 0.5526585578918457\n",
            "Iter 4211: train loss: 0.5525315999984741\n",
            "Iter 4212: train loss: 0.5524047613143921\n",
            "Iter 4213: train loss: 0.5522779226303101\n",
            "Iter 4214: train loss: 0.5521512031555176\n",
            "Iter 4215: train loss: 0.5520243048667908\n",
            "Iter 4216: train loss: 0.5518976449966431\n",
            "Iter 4217: train loss: 0.5517709255218506\n",
            "Iter 4218: train loss: 0.5516441464424133\n",
            "Iter 4219: train loss: 0.5515175461769104\n",
            "Iter 4220: train loss: 0.5513908863067627\n",
            "Iter 4221: train loss: 0.5512641668319702\n",
            "Iter 4222: train loss: 0.5511376261711121\n",
            "Iter 4223: train loss: 0.5510110855102539\n",
            "Iter 4224: train loss: 0.5508845448493958\n",
            "Iter 4225: train loss: 0.5507580041885376\n",
            "Iter 4226: train loss: 0.5506315231323242\n",
            "Iter 4227: train loss: 0.5505050420761108\n",
            "Iter 4228: train loss: 0.550378680229187\n",
            "Iter 4229: train loss: 0.5502521991729736\n",
            "Iter 4230: train loss: 0.5501258373260498\n",
            "Iter 4231: train loss: 0.5499995350837708\n",
            "Iter 4232: train loss: 0.5498731732368469\n",
            "Iter 4233: train loss: 0.5497468709945679\n",
            "Iter 4234: train loss: 0.5496206283569336\n",
            "Iter 4235: train loss: 0.5494943857192993\n",
            "Iter 4236: train loss: 0.5493682026863098\n",
            "Iter 4237: train loss: 0.5492420196533203\n",
            "Iter 4238: train loss: 0.549115777015686\n",
            "Iter 4239: train loss: 0.5489896535873413\n",
            "Iter 4240: train loss: 0.5488635301589966\n",
            "Iter 4241: train loss: 0.5487375259399414\n",
            "Iter 4242: train loss: 0.5486114025115967\n",
            "Iter 4243: train loss: 0.5484853982925415\n",
            "Iter 4244: train loss: 0.5483594536781311\n",
            "Iter 4245: train loss: 0.5482334494590759\n",
            "Iter 4246: train loss: 0.5481075048446655\n",
            "Iter 4247: train loss: 0.5479816198348999\n",
            "Iter 4248: train loss: 0.5478557348251343\n",
            "Iter 4249: train loss: 0.5477298498153687\n",
            "Iter 4250: train loss: 0.5476040244102478\n",
            "Iter 4251: train loss: 0.547478199005127\n",
            "Iter 4252: train loss: 0.5473523736000061\n",
            "Iter 4253: train loss: 0.54722660779953\n",
            "Iter 4254: train loss: 0.547100841999054\n",
            "Iter 4255: train loss: 0.5469751358032227\n",
            "Iter 4256: train loss: 0.5468494892120361\n",
            "Iter 4257: train loss: 0.5467238426208496\n",
            "Iter 4258: train loss: 0.5465981960296631\n",
            "Iter 4259: train loss: 0.5464725494384766\n",
            "Iter 4260: train loss: 0.5463470220565796\n",
            "Iter 4261: train loss: 0.5462214350700378\n",
            "Iter 4262: train loss: 0.5460959076881409\n",
            "Iter 4263: train loss: 0.5459704399108887\n",
            "Iter 4264: train loss: 0.5458449125289917\n",
            "Iter 4265: train loss: 0.5457195043563843\n",
            "Iter 4266: train loss: 0.5455940365791321\n",
            "Iter 4267: train loss: 0.5454686284065247\n",
            "Iter 4268: train loss: 0.545343279838562\n",
            "Iter 4269: train loss: 0.5452179312705994\n",
            "Iter 4270: train loss: 0.5450925827026367\n",
            "Iter 4271: train loss: 0.5449672937393188\n",
            "Iter 4272: train loss: 0.5448420643806458\n",
            "Iter 4273: train loss: 0.5447167754173279\n",
            "Iter 4274: train loss: 0.5445916056632996\n",
            "Iter 4275: train loss: 0.5444663166999817\n",
            "Iter 4276: train loss: 0.5443412065505981\n",
            "Iter 4277: train loss: 0.5442160964012146\n",
            "Iter 4278: train loss: 0.5440909266471863\n",
            "Iter 4279: train loss: 0.5439658164978027\n",
            "Iter 4280: train loss: 0.543840765953064\n",
            "Iter 4281: train loss: 0.5437157154083252\n",
            "Iter 4282: train loss: 0.5435906648635864\n",
            "Iter 4283: train loss: 0.5434656739234924\n",
            "Iter 4284: train loss: 0.5433406829833984\n",
            "Iter 4285: train loss: 0.5432157516479492\n",
            "Iter 4286: train loss: 0.5430908203125\n",
            "Iter 4287: train loss: 0.5429658889770508\n",
            "Iter 4288: train loss: 0.5428410172462463\n",
            "Iter 4289: train loss: 0.5427162051200867\n",
            "Iter 4290: train loss: 0.5425913333892822\n",
            "Iter 4291: train loss: 0.5424665212631226\n",
            "Iter 4292: train loss: 0.5423417687416077\n",
            "Iter 4293: train loss: 0.542216956615448\n",
            "Iter 4294: train loss: 0.5420922040939331\n",
            "Iter 4295: train loss: 0.541967511177063\n",
            "Iter 4296: train loss: 0.5418428778648376\n",
            "Iter 4297: train loss: 0.5417181849479675\n",
            "Iter 4298: train loss: 0.5415935516357422\n",
            "Iter 4299: train loss: 0.5414689183235168\n",
            "Iter 4300: train loss: 0.5413443446159363\n",
            "Iter 4301: train loss: 0.5412197709083557\n",
            "Iter 4302: train loss: 0.5410951972007751\n",
            "Iter 4303: train loss: 0.5409706830978394\n",
            "Iter 4304: train loss: 0.5408461689949036\n",
            "Iter 4305: train loss: 0.5407217144966125\n",
            "Iter 4306: train loss: 0.5405972599983215\n",
            "Iter 4307: train loss: 0.5404728651046753\n",
            "Iter 4308: train loss: 0.540348470211029\n",
            "Iter 4309: train loss: 0.5402240753173828\n",
            "Iter 4310: train loss: 0.5400996804237366\n",
            "Iter 4311: train loss: 0.5399753451347351\n",
            "Iter 4312: train loss: 0.5398510098457336\n",
            "Iter 4313: train loss: 0.539726734161377\n",
            "Iter 4314: train loss: 0.5396024584770203\n",
            "Iter 4315: train loss: 0.5394782423973083\n",
            "Iter 4316: train loss: 0.5393540859222412\n",
            "Iter 4317: train loss: 0.5392297506332397\n",
            "Iter 4318: train loss: 0.5391055941581726\n",
            "Iter 4319: train loss: 0.5389814376831055\n",
            "Iter 4320: train loss: 0.5388573408126831\n",
            "Iter 4321: train loss: 0.538733184337616\n",
            "Iter 4322: train loss: 0.5386090874671936\n",
            "Iter 4323: train loss: 0.5384849309921265\n",
            "Iter 4324: train loss: 0.5383610129356384\n",
            "Iter 4325: train loss: 0.5382369160652161\n",
            "Iter 4326: train loss: 0.5381129384040833\n",
            "Iter 4327: train loss: 0.5379889011383057\n",
            "Iter 4328: train loss: 0.5378649830818176\n",
            "Iter 4329: train loss: 0.5377410054206848\n",
            "Iter 4330: train loss: 0.5376171469688416\n",
            "Iter 4331: train loss: 0.5374932289123535\n",
            "Iter 4332: train loss: 0.5373693108558655\n",
            "Iter 4333: train loss: 0.5372454524040222\n",
            "Iter 4334: train loss: 0.5371215343475342\n",
            "Iter 4335: train loss: 0.5369977951049805\n",
            "Iter 4336: train loss: 0.536873996257782\n",
            "Iter 4337: train loss: 0.5367501974105835\n",
            "Iter 4338: train loss: 0.5366264581680298\n",
            "Iter 4339: train loss: 0.5365027189254761\n",
            "Iter 4340: train loss: 0.5363789200782776\n",
            "Iter 4341: train loss: 0.5362553000450134\n",
            "Iter 4342: train loss: 0.5361316204071045\n",
            "Iter 4343: train loss: 0.5360079407691956\n",
            "Iter 4344: train loss: 0.5358843207359314\n",
            "Iter 4345: train loss: 0.5357607007026672\n",
            "Iter 4346: train loss: 0.5356371402740479\n",
            "Iter 4347: train loss: 0.5355134606361389\n",
            "Iter 4348: train loss: 0.5353899002075195\n",
            "Iter 4349: train loss: 0.5352663993835449\n",
            "Iter 4350: train loss: 0.5351428985595703\n",
            "Iter 4351: train loss: 0.5350193977355957\n",
            "Iter 4352: train loss: 0.5348958969116211\n",
            "Iter 4353: train loss: 0.5347724556922913\n",
            "Iter 4354: train loss: 0.5346490144729614\n",
            "Iter 4355: train loss: 0.5345256328582764\n",
            "Iter 4356: train loss: 0.5344021320343018\n",
            "Iter 4357: train loss: 0.5342787504196167\n",
            "Iter 4358: train loss: 0.5341554284095764\n",
            "Iter 4359: train loss: 0.5340321063995361\n",
            "Iter 4360: train loss: 0.5339086651802063\n",
            "Iter 4361: train loss: 0.5337854623794556\n",
            "Iter 4362: train loss: 0.5336621403694153\n",
            "Iter 4363: train loss: 0.5335388779640198\n",
            "Iter 4364: train loss: 0.5334156155586243\n",
            "Iter 4365: train loss: 0.5332923531532288\n",
            "Iter 4366: train loss: 0.533169150352478\n",
            "Iter 4367: train loss: 0.5330460071563721\n",
            "Iter 4368: train loss: 0.5329227447509766\n",
            "Iter 4369: train loss: 0.5327995419502258\n",
            "Iter 4370: train loss: 0.5326763987541199\n",
            "Iter 4371: train loss: 0.5325532555580139\n",
            "Iter 4372: train loss: 0.5324301719665527\n",
            "Iter 4373: train loss: 0.5323070883750916\n",
            "Iter 4374: train loss: 0.5321839451789856\n",
            "Iter 4375: train loss: 0.532060980796814\n",
            "Iter 4376: train loss: 0.531937837600708\n",
            "Iter 4377: train loss: 0.5318148136138916\n",
            "Iter 4378: train loss: 0.53169184923172\n",
            "Iter 4379: train loss: 0.5315688252449036\n",
            "Iter 4380: train loss: 0.5314458012580872\n",
            "Iter 4381: train loss: 0.5313228964805603\n",
            "Iter 4382: train loss: 0.5311998724937439\n",
            "Iter 4383: train loss: 0.531076967716217\n",
            "Iter 4384: train loss: 0.530954122543335\n",
            "Iter 4385: train loss: 0.5308311581611633\n",
            "Iter 4386: train loss: 0.5307082533836365\n",
            "Iter 4387: train loss: 0.5305854082107544\n",
            "Iter 4388: train loss: 0.5304625034332275\n",
            "Iter 4389: train loss: 0.5303397178649902\n",
            "Iter 4390: train loss: 0.5302168726921082\n",
            "Iter 4391: train loss: 0.5300940871238708\n",
            "Iter 4392: train loss: 0.5299713015556335\n",
            "Iter 4393: train loss: 0.5298484563827515\n",
            "Iter 4394: train loss: 0.5297257900238037\n",
            "Iter 4395: train loss: 0.5296030044555664\n",
            "Iter 4396: train loss: 0.5294803380966187\n",
            "Iter 4397: train loss: 0.5293574929237366\n",
            "Iter 4398: train loss: 0.5292348265647888\n",
            "Iter 4399: train loss: 0.5291121602058411\n",
            "Iter 4400: train loss: 0.5289894342422485\n",
            "Iter 4401: train loss: 0.5288668274879456\n",
            "Iter 4402: train loss: 0.5287441611289978\n",
            "Iter 4403: train loss: 0.52862149477005\n",
            "Iter 4404: train loss: 0.5284989476203918\n",
            "Iter 4405: train loss: 0.5283762812614441\n",
            "Iter 4406: train loss: 0.5282536745071411\n",
            "Iter 4407: train loss: 0.5281310677528381\n",
            "Iter 4408: train loss: 0.5280085206031799\n",
            "Iter 4409: train loss: 0.5278859734535217\n",
            "Iter 4410: train loss: 0.5277634859085083\n",
            "Iter 4411: train loss: 0.5276409387588501\n",
            "Iter 4412: train loss: 0.5275183916091919\n",
            "Iter 4413: train loss: 0.5273958444595337\n",
            "Iter 4414: train loss: 0.5272733569145203\n",
            "Iter 4415: train loss: 0.5271509289741516\n",
            "Iter 4416: train loss: 0.5270284414291382\n",
            "Iter 4417: train loss: 0.5269060134887695\n",
            "Iter 4418: train loss: 0.5267835259437561\n",
            "Iter 4419: train loss: 0.5266610980033875\n",
            "Iter 4420: train loss: 0.5265386700630188\n",
            "Iter 4421: train loss: 0.5264163017272949\n",
            "Iter 4422: train loss: 0.526293933391571\n",
            "Iter 4423: train loss: 0.5261715054512024\n",
            "Iter 4424: train loss: 0.5260491371154785\n",
            "Iter 4425: train loss: 0.5259267687797546\n",
            "Iter 4426: train loss: 0.5258044600486755\n",
            "Iter 4427: train loss: 0.5256820917129517\n",
            "Iter 4428: train loss: 0.5255597829818726\n",
            "Iter 4429: train loss: 0.5254374146461487\n",
            "Iter 4430: train loss: 0.5253151059150696\n",
            "Iter 4431: train loss: 0.5251928567886353\n",
            "Iter 4432: train loss: 0.5250705480575562\n",
            "Iter 4433: train loss: 0.5249482989311218\n",
            "Iter 4434: train loss: 0.5248259902000427\n",
            "Iter 4435: train loss: 0.5247037410736084\n",
            "Iter 4436: train loss: 0.5245814919471741\n",
            "Iter 4437: train loss: 0.5244592428207397\n",
            "Iter 4438: train loss: 0.5243370532989502\n",
            "Iter 4439: train loss: 0.5242148041725159\n",
            "Iter 4440: train loss: 0.5240925550460815\n",
            "Iter 4441: train loss: 0.5239704251289368\n",
            "Iter 4442: train loss: 0.5238482356071472\n",
            "Iter 4443: train loss: 0.5237260460853577\n",
            "Iter 4444: train loss: 0.5236037969589233\n",
            "Iter 4445: train loss: 0.5234816670417786\n",
            "Iter 4446: train loss: 0.5233595371246338\n",
            "Iter 4447: train loss: 0.5232373476028442\n",
            "Iter 4448: train loss: 0.5231152176856995\n",
            "Iter 4449: train loss: 0.5229930877685547\n",
            "Iter 4450: train loss: 0.5228710174560547\n",
            "Iter 4451: train loss: 0.5227488279342651\n",
            "Iter 4452: train loss: 0.5226268172264099\n",
            "Iter 4453: train loss: 0.5225046873092651\n",
            "Iter 4454: train loss: 0.5223825573921204\n",
            "Iter 4455: train loss: 0.5222604274749756\n",
            "Iter 4456: train loss: 0.5221384167671204\n",
            "Iter 4457: train loss: 0.5220163464546204\n",
            "Iter 4458: train loss: 0.5218942761421204\n",
            "Iter 4459: train loss: 0.5217722058296204\n",
            "Iter 4460: train loss: 0.5216501355171204\n",
            "Iter 4461: train loss: 0.5215281248092651\n",
            "Iter 4462: train loss: 0.5214060544967651\n",
            "Iter 4463: train loss: 0.5212841033935547\n",
            "Iter 4464: train loss: 0.5211620330810547\n",
            "Iter 4465: train loss: 0.5210399627685547\n",
            "Iter 4466: train loss: 0.5209179520606995\n",
            "Iter 4467: train loss: 0.5207958817481995\n",
            "Iter 4468: train loss: 0.520673930644989\n",
            "Iter 4469: train loss: 0.5205519795417786\n",
            "Iter 4470: train loss: 0.5204299688339233\n",
            "Iter 4471: train loss: 0.5203080177307129\n",
            "Iter 4472: train loss: 0.5201860070228577\n",
            "Iter 4473: train loss: 0.5200639963150024\n",
            "Iter 4474: train loss: 0.519942045211792\n",
            "Iter 4475: train loss: 0.5198200345039368\n",
            "Iter 4476: train loss: 0.5196981430053711\n",
            "Iter 4477: train loss: 0.5195761322975159\n",
            "Iter 4478: train loss: 0.5194541811943054\n",
            "Iter 4479: train loss: 0.519332230091095\n",
            "Iter 4480: train loss: 0.5192102193832397\n",
            "Iter 4481: train loss: 0.5190882682800293\n",
            "Iter 4482: train loss: 0.5189663171768188\n",
            "Iter 4483: train loss: 0.5188443660736084\n",
            "Iter 4484: train loss: 0.5187224745750427\n",
            "Iter 4485: train loss: 0.5186005234718323\n",
            "Iter 4486: train loss: 0.5184785723686218\n",
            "Iter 4487: train loss: 0.5183566808700562\n",
            "Iter 4488: train loss: 0.5182346701622009\n",
            "Iter 4489: train loss: 0.5181127786636353\n",
            "Iter 4490: train loss: 0.5179908871650696\n",
            "Iter 4491: train loss: 0.5178689360618591\n",
            "Iter 4492: train loss: 0.5177469849586487\n",
            "Iter 4493: train loss: 0.517625093460083\n",
            "Iter 4494: train loss: 0.5175032019615173\n",
            "Iter 4495: train loss: 0.5173812508583069\n",
            "Iter 4496: train loss: 0.5172593593597412\n",
            "Iter 4497: train loss: 0.5171374678611755\n",
            "Iter 4498: train loss: 0.5170155167579651\n",
            "Iter 4499: train loss: 0.5168936252593994\n",
            "Iter 4500: train loss: 0.516771674156189\n",
            "Iter 4501: train loss: 0.5166498422622681\n",
            "Iter 4502: train loss: 0.5165278911590576\n",
            "Iter 4503: train loss: 0.5164059996604919\n",
            "Iter 4504: train loss: 0.5162840485572815\n",
            "Iter 4505: train loss: 0.5161621570587158\n",
            "Iter 4506: train loss: 0.5160402059555054\n",
            "Iter 4507: train loss: 0.5159183144569397\n",
            "Iter 4508: train loss: 0.515796422958374\n",
            "Iter 4509: train loss: 0.5156745314598083\n",
            "Iter 4510: train loss: 0.5155525803565979\n",
            "Iter 4511: train loss: 0.5154306888580322\n",
            "Iter 4512: train loss: 0.5153088569641113\n",
            "Iter 4513: train loss: 0.5151869058609009\n",
            "Iter 4514: train loss: 0.5150649547576904\n",
            "Iter 4515: train loss: 0.51494300365448\n",
            "Iter 4516: train loss: 0.5148211121559143\n",
            "Iter 4517: train loss: 0.5146991610527039\n",
            "Iter 4518: train loss: 0.5145772695541382\n",
            "Iter 4519: train loss: 0.514455258846283\n",
            "Iter 4520: train loss: 0.5143333673477173\n",
            "Iter 4521: train loss: 0.5142114758491516\n",
            "Iter 4522: train loss: 0.5140895247459412\n",
            "Iter 4523: train loss: 0.5139675140380859\n",
            "Iter 4524: train loss: 0.5138455629348755\n",
            "Iter 4525: train loss: 0.5137235522270203\n",
            "Iter 4526: train loss: 0.5136016607284546\n",
            "Iter 4527: train loss: 0.5134797096252441\n",
            "Iter 4528: train loss: 0.5133577585220337\n",
            "Iter 4529: train loss: 0.5132358074188232\n",
            "Iter 4530: train loss: 0.5131138563156128\n",
            "Iter 4531: train loss: 0.5129918456077576\n",
            "Iter 4532: train loss: 0.5128698945045471\n",
            "Iter 4533: train loss: 0.5127479434013367\n",
            "Iter 4534: train loss: 0.5126259326934814\n",
            "Iter 4535: train loss: 0.5125039219856262\n",
            "Iter 4536: train loss: 0.512381911277771\n",
            "Iter 4537: train loss: 0.5122599601745605\n",
            "Iter 4538: train loss: 0.5121378898620605\n",
            "Iter 4539: train loss: 0.5120158791542053\n",
            "Iter 4540: train loss: 0.5118939280509949\n",
            "Iter 4541: train loss: 0.5117718577384949\n",
            "Iter 4542: train loss: 0.5116498470306396\n",
            "Iter 4543: train loss: 0.5115277767181396\n",
            "Iter 4544: train loss: 0.5114057660102844\n",
            "Iter 4545: train loss: 0.5112836956977844\n",
            "Iter 4546: train loss: 0.5111616253852844\n",
            "Iter 4547: train loss: 0.5110394954681396\n",
            "Iter 4548: train loss: 0.5109174251556396\n",
            "Iter 4549: train loss: 0.5107953548431396\n",
            "Iter 4550: train loss: 0.5106732845306396\n",
            "Iter 4551: train loss: 0.5105512142181396\n",
            "Iter 4552: train loss: 0.5104290246963501\n",
            "Iter 4553: train loss: 0.5103068947792053\n",
            "Iter 4554: train loss: 0.5101848244667053\n",
            "Iter 4555: train loss: 0.5100626945495605\n",
            "Iter 4556: train loss: 0.5099405646324158\n",
            "Iter 4557: train loss: 0.5098183751106262\n",
            "Iter 4558: train loss: 0.5096963047981262\n",
            "Iter 4559: train loss: 0.5095741152763367\n",
            "Iter 4560: train loss: 0.5094519257545471\n",
            "Iter 4561: train loss: 0.5093297362327576\n",
            "Iter 4562: train loss: 0.5092074871063232\n",
            "Iter 4563: train loss: 0.5090852379798889\n",
            "Iter 4564: train loss: 0.5089630484580994\n",
            "Iter 4565: train loss: 0.5088408589363098\n",
            "Iter 4566: train loss: 0.5087185502052307\n",
            "Iter 4567: train loss: 0.5085963606834412\n",
            "Iter 4568: train loss: 0.5084741115570068\n",
            "Iter 4569: train loss: 0.5083518028259277\n",
            "Iter 4570: train loss: 0.5082294940948486\n",
            "Iter 4571: train loss: 0.5081072449684143\n",
            "Iter 4572: train loss: 0.5079848766326904\n",
            "Iter 4573: train loss: 0.5078625679016113\n",
            "Iter 4574: train loss: 0.5077402591705322\n",
            "Iter 4575: train loss: 0.5076178908348083\n",
            "Iter 4576: train loss: 0.5074955224990845\n",
            "Iter 4577: train loss: 0.5073731541633606\n",
            "Iter 4578: train loss: 0.5072507858276367\n",
            "Iter 4579: train loss: 0.5071284174919128\n",
            "Iter 4580: train loss: 0.5070059299468994\n",
            "Iter 4581: train loss: 0.5068836212158203\n",
            "Iter 4582: train loss: 0.5067611336708069\n",
            "Iter 4583: train loss: 0.5066386461257935\n",
            "Iter 4584: train loss: 0.50651615858078\n",
            "Iter 4585: train loss: 0.5063936710357666\n",
            "Iter 4586: train loss: 0.506271243095398\n",
            "Iter 4587: train loss: 0.506148636341095\n",
            "Iter 4588: train loss: 0.5060262084007263\n",
            "Iter 4589: train loss: 0.5059036016464233\n",
            "Iter 4590: train loss: 0.5057811141014099\n",
            "Iter 4591: train loss: 0.5056585073471069\n",
            "Iter 4592: train loss: 0.505535900592804\n",
            "Iter 4593: train loss: 0.505413293838501\n",
            "Iter 4594: train loss: 0.505290687084198\n",
            "Iter 4595: train loss: 0.505168080329895\n",
            "Iter 4596: train loss: 0.5050454139709473\n",
            "Iter 4597: train loss: 0.5049227476119995\n",
            "Iter 4598: train loss: 0.504800021648407\n",
            "Iter 4599: train loss: 0.5046773552894592\n",
            "Iter 4600: train loss: 0.5045546293258667\n",
            "Iter 4601: train loss: 0.5044319033622742\n",
            "Iter 4602: train loss: 0.5043091177940369\n",
            "Iter 4603: train loss: 0.5041863918304443\n",
            "Iter 4604: train loss: 0.504063606262207\n",
            "Iter 4605: train loss: 0.5039408206939697\n",
            "Iter 4606: train loss: 0.5038178563117981\n",
            "Iter 4607: train loss: 0.503695011138916\n",
            "Iter 4608: train loss: 0.5035722851753235\n",
            "Iter 4609: train loss: 0.5034493207931519\n",
            "Iter 4610: train loss: 0.503326416015625\n",
            "Iter 4611: train loss: 0.5032035112380981\n",
            "Iter 4612: train loss: 0.5030805468559265\n",
            "Iter 4613: train loss: 0.5029575824737549\n",
            "Iter 4614: train loss: 0.502834677696228\n",
            "Iter 4615: train loss: 0.5027116537094116\n",
            "Iter 4616: train loss: 0.5025885701179504\n",
            "Iter 4617: train loss: 0.5024656057357788\n",
            "Iter 4618: train loss: 0.5023425221443176\n",
            "Iter 4619: train loss: 0.5022194385528564\n",
            "Iter 4620: train loss: 0.5020962953567505\n",
            "Iter 4621: train loss: 0.5019731521606445\n",
            "Iter 4622: train loss: 0.5018500685691833\n",
            "Iter 4623: train loss: 0.5017269253730774\n",
            "Iter 4624: train loss: 0.5016036629676819\n",
            "Iter 4625: train loss: 0.5014804601669312\n",
            "Iter 4626: train loss: 0.5013571977615356\n",
            "Iter 4627: train loss: 0.5012339949607849\n",
            "Iter 4628: train loss: 0.5011107325553894\n",
            "Iter 4629: train loss: 0.5009873509407043\n",
            "Iter 4630: train loss: 0.5008640289306641\n",
            "Iter 4631: train loss: 0.5007407069206238\n",
            "Iter 4632: train loss: 0.5006173253059387\n",
            "Iter 4633: train loss: 0.5004938840866089\n",
            "Iter 4634: train loss: 0.5003705024719238\n",
            "Iter 4635: train loss: 0.5002470016479492\n",
            "Iter 4636: train loss: 0.5001235008239746\n",
            "Iter 4637: train loss: 0.5000000596046448\n",
            "Iter 4638: train loss: 0.4998764991760254\n",
            "Iter 4639: train loss: 0.4997529983520508\n",
            "Iter 4640: train loss: 0.499629408121109\n",
            "Iter 4641: train loss: 0.49950578808784485\n",
            "Iter 4642: train loss: 0.4993821382522583\n",
            "Iter 4643: train loss: 0.49925851821899414\n",
            "Iter 4644: train loss: 0.4991348087787628\n",
            "Iter 4645: train loss: 0.4990111291408539\n",
            "Iter 4646: train loss: 0.49888741970062256\n",
            "Iter 4647: train loss: 0.49876365065574646\n",
            "Iter 4648: train loss: 0.4986397922039032\n",
            "Iter 4649: train loss: 0.4985160231590271\n",
            "Iter 4650: train loss: 0.4983921945095062\n",
            "Iter 4651: train loss: 0.4982683062553406\n",
            "Iter 4652: train loss: 0.4981444180011749\n",
            "Iter 4653: train loss: 0.4980204701423645\n",
            "Iter 4654: train loss: 0.49789655208587646\n",
            "Iter 4655: train loss: 0.49777254462242126\n",
            "Iter 4656: train loss: 0.49764856696128845\n",
            "Iter 4657: train loss: 0.4975244998931885\n",
            "Iter 4658: train loss: 0.4974003732204437\n",
            "Iter 4659: train loss: 0.49727630615234375\n",
            "Iter 4660: train loss: 0.497152179479599\n",
            "Iter 4661: train loss: 0.49702805280685425\n",
            "Iter 4662: train loss: 0.49690383672714233\n",
            "Iter 4663: train loss: 0.49677959084510803\n",
            "Iter 4664: train loss: 0.49665531516075134\n",
            "Iter 4665: train loss: 0.49653100967407227\n",
            "Iter 4666: train loss: 0.49640679359436035\n",
            "Iter 4667: train loss: 0.4962824285030365\n",
            "Iter 4668: train loss: 0.49615803360939026\n",
            "Iter 4669: train loss: 0.496033638715744\n",
            "Iter 4670: train loss: 0.4959091544151306\n",
            "Iter 4671: train loss: 0.4957846999168396\n",
            "Iter 4672: train loss: 0.4956601858139038\n",
            "Iter 4673: train loss: 0.495535671710968\n",
            "Iter 4674: train loss: 0.49541109800338745\n",
            "Iter 4675: train loss: 0.4952865242958069\n",
            "Iter 4676: train loss: 0.49516183137893677\n",
            "Iter 4677: train loss: 0.49503713846206665\n",
            "Iter 4678: train loss: 0.49491244554519653\n",
            "Iter 4679: train loss: 0.49478769302368164\n",
            "Iter 4680: train loss: 0.49466294050216675\n",
            "Iter 4681: train loss: 0.49453815817832947\n",
            "Iter 4682: train loss: 0.494413286447525\n",
            "Iter 4683: train loss: 0.49428844451904297\n",
            "Iter 4684: train loss: 0.49416351318359375\n",
            "Iter 4685: train loss: 0.49403849244117737\n",
            "Iter 4686: train loss: 0.4939135015010834\n",
            "Iter 4687: train loss: 0.493788480758667\n",
            "Iter 4688: train loss: 0.493663489818573\n",
            "Iter 4689: train loss: 0.49353834986686707\n",
            "Iter 4690: train loss: 0.4934132695198059\n",
            "Iter 4691: train loss: 0.4932880103588104\n",
            "Iter 4692: train loss: 0.4931628704071045\n",
            "Iter 4693: train loss: 0.493037611246109\n",
            "Iter 4694: train loss: 0.49291229248046875\n",
            "Iter 4695: train loss: 0.4927869737148285\n",
            "Iter 4696: train loss: 0.49266165494918823\n",
            "Iter 4697: train loss: 0.4925362169742584\n",
            "Iter 4698: train loss: 0.492410808801651\n",
            "Iter 4699: train loss: 0.4922853708267212\n",
            "Iter 4700: train loss: 0.4921598434448242\n",
            "Iter 4701: train loss: 0.49203434586524963\n",
            "Iter 4702: train loss: 0.4919086992740631\n",
            "Iter 4703: train loss: 0.491783082485199\n",
            "Iter 4704: train loss: 0.49165743589401245\n",
            "Iter 4705: train loss: 0.49153169989585876\n",
            "Iter 4706: train loss: 0.4914059340953827\n",
            "Iter 4707: train loss: 0.49128010869026184\n",
            "Iter 4708: train loss: 0.49115434288978577\n",
            "Iter 4709: train loss: 0.49102845788002014\n",
            "Iter 4710: train loss: 0.4909025728702545\n",
            "Iter 4711: train loss: 0.4907766282558441\n",
            "Iter 4712: train loss: 0.49065056443214417\n",
            "Iter 4713: train loss: 0.4905245900154114\n",
            "Iter 4714: train loss: 0.49039846658706665\n",
            "Iter 4715: train loss: 0.4902723431587219\n",
            "Iter 4716: train loss: 0.4901461899280548\n",
            "Iter 4717: train loss: 0.49001994729042053\n",
            "Iter 4718: train loss: 0.4898937940597534\n",
            "Iter 4719: train loss: 0.4897674322128296\n",
            "Iter 4720: train loss: 0.48964110016822815\n",
            "Iter 4721: train loss: 0.48951470851898193\n",
            "Iter 4722: train loss: 0.48938825726509094\n",
            "Iter 4723: train loss: 0.48926180601119995\n",
            "Iter 4724: train loss: 0.4891352951526642\n",
            "Iter 4725: train loss: 0.48900872468948364\n",
            "Iter 4726: train loss: 0.4888821542263031\n",
            "Iter 4727: train loss: 0.48875540494918823\n",
            "Iter 4728: train loss: 0.48862871527671814\n",
            "Iter 4729: train loss: 0.48850199580192566\n",
            "Iter 4730: train loss: 0.4883752465248108\n",
            "Iter 4731: train loss: 0.488248348236084\n",
            "Iter 4732: train loss: 0.48812153935432434\n",
            "Iter 4733: train loss: 0.48799458146095276\n",
            "Iter 4734: train loss: 0.4878676235675812\n",
            "Iter 4735: train loss: 0.48774057626724243\n",
            "Iter 4736: train loss: 0.4876134991645813\n",
            "Iter 4737: train loss: 0.48748642206192017\n",
            "Iter 4738: train loss: 0.4873592257499695\n",
            "Iter 4739: train loss: 0.4872320294380188\n",
            "Iter 4740: train loss: 0.48710474371910095\n",
            "Iter 4741: train loss: 0.4869774878025055\n",
            "Iter 4742: train loss: 0.4868500530719757\n",
            "Iter 4743: train loss: 0.4867226779460907\n",
            "Iter 4744: train loss: 0.4865952134132385\n",
            "Iter 4745: train loss: 0.4864676892757416\n",
            "Iter 4746: train loss: 0.48634013533592224\n",
            "Iter 4747: train loss: 0.48621249198913574\n",
            "Iter 4748: train loss: 0.486084908246994\n",
            "Iter 4749: train loss: 0.48595714569091797\n",
            "Iter 4750: train loss: 0.48582935333251953\n",
            "Iter 4751: train loss: 0.4857015907764435\n",
            "Iter 4752: train loss: 0.48557373881340027\n",
            "Iter 4753: train loss: 0.4854457974433899\n",
            "Iter 4754: train loss: 0.4853178560733795\n",
            "Iter 4755: train loss: 0.4851897954940796\n",
            "Iter 4756: train loss: 0.48506176471710205\n",
            "Iter 4757: train loss: 0.4849335849285126\n",
            "Iter 4758: train loss: 0.4848054349422455\n",
            "Iter 4759: train loss: 0.4846772253513336\n",
            "Iter 4760: train loss: 0.4845489263534546\n",
            "Iter 4761: train loss: 0.4844205379486084\n",
            "Iter 4762: train loss: 0.4842921495437622\n",
            "Iter 4763: train loss: 0.48416370153427124\n",
            "Iter 4764: train loss: 0.4840352535247803\n",
            "Iter 4765: train loss: 0.48390665650367737\n",
            "Iter 4766: train loss: 0.4837780296802521\n",
            "Iter 4767: train loss: 0.483649343252182\n",
            "Iter 4768: train loss: 0.48352062702178955\n",
            "Iter 4769: train loss: 0.4833918809890747\n",
            "Iter 4770: train loss: 0.4832629859447479\n",
            "Iter 4771: train loss: 0.4831341505050659\n",
            "Iter 4772: train loss: 0.48300519585609436\n",
            "Iter 4773: train loss: 0.48287615180015564\n",
            "Iter 4774: train loss: 0.4827471375465393\n",
            "Iter 4775: train loss: 0.48261797428131104\n",
            "Iter 4776: train loss: 0.48248884081840515\n",
            "Iter 4777: train loss: 0.4823595881462097\n",
            "Iter 4778: train loss: 0.4822302758693695\n",
            "Iter 4779: train loss: 0.4821009337902069\n",
            "Iter 4780: train loss: 0.48197150230407715\n",
            "Iter 4781: train loss: 0.481842041015625\n",
            "Iter 4782: train loss: 0.48171257972717285\n",
            "Iter 4783: train loss: 0.4815829396247864\n",
            "Iter 4784: train loss: 0.4814532697200775\n",
            "Iter 4785: train loss: 0.48132362961769104\n",
            "Iter 4786: train loss: 0.481193870306015\n",
            "Iter 4787: train loss: 0.4810640215873718\n",
            "Iter 4788: train loss: 0.48093414306640625\n",
            "Iter 4789: train loss: 0.4808041453361511\n",
            "Iter 4790: train loss: 0.4806741774082184\n",
            "Iter 4791: train loss: 0.4805440902709961\n",
            "Iter 4792: train loss: 0.4804139733314514\n",
            "Iter 4793: train loss: 0.4802837669849396\n",
            "Iter 4794: train loss: 0.48015356063842773\n",
            "Iter 4795: train loss: 0.48002323508262634\n",
            "Iter 4796: train loss: 0.4798927903175354\n",
            "Iter 4797: train loss: 0.47976234555244446\n",
            "Iter 4798: train loss: 0.4796319007873535\n",
            "Iter 4799: train loss: 0.47950130701065063\n",
            "Iter 4800: train loss: 0.47937068343162537\n",
            "Iter 4801: train loss: 0.4792400300502777\n",
            "Iter 4802: train loss: 0.4791092276573181\n",
            "Iter 4803: train loss: 0.47897839546203613\n",
            "Iter 4804: train loss: 0.4788475036621094\n",
            "Iter 4805: train loss: 0.47871655225753784\n",
            "Iter 4806: train loss: 0.47858554124832153\n",
            "Iter 4807: train loss: 0.47845447063446045\n",
            "Iter 4808: train loss: 0.4783233106136322\n",
            "Iter 4809: train loss: 0.47819212079048157\n",
            "Iter 4810: train loss: 0.4780608117580414\n",
            "Iter 4811: train loss: 0.4779295325279236\n",
            "Iter 4812: train loss: 0.47779807448387146\n",
            "Iter 4813: train loss: 0.47766658663749695\n",
            "Iter 4814: train loss: 0.4775350093841553\n",
            "Iter 4815: train loss: 0.4774033725261688\n",
            "Iter 4816: train loss: 0.47727170586586\n",
            "Iter 4817: train loss: 0.47714000940322876\n",
            "Iter 4818: train loss: 0.4770081341266632\n",
            "Iter 4819: train loss: 0.47687625885009766\n",
            "Iter 4820: train loss: 0.47674429416656494\n",
            "Iter 4821: train loss: 0.4766123294830322\n",
            "Iter 4822: train loss: 0.4764802157878876\n",
            "Iter 4823: train loss: 0.47634801268577576\n",
            "Iter 4824: train loss: 0.47621574997901917\n",
            "Iter 4825: train loss: 0.4760834276676178\n",
            "Iter 4826: train loss: 0.4759511947631836\n",
            "Iter 4827: train loss: 0.4758186638355255\n",
            "Iter 4828: train loss: 0.47568613290786743\n",
            "Iter 4829: train loss: 0.4755535423755646\n",
            "Iter 4830: train loss: 0.47542092204093933\n",
            "Iter 4831: train loss: 0.47528815269470215\n",
            "Iter 4832: train loss: 0.47515538334846497\n",
            "Iter 4833: train loss: 0.47502249479293823\n",
            "Iter 4834: train loss: 0.4748895764350891\n",
            "Iter 4835: train loss: 0.4747565686702728\n",
            "Iter 4836: train loss: 0.474623441696167\n",
            "Iter 4837: train loss: 0.4744902551174164\n",
            "Iter 4838: train loss: 0.4743570387363434\n",
            "Iter 4839: train loss: 0.4742237627506256\n",
            "Iter 4840: train loss: 0.4740903079509735\n",
            "Iter 4841: train loss: 0.4739568829536438\n",
            "Iter 4842: train loss: 0.47382330894470215\n",
            "Iter 4843: train loss: 0.4736897945404053\n",
            "Iter 4844: train loss: 0.4735561013221741\n",
            "Iter 4845: train loss: 0.4734223186969757\n",
            "Iter 4846: train loss: 0.47328853607177734\n",
            "Iter 4847: train loss: 0.47315454483032227\n",
            "Iter 4848: train loss: 0.47302064299583435\n",
            "Iter 4849: train loss: 0.4728865623474121\n",
            "Iter 4850: train loss: 0.4727524220943451\n",
            "Iter 4851: train loss: 0.4726182222366333\n",
            "Iter 4852: train loss: 0.47248393297195435\n",
            "Iter 4853: train loss: 0.4723495543003082\n",
            "Iter 4854: train loss: 0.4722151458263397\n",
            "Iter 4855: train loss: 0.4720805585384369\n",
            "Iter 4856: train loss: 0.47194603085517883\n",
            "Iter 4857: train loss: 0.47181135416030884\n",
            "Iter 4858: train loss: 0.4716765880584717\n",
            "Iter 4859: train loss: 0.47154173254966736\n",
            "Iter 4860: train loss: 0.47140681743621826\n",
            "Iter 4861: train loss: 0.4712718427181244\n",
            "Iter 4862: train loss: 0.47113677859306335\n",
            "Iter 4863: train loss: 0.47100162506103516\n",
            "Iter 4864: train loss: 0.4708663821220398\n",
            "Iter 4865: train loss: 0.47073107957839966\n",
            "Iter 4866: train loss: 0.47059568762779236\n",
            "Iter 4867: train loss: 0.4704602360725403\n",
            "Iter 4868: train loss: 0.47032469511032104\n",
            "Iter 4869: train loss: 0.47018909454345703\n",
            "Iter 4870: train loss: 0.4700533151626587\n",
            "Iter 4871: train loss: 0.46991756558418274\n",
            "Iter 4872: train loss: 0.4697817265987396\n",
            "Iter 4873: train loss: 0.4696457087993622\n",
            "Iter 4874: train loss: 0.46950963139533997\n",
            "Iter 4875: train loss: 0.46937358379364014\n",
            "Iter 4876: train loss: 0.469237357378006\n",
            "Iter 4877: train loss: 0.46910110116004944\n",
            "Iter 4878: train loss: 0.46896472573280334\n",
            "Iter 4879: train loss: 0.4688282310962677\n",
            "Iter 4880: train loss: 0.46869176626205444\n",
            "Iter 4881: train loss: 0.46855512261390686\n",
            "Iter 4882: train loss: 0.4684183597564697\n",
            "Iter 4883: train loss: 0.468281626701355\n",
            "Iter 4884: train loss: 0.4681447744369507\n",
            "Iter 4885: train loss: 0.46800777316093445\n",
            "Iter 4886: train loss: 0.4678707420825958\n",
            "Iter 4887: train loss: 0.46773359179496765\n",
            "Iter 4888: train loss: 0.4675963819026947\n",
            "Iter 4889: train loss: 0.467459112405777\n",
            "Iter 4890: train loss: 0.4673217236995697\n",
            "Iter 4891: train loss: 0.46718424558639526\n",
            "Iter 4892: train loss: 0.46704670786857605\n",
            "Iter 4893: train loss: 0.4669090509414673\n",
            "Iter 4894: train loss: 0.46677133440971375\n",
            "Iter 4895: train loss: 0.46663355827331543\n",
            "Iter 4896: train loss: 0.4664955735206604\n",
            "Iter 4897: train loss: 0.46635761857032776\n",
            "Iter 4898: train loss: 0.4662195146083832\n",
            "Iter 4899: train loss: 0.46608129143714905\n",
            "Iter 4900: train loss: 0.4659430980682373\n",
            "Iter 4901: train loss: 0.46580472588539124\n",
            "Iter 4902: train loss: 0.4656663239002228\n",
            "Iter 4903: train loss: 0.46552774310112\n",
            "Iter 4904: train loss: 0.4653891324996948\n",
            "Iter 4905: train loss: 0.4652504324913025\n",
            "Iter 4906: train loss: 0.46511170268058777\n",
            "Iter 4907: train loss: 0.46497276425361633\n",
            "Iter 4908: train loss: 0.4648338258266449\n",
            "Iter 4909: train loss: 0.4646947383880615\n",
            "Iter 4910: train loss: 0.4645555317401886\n",
            "Iter 4911: train loss: 0.4644163250923157\n",
            "Iter 4912: train loss: 0.4642769992351532\n",
            "Iter 4913: train loss: 0.46413758397102356\n",
            "Iter 4914: train loss: 0.463998019695282\n",
            "Iter 4915: train loss: 0.463858425617218\n",
            "Iter 4916: train loss: 0.4637187421321869\n",
            "Iter 4917: train loss: 0.46357887983322144\n",
            "Iter 4918: train loss: 0.46343907713890076\n",
            "Iter 4919: train loss: 0.46329906582832336\n",
            "Iter 4920: train loss: 0.4631589949131012\n",
            "Iter 4921: train loss: 0.4630188047885895\n",
            "Iter 4922: train loss: 0.4628785252571106\n",
            "Iter 4923: train loss: 0.4627382159233093\n",
            "Iter 4924: train loss: 0.4625977575778961\n",
            "Iter 4925: train loss: 0.46245720982551575\n",
            "Iter 4926: train loss: 0.4623165428638458\n",
            "Iter 4927: train loss: 0.46217581629753113\n",
            "Iter 4928: train loss: 0.46203503012657166\n",
            "Iter 4929: train loss: 0.46189406514167786\n",
            "Iter 4930: train loss: 0.4617530107498169\n",
            "Iter 4931: train loss: 0.46161192655563354\n",
            "Iter 4932: train loss: 0.46147069334983826\n",
            "Iter 4933: train loss: 0.4613294303417206\n",
            "Iter 4934: train loss: 0.46118801832199097\n",
            "Iter 4935: train loss: 0.4610464870929718\n",
            "Iter 4936: train loss: 0.46090492606163025\n",
            "Iter 4937: train loss: 0.46076321601867676\n",
            "Iter 4938: train loss: 0.4606214165687561\n",
            "Iter 4939: train loss: 0.4604795575141907\n",
            "Iter 4940: train loss: 0.4603375494480133\n",
            "Iter 4941: train loss: 0.46019548177719116\n",
            "Iter 4942: train loss: 0.46005329489707947\n",
            "Iter 4943: train loss: 0.45991095900535583\n",
            "Iter 4944: train loss: 0.4597686529159546\n",
            "Iter 4945: train loss: 0.45962613821029663\n",
            "Iter 4946: train loss: 0.4594835638999939\n",
            "Iter 4947: train loss: 0.459340900182724\n",
            "Iter 4948: train loss: 0.45919814705848694\n",
            "Iter 4949: train loss: 0.45905524492263794\n",
            "Iter 4950: train loss: 0.45891228318214417\n",
            "Iter 4951: train loss: 0.45876917243003845\n",
            "Iter 4952: train loss: 0.45862603187561035\n",
            "Iter 4953: train loss: 0.4584828019142151\n",
            "Iter 4954: train loss: 0.4583393931388855\n",
            "Iter 4955: train loss: 0.45819592475891113\n",
            "Iter 4956: train loss: 0.4580523371696472\n",
            "Iter 4957: train loss: 0.4579087197780609\n",
            "Iter 4958: train loss: 0.4577648937702179\n",
            "Iter 4959: train loss: 0.4576210379600525\n",
            "Iter 4960: train loss: 0.45747706294059753\n",
            "Iter 4961: train loss: 0.45733293890953064\n",
            "Iter 4962: train loss: 0.45718875527381897\n",
            "Iter 4963: train loss: 0.4570445120334625\n",
            "Iter 4964: train loss: 0.45690008997917175\n",
            "Iter 4965: train loss: 0.4567556381225586\n",
            "Iter 4966: train loss: 0.4566110372543335\n",
            "Iter 4967: train loss: 0.45646634697914124\n",
            "Iter 4968: train loss: 0.4563215672969818\n",
            "Iter 4969: train loss: 0.4561765789985657\n",
            "Iter 4970: train loss: 0.4560316205024719\n",
            "Iter 4971: train loss: 0.45588651299476624\n",
            "Iter 4972: train loss: 0.4557413160800934\n",
            "Iter 4973: train loss: 0.455595999956131\n",
            "Iter 4974: train loss: 0.4554505944252014\n",
            "Iter 4975: train loss: 0.4553050696849823\n",
            "Iter 4976: train loss: 0.45515939593315125\n",
            "Iter 4977: train loss: 0.4550136923789978\n",
            "Iter 4978: train loss: 0.4548678398132324\n",
            "Iter 4979: train loss: 0.4547218680381775\n",
            "Iter 4980: train loss: 0.4545758366584778\n",
            "Iter 4981: train loss: 0.45442965626716614\n",
            "Iter 4982: train loss: 0.4542834162712097\n",
            "Iter 4983: train loss: 0.45413705706596375\n",
            "Iter 4984: train loss: 0.45399054884910583\n",
            "Iter 4985: train loss: 0.45384401082992554\n",
            "Iter 4986: train loss: 0.4536972939968109\n",
            "Iter 4987: train loss: 0.4535505175590515\n",
            "Iter 4988: train loss: 0.4534035921096802\n",
            "Iter 4989: train loss: 0.4532565474510193\n",
            "Iter 4990: train loss: 0.4531094431877136\n",
            "Iter 4991: train loss: 0.4529622197151184\n",
            "Iter 4992: train loss: 0.45281487703323364\n",
            "Iter 4993: train loss: 0.4526674747467041\n",
            "Iter 4994: train loss: 0.45251989364624023\n",
            "Iter 4995: train loss: 0.4523722529411316\n",
            "Iter 4996: train loss: 0.4522244930267334\n",
            "Iter 4997: train loss: 0.45207658410072327\n",
            "Iter 4998: train loss: 0.45192867517471313\n",
            "Iter 4999: train loss: 0.4517805278301239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train error\n",
        "y_pred = model(x_train) #predict\n",
        "y_pred=(y_pred>0.5).int().flatten() #argmax class lable\n",
        "test_acc = torch.sum(y_pred == y_train.int()) /y_train.shape[0]\n",
        "print(\"test ACC: \",test_acc.float())"
      ],
      "metadata": {
        "id": "5oAyQMFldSwU",
        "outputId": "700de7a5-afbb-4879-8333-e1b6bd43cda3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test ACC:  tensor(0.9776)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test error\n",
        "y_pred = model(x_test) #predict\n",
        "y_pred=(y_pred>0.5).int().flatten() #argmax class lable\n",
        "test_acc = torch.sum(y_pred == y_test.int()) /y_test.shape[0]\n",
        "print(\"test ACC: \",test_acc.float())"
      ],
      "metadata": {
        "id": "AKqld7MKW61e",
        "outputId": "ff7711f7-b182-4179-852a-b24712a333ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test ACC:  tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a34SBiPJZMbN"
      },
      "execution_count": 64,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}