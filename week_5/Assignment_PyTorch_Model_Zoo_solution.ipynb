{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mReKErnKCSXj"
      },
      "source": [
        "# Assigment 2: PyTorch Model Zoo\n",
        "\n",
        "The [PyTorch \"Model Zoo\"](https://pytorch.org/vision/stable/models.html) provides a large number of pre-trained CNN models and vision [data sets](https://pytorch.org/vision/stable/datasets.html)..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KmAdRglbCSXr"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sUKIJQ9GCSXt",
        "outputId": "17ac47a6-b753-4ba6-e1c9-387626ce749e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:04<00:00, 40.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "#transform input data (image) to tensor\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "#set batch size\n",
        "batch_size = 64\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMFM5DeGCSXv"
      },
      "source": [
        "## Assignment 1:\n",
        "Load a \"*ResNet18*\" from the torchvision model zoo and train it for 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JWCWLdvVCSXw"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "\n",
        "resnet18 = models.resnet18().cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(resnet18.parameters(), lr=0.01, momentum=0.9)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "running_loss = 0.0\n",
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "    print(\"---epoch:\",epoch)\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].cuda(),data[1].cuda()\n",
        "        #print(labels)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = resnet18(inputs)\n",
        "        #print(outputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
        "            #print(running_loss / 1000)\n",
        "            running_loss = 0.0\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "HOsxwbFINuBL",
        "outputId": "23e8e6da-96fe-43ea-bfef-ae5449c00f43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---epoch: 0\n",
            "---epoch: 1\n",
            "---epoch: 2\n",
            "---epoch: 3\n",
            "---epoch: 4\n",
            "---epoch: 5\n",
            "---epoch: 6\n",
            "---epoch: 7\n",
            "---epoch: 8\n",
            "---epoch: 9\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "resnet18.eval()\n",
        "\n",
        "for data in testloader:\n",
        "        images, labels = data[0].cuda(),data[1].cuda()\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = resnet18(images)\n",
        "        #print(outputs)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        #print(predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
      ],
      "metadata": {
        "id": "UHVWsKNwO8s-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d49ad97-3b47-4e42-82b3-f39de2b7e8ce"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 73 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjhXvjZSCSXw"
      },
      "source": [
        "## Assigment 2:\n",
        "Load a **pre-trained** (on ImageNet) \"*ResNet18*\" from the torchvision model zoo and *fine-tune* it for ten epochs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet18 = models.resnet18(weights='DEFAULT') #use pre-trained model"
      ],
      "metadata": {
        "id": "yjZ4eDV9c2L9",
        "outputId": "f379ddb9-3d68-4113-dd69-0457b08c67bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 184MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print model architecture of the pre-trained model\n",
        "print(resnet18)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L28rDGzDc1Dw",
        "outputId": "21e3cc15-dde6-4094-8f21-124832992d9b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print layer names\n",
        "for name, layer in resnet18.named_children():\n",
        "    print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V30P9XdvdCVk",
        "outputId": "0f7427ea-09ef-44df-fdc0-cb244b69fb7b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1\n",
            "bn1\n",
            "relu\n",
            "maxpool\n",
            "layer1\n",
            "layer2\n",
            "layer3\n",
            "layer4\n",
            "avgpool\n",
            "fc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WcuX8tYdCSXx"
      },
      "outputs": [],
      "source": [
        "#resnet 18 has been pretrained on ImageNet\n",
        "# -> 1000 classes = 1000 output neurons in the last FC layer\n",
        "# -> Cifar 10 has only 10 classes!\n",
        "# -> better change this!\n",
        "resnet18.fc = torch.nn.Linear(in_features=512, out_features=10, bias=True) #this is now new and un-trained!\n",
        "resnet18.cuda() #move model to GPU\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(resnet18.parameters(), lr=0.01, momentum=0.9)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "running_loss = 0.0\n",
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "    print(\"---epoch:\",epoch)\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].cuda(),data[1].cuda()\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = resnet18(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
        "            #print(running_loss / 1000)\n",
        "            running_loss = 0.0\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "NMNnTQjkO2V0",
        "outputId": "26b2c682-3005-4227-8272-4c3396f3147c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---epoch: 0\n",
            "---epoch: 1\n",
            "---epoch: 2\n",
            "---epoch: 3\n",
            "---epoch: 4\n",
            "---epoch: 5\n",
            "---epoch: 6\n",
            "---epoch: 7\n",
            "---epoch: 8\n",
            "---epoch: 9\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "resnet18.cuda()\n",
        "\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "resnet18.eval()\n",
        "\n",
        "for data in testloader:\n",
        "        images, labels = data[0].cuda(),data[1].cuda()\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = resnet18(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
      ],
      "metadata": {
        "id": "2B9TNRVgPDqS",
        "outputId": "d1ede16d-f524-4104-d0e1-8e8bdd782e3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 81 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Alternative Solution: train only last FC Layer..."
      ],
      "metadata": {
        "id": "6JbvtFVbmqKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet18v2 = models.resnet18(weights='DEFAULT') #get new pre-trained model"
      ],
      "metadata": {
        "id": "sioNBGHUPLY9"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all layers -> turn of gradient updates\n",
        "for param in resnet18v2.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "tOmge8kVm4Hf"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet18v2.fc = torch.nn.Linear(in_features=512, out_features=10, bias=True) #this is now new and un-trained!"
      ],
      "metadata": {
        "id": "5_wV-bybnDe4"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in resnet18v2.parameters():\n",
        "    print(param.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V36o25e6nNKj",
        "outputId": "304c2efd-874b-4540-fea0-2703903b1142"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet18v2.cuda() #move model to GPU\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(resnet18v2.fc.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "_1sVvwY0ndPM"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "running_loss = 0.0\n",
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "    print(\"---epoch:\",epoch)\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].cuda(),data[1].cuda()\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = resnet18v2(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
        "            #print(running_loss / 1000)\n",
        "            running_loss = 0.0\n",
        "print('Finished Training')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYAVHUoRnrKT",
        "outputId": "e2bdf4fb-5d85-421a-92b9-1841e1e3f5ae"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---epoch: 0\n",
            "---epoch: 1\n",
            "---epoch: 2\n",
            "---epoch: 3\n",
            "---epoch: 4\n",
            "---epoch: 5\n",
            "---epoch: 6\n",
            "---epoch: 7\n",
            "---epoch: 8\n",
            "---epoch: 9\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# set model to eval mode\n",
        "resnet18v2.eval()\n",
        "\n",
        "for data in testloader:\n",
        "        images, labels = data[0].cuda(),data[1].cuda()\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = resnet18v2(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auxsY_prnxQk",
        "outputId": "b2b999d5-b390-46ef-97da-17067ab02fd6"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 47 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "veemH42Kn3QJ"
      },
      "execution_count": 64,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}